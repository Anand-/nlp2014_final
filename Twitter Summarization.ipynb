{
 "metadata": {
  "name": "",
  "signature": "sha256:d7a4c3076db9b0a8adaa0512d1e74c5ec81beef5949c46dba36baf0827b3ece9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk, string\n",
      "from nltk.corpus import stopwords, brown\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from nltk.collocations import *\n",
      "import codecs, os, json, glob\n",
      "from bs4 import BeautifulSoup\n",
      "from nltk.corpus import wordnet as wn\n",
      "from pandas import DataFrame\n",
      "import pandas as pd\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting data from the Files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get list of files\n",
      "def readFilestoList(path):\n",
      "    filelist = []\n",
      "    for file in glob.glob(os.path.join(path, '*.json')):\n",
      "        filelist.append(file)\n",
      "    return filelist        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def jsonToDict(filelist):\n",
      "    articles = {}\n",
      "    for filepath in filelist:\n",
      "        with open(filepath, 'r') as f:\n",
      "            j = json.load(f)\n",
      "            if 'objects' in j.keys():\n",
      "                if 'title' in j['objects'][0]:\n",
      "                    articles[j['objects'][0]['title']]=j['objects'][0]['text']\n",
      "    return articles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "voterID = readFilestoList(\"C:\\Users\\st.johns\\Desktop\\\\voterID_clean\\\\voterID_clean\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diction = jsonToDict(voterID)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Adding tuples into Dataframe"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def languageCheck(text):\n",
      "    fd = nltk.FreqDist(nltk.word_tokenize(text))\n",
      "    topwords = [key.lower() for key in fd.keys()[:15]]\n",
      "    \n",
      "    if \"the\" not in topwords:\n",
      "#         print \"BAD TOPWORDS: \", topwords\n",
      "        return False\n",
      "    else:\n",
      "#         print \"GOOD TOPWORDS: \", topwords\n",
      "        return True\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pattern to tokenize words from sentences "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r\"([A-Z]\\.)+|\\w+([-']\\w+)*|\\$?\\d+(\\.\\d+)?%?|\\.\\.\\.|[][.,;\\\"'?():-_`]\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def RegTokenizeWords(wordlist):\n",
      "    return [word for word in nltk.regexp_tokenize(wordlist,pattern)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create df for titles & content\n",
      "#tokenize titles and content\n",
      "def tokenizeDictionaryContentToDf(tuples):\n",
      "    articles = []\n",
      "    titles = []\n",
      "    for title,article in tuples.items():\n",
      "#         if(languageCheck(article)):\n",
      "        articles.append(article)\n",
      "        titles.append(title)\n",
      "\n",
      "    data = {'article': articles, 'title': titles}\n",
      "    df = DataFrame(data)\n",
      "    df['tokenized_article'] = df['article'].map(nltk.word_tokenize)\n",
      "    df['tokenized_title'] = df['title'].map(nltk.word_tokenize)\n",
      "    df['tokenized_title2'] = df['title'].map(RegTokenizeWords)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#functions for tokenizing sentences\n",
      "def listToTokens(sentenceList):\n",
      "    tokenized_sents = [RegTokenizeWords(sent) for sent in sentenceList]\n",
      "    return tokenized_sents\n",
      "\n",
      "def tagTokens(tokenList):\n",
      "    tagged_sents = [nltk.pos_tag(sent) for sent in tokenList]\n",
      "    return tagged_sents\n",
      "\n",
      "def tagTitle(title):\n",
      "    tagged_title = [nltk.pos_tag(title)]\n",
      "    return tagged_title\n",
      "\n",
      "\n",
      "#functions for adding columns to df of sentence tokenized, word tokenized, and pos tagged text\n",
      "def docsIntoSents(columnname, df):\n",
      "    df['sent_tokenized'] = df[columnname].map(nltk.sent_tokenize)\n",
      "    return df\n",
      "    \n",
      "def sentsIntoTokens(columnname, df):\n",
      "    df['word_tokenized'] = df[columnname].map(listToTokens)\n",
      "    return df\n",
      "    \n",
      "def tokensPOStag(columnname, df, option='article'):\n",
      "    if option=='article':\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTokens)\n",
      "        return df\n",
      "    else:\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTitle)\n",
      "        return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 268
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_df = tokenizeDictionaryContentToDf(diction)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 269
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_df = docsIntoSents('article', articles_df)\n",
      "articles_df = sentsIntoTokens('sent_tokenized', articles_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 270
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_df = docsIntoSents('article', articles_df)\n",
      "articles_df = sentsIntoTokens('sent_tokenized', articles_df)\n",
      "articles_df = tokensPOStag('word_tokenized', articles_df)\n",
      "articles_df = tokensPOStag('tokenized_title', articles_df, option='title')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_df.head(25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_df.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "article              297\n",
        "title                297\n",
        "tokenized_article    297\n",
        "tokenized_title      297\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Key Phrases for the documents, all taken together"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allwords = []\n",
      "for art in articles_df['tokenized_article']:\n",
      "    allwords.extend([word.encode('ascii', errors='backslashreplace') for word in art])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allwords_noStop_noPunct = [word for word in allwords if word.lower() not in stopwords.words('english') and word not in string.punctuation]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fd = nltk.FreqDist(allwords_noStop_noPunct)\n",
      "fd.items()[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO:\n",
      "1. change tokenizer from word_tokenize to a grammar based (-  this needs sentences)\n",
      "2. stemming before FD?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Summary based on Titles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pstemmer = nltk.PorterStemmer()  #decent - deosn't get proper nouns like texas\n",
      "# lstemmer = nltk.LancasterStemmer() #bad\n",
      "wnlemmatizer = nltk.WordNetLemmatizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def CreateNgramsOnTitle(articles_df):\n",
      "    title_words = []\n",
      "    for art in articles_df['tokenized_title2']:\n",
      "        title_words.extend([word.replace(u\"\\u2018\", \"'\").replace(u\"\\u2019\", \"'\").replace(u\"\\u201c\",'\"').replace(u\"\\u201d\", '\"') for word in  art])\n",
      "    print len(title_words)\n",
      "\n",
      "    title_words_noStop_noPunct = [word for word in title_words if word.lower() not in stopwords.words('english') and word not in string.punctuation] \n",
      "    print len(title_words_noStop_noPunct)\n",
      "\n",
      "    freqD = nltk.FreqDist((title_words_noStop_noPunct))\n",
      "    top_unigs = freqD.keys()[:50]\n",
      "\n",
      "    tw_noSP_stemmed = [wnlemmatizer.lemmatize(word.lower()) for word in title_words_noStop_noPunct]\n",
      "    freqD2 = nltk.FreqDist((tw_noSP_stemmed))\n",
      "    top_unigs_stemmed = freqD2.keys()[:50]\n",
      "\n",
      "    freqD3 = nltk.FreqDist(nltk.bigrams(title_words_noStop_noPunct))\n",
      "    top_bigrams = freqD3.keys()[:50]\n",
      "\n",
      "    freqD4 = nltk.FreqDist(nltk.trigrams(title_words_noStop_noPunct))\n",
      "    top_trigrams = freqD4.keys()[:50]\n",
      "\n",
      "    freqD5 = nltk.FreqDist(nltk.ngrams(title_words_noStop_noPunct,4))\n",
      "    top_ngrams = freqD5.keys()[:50]\n",
      "    \n",
      "    title_df = DataFrame({\"top_unig_stemmed\":top_unigs_stemmed, \"top_unig\":top_unigs, \"top_bigrams\":top_bigrams, \"top_trigrams\":top_trigrams, \"top_ngrams\":top_ngrams})\n",
      "    \n",
      "    return title_df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 273
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title_df = CreateNgramsOnTitle(articles_df)\n",
      "title_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2835\n",
        "1946"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>top_bigrams</th>\n",
        "      <th>top_ngrams</th>\n",
        "      <th>top_trigrams</th>\n",
        "      <th>top_unig</th>\n",
        "      <th>top_unig_stemmed</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>             (Voter, ID)</td>\n",
        "      <td>            (AG, Nominee, Loretta, Lynch)</td>\n",
        "      <td>               (Voter, ID, Laws)</td>\n",
        "      <td>          Voter</td>\n",
        "      <td>       voter</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>             (voter, ID)</td>\n",
        "      <td>              (AG, Nominee, Lynch, Voter)</td>\n",
        "      <td>               (voter, ID, laws)</td>\n",
        "      <td>             ID</td>\n",
        "      <td>          id</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>              (ID, Laws)</td>\n",
        "      <td>  (Difference, New, Voting, Restrictions)</td>\n",
        "      <td>                (Voter, ID, Law)</td>\n",
        "      <td>          voter</td>\n",
        "      <td>         law</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>          (Voter, Fraud)</td>\n",
        "      <td>               (ID, Laws, Passed, Racist)</td>\n",
        "      <td>                (voter, ID, law)</td>\n",
        "      <td>         Voting</td>\n",
        "      <td>      voting</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>               (ID, law)</td>\n",
        "      <td>                  (ID, law, voter, fraud)</td>\n",
        "      <td>              (Lynch, Voter, ID)</td>\n",
        "      <td>           Laws</td>\n",
        "      <td>    election</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>              (ID, laws)</td>\n",
        "      <td>      (Laws, Passed, Racist, Southerners)</td>\n",
        "      <td>              (Texas, Voter, ID)</td>\n",
        "      <td>       Election</td>\n",
        "      <td>       fraud</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>    (Voter, Suppression)</td>\n",
        "      <td>              (Loretta, Lynch, Voter, ID)</td>\n",
        "      <td>     (New, Voting, Restrictions)</td>\n",
        "      <td>          Texas</td>\n",
        "      <td>        vote</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>         (Election, Day)</td>\n",
        "      <td>                 (Lynch, Voter, ID, Laws)</td>\n",
        "      <td>            (Obama, AG, Nominee)</td>\n",
        "      <td>          Fraud</td>\n",
        "      <td>         new</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>               (ID, Law)</td>\n",
        "      <td>          (Much, Difference, New, Voting)</td>\n",
        "      <td>           (Voter, Fraud, Voter)</td>\n",
        "      <td>            law</td>\n",
        "      <td>       texas</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>          (voter, fraud)</td>\n",
        "      <td>        (New, Voting, Restrictions, Make)</td>\n",
        "      <td>                (new, voter, ID)</td>\n",
        "      <td>          Obama</td>\n",
        "      <td>       state</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>        (Loretta, Lynch)</td>\n",
        "      <td>         (Nominee, Loretta, Lynch, Voter)</td>\n",
        "      <td>          (AG, Nominee, Loretta)</td>\n",
        "      <td>           laws</td>\n",
        "      <td>       obama</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>             (Obama, AG)</td>\n",
        "      <td>              (Nominee, Lynch, Voter, ID)</td>\n",
        "      <td>            (AG, Nominee, Lynch)</td>\n",
        "      <td>           2014</td>\n",
        "      <td>        2014</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>             (Photo, ID)</td>\n",
        "      <td>              (Obama, AG, Nominee, Lynch)</td>\n",
        "      <td>       (Difference, New, Voting)</td>\n",
        "      <td>           Vote</td>\n",
        "      <td>      ballot</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>           (AG, Nominee)</td>\n",
        "      <td>      (Passed, Racist, Southerners, Must)</td>\n",
        "      <td> (FRONTLINE, Answers, Questions)</td>\n",
        "      <td>            New</td>\n",
        "      <td> suppression</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>        (Election, 2014)</td>\n",
        "      <td>                  (Photo, ID, law, voter)</td>\n",
        "      <td>            (Fraud, Voter, I.D.)</td>\n",
        "      <td>         voting</td>\n",
        "      <td>         day</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>          (Lynch, Voter)</td>\n",
        "      <td>     (Racist, Southerners, Must, Stopped)</td>\n",
        "      <td>              (ID, Laws, Passed)</td>\n",
        "      <td>         Voters</td>\n",
        "      <td>       photo</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>         (Must, Stopped)</td>\n",
        "      <td>                  (Texas, Voter, ID, Law)</td>\n",
        "      <td>               (ID, Laws, Voter)</td>\n",
        "      <td>          fraud</td>\n",
        "      <td>       right</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>           (New, Voting)</td>\n",
        "      <td>              (Voter, Fraud, Voter, I.D.)</td>\n",
        "      <td>                (ID, law, voter)</td>\n",
        "      <td>           vote</td>\n",
        "      <td>  republican</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>          (Texas, Voter)</td>\n",
        "      <td>                (Voter, ID, Laws, Passed)</td>\n",
        "      <td>          (Laws, Passed, Racist)</td>\n",
        "      <td>            Day</td>\n",
        "      <td>     turnout</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>        (Voting, Rights)</td>\n",
        "      <td>                 (Voter, ID, Laws, Voter)</td>\n",
        "      <td>         (Loretta, Lynch, Voter)</td>\n",
        "      <td>    Suppression</td>\n",
        "      <td>         get</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>             (photo, ID)</td>\n",
        "      <td>               (law, voter, fraud, worst)</td>\n",
        "      <td>         (Much, Difference, New)</td>\n",
        "      <td>            GOP</td>\n",
        "      <td>        poll</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>     (Attorney, General)</td>\n",
        "      <td>                    (new, voter, ID, law)</td>\n",
        "      <td>       (Nominee, Loretta, Lynch)</td>\n",
        "      <td>             AG</td>\n",
        "      <td>         gop</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>          (Fraud, Voter)</td>\n",
        "      <td>             (..., voting, social, media)</td>\n",
        "      <td>         (Nominee, Lynch, Voter)</td>\n",
        "      <td>            Law</td>\n",
        "      <td>       video</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>           (Laws, Voter)</td>\n",
        "      <td>               (000, People, It's, First)</td>\n",
        "      <td>   (Passed, Racist, Southerners)</td>\n",
        "      <td>          Lynch</td>\n",
        "      <td>          ag</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>           (Voter, I.D.)</td>\n",
        "      <td>                 (03, 2013, Last, Minute)</td>\n",
        "      <td>                (Photo, ID, law)</td>\n",
        "      <td>            new</td>\n",
        "      <td>       lynch</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td> (Voter, Identification)</td>\n",
        "      <td>             (0600, Voter, ID, Registrar)</td>\n",
        "      <td>               (Pick, Voter, ID)</td>\n",
        "      <td>         voters</td>\n",
        "      <td>     midterm</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>          (Voter, fraud)</td>\n",
        "      <td>         (0700, Mark, Obenshain, Marines)</td>\n",
        "      <td>         (Racist, Must, Stopped)</td>\n",
        "      <td>         Racist</td>\n",
        "      <td>     problem</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>  (Voting, Restrictions)</td>\n",
        "      <td>                  (1, 8, Million, Voters)</td>\n",
        "      <td>     (Racist, Southerners, Must)</td>\n",
        "      <td>     Republican</td>\n",
        "      <td>        race</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>         (Voting, Voter)</td>\n",
        "      <td>        (1, Situation, Democrats, Racist)</td>\n",
        "      <td>    (Southerners, Must, Stopped)</td>\n",
        "      <td>       election</td>\n",
        "      <td>       woman</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>            (new, voter)</td>\n",
        "      <td>               (10, counts, voter, fraud)</td>\n",
        "      <td>             (Voter, ID, Racist)</td>\n",
        "      <td>          photo</td>\n",
        "      <td>       could</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>        (voting, rights)</td>\n",
        "      <td>                    (16, States, ASU, Ph)</td>\n",
        "      <td>              (Voter, ID, Voter)</td>\n",
        "      <td>          state</td>\n",
        "      <td>    democrat</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td>        (2014, Election)</td>\n",
        "      <td>   (1800s, Election, 2014, Ill-Concealed)</td>\n",
        "      <td>               (Voter, ID, laws)</td>\n",
        "      <td>          Could</td>\n",
        "      <td>        make</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td>    (Answers, Questions)</td>\n",
        "      <td>            (1960s, Ground, Texas, Voter)</td>\n",
        "      <td>    (Voting, Restrictions, Make)</td>\n",
        "      <td>        Loretta</td>\n",
        "      <td>     nominee</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>          (Close, Races)</td>\n",
        "      <td>        (1964, Louisiana, Literacy, test)</td>\n",
        "      <td>           (Voting, Rights, Act)</td>\n",
        "      <td>           Make</td>\n",
        "      <td>     polling</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>       (Difference, New)</td>\n",
        "      <td>    (19th, Century, Style, Balkinization)</td>\n",
        "      <td>          (Voting, Voter, fraud)</td>\n",
        "      <td>        Nominee</td>\n",
        "      <td>      racist</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>     (Election, Results)</td>\n",
        "      <td>     (1st, statewide, election, problems)</td>\n",
        "      <td>             (law, voter, fraud)</td>\n",
        "      <td>          Photo</td>\n",
        "      <td>      report</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>    (FRONTLINE, Answers)</td>\n",
        "      <td>                (2, Loretta, Lynch, Eric)</td>\n",
        "      <td>                (photo, ID, law)</td>\n",
        "      <td>          Races</td>\n",
        "      <td>        time</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>            (ID, Racist)</td>\n",
        "      <td>           (2013, Last, Minute, Decision)</td>\n",
        "      <td>       (vote, suppressed, Voter)</td>\n",
        "      <td>    Republicans</td>\n",
        "      <td>    american</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td>             (ID, Voter)</td>\n",
        "      <td>          (2014, Beyond, Horserace, It's)</td>\n",
        "      <td>             (voter, ID, battle)</td>\n",
        "      <td>        Turnout</td>\n",
        "      <td>       black</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td>            (ID, Voting)</td>\n",
        "      <td>       (2014, Coverage, Democracy, First)</td>\n",
        "      <td>           (voter, fraud, worst)</td>\n",
        "      <td>          Video</td>\n",
        "      <td>        case</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td>            (ID, battle)</td>\n",
        "      <td>   (2014, Election, George, Soros-Funded)</td>\n",
        "      <td>           (..., voting, social)</td>\n",
        "      <td>           gets</td>\n",
        "      <td>   convicted</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td>   (Justice, Department)</td>\n",
        "      <td>             (2014, Election, New, Rules)</td>\n",
        "      <td>             (000, People, It's)</td>\n",
        "      <td>        turnout</td>\n",
        "      <td>        didn</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td>           (Know, Voter)</td>\n",
        "      <td> (2014, Ill-Concealed, Prejudice, Voting)</td>\n",
        "      <td>                (03, 2013, Last)</td>\n",
        "      <td>        Ballots</td>\n",
        "      <td>       judge</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43</th>\n",
        "      <td>          (Laws, Passed)</td>\n",
        "      <td>           (2014, Media, Wrap-Up, Voters)</td>\n",
        "      <td>               (0600, Voter, ID)</td>\n",
        "      <td>          Black</td>\n",
        "      <td>        know</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44</th>\n",
        "      <td>      (Minority, Voters)</td>\n",
        "      <td>       (2014, Protecting, Voting, Rights)</td>\n",
        "      <td>         (0700, Mark, Obenshain)</td>\n",
        "      <td>         Caught</td>\n",
        "      <td>     loretta</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td>      (Much, Difference)</td>\n",
        "      <td>  (2014, Research-based, best, practices)</td>\n",
        "      <td>                 (1, 8, Million)</td>\n",
        "      <td>      Convicted</td>\n",
        "      <td>    minority</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td>           (New, Mexico)</td>\n",
        "      <td>               (2014, S.C., model, voter)</td>\n",
        "      <td>       (1, Situation, Democrats)</td>\n",
        "      <td>           I.D.</td>\n",
        "      <td>     opinion</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td>            (New, Voter)</td>\n",
        "      <td>                 (2014, Ted, Kennedy, Jr)</td>\n",
        "      <td>             (10, counts, voter)</td>\n",
        "      <td> Identification</td>\n",
        "      <td>    question</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td>      (Nominee, Loretta)</td>\n",
        "      <td>                  (2014, Voter, ID, Laws)</td>\n",
        "      <td>               (16, States, ASU)</td>\n",
        "      <td>           It's</td>\n",
        "      <td>        rule</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td>        (Nominee, Lynch)</td>\n",
        "      <td>               (2014, results, Texas, ID)</td>\n",
        "      <td>         (1800s, Election, 2014)</td>\n",
        "      <td>         Kansas</td>\n",
        "      <td>        test</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 274,
       "text": [
        "                top_bigrams                                top_ngrams  \\\n",
        "0               (Voter, ID)             (AG, Nominee, Loretta, Lynch)   \n",
        "1               (voter, ID)               (AG, Nominee, Lynch, Voter)   \n",
        "2                (ID, Laws)   (Difference, New, Voting, Restrictions)   \n",
        "3            (Voter, Fraud)                (ID, Laws, Passed, Racist)   \n",
        "4                 (ID, law)                   (ID, law, voter, fraud)   \n",
        "5                (ID, laws)       (Laws, Passed, Racist, Southerners)   \n",
        "6      (Voter, Suppression)               (Loretta, Lynch, Voter, ID)   \n",
        "7           (Election, Day)                  (Lynch, Voter, ID, Laws)   \n",
        "8                 (ID, Law)           (Much, Difference, New, Voting)   \n",
        "9            (voter, fraud)         (New, Voting, Restrictions, Make)   \n",
        "10         (Loretta, Lynch)          (Nominee, Loretta, Lynch, Voter)   \n",
        "11              (Obama, AG)               (Nominee, Lynch, Voter, ID)   \n",
        "12              (Photo, ID)               (Obama, AG, Nominee, Lynch)   \n",
        "13            (AG, Nominee)       (Passed, Racist, Southerners, Must)   \n",
        "14         (Election, 2014)                   (Photo, ID, law, voter)   \n",
        "15           (Lynch, Voter)      (Racist, Southerners, Must, Stopped)   \n",
        "16          (Must, Stopped)                   (Texas, Voter, ID, Law)   \n",
        "17            (New, Voting)               (Voter, Fraud, Voter, I.D.)   \n",
        "18           (Texas, Voter)                 (Voter, ID, Laws, Passed)   \n",
        "19         (Voting, Rights)                  (Voter, ID, Laws, Voter)   \n",
        "20              (photo, ID)                (law, voter, fraud, worst)   \n",
        "21      (Attorney, General)                     (new, voter, ID, law)   \n",
        "22           (Fraud, Voter)              (..., voting, social, media)   \n",
        "23            (Laws, Voter)                (000, People, It's, First)   \n",
        "24            (Voter, I.D.)                  (03, 2013, Last, Minute)   \n",
        "25  (Voter, Identification)              (0600, Voter, ID, Registrar)   \n",
        "26           (Voter, fraud)          (0700, Mark, Obenshain, Marines)   \n",
        "27   (Voting, Restrictions)                   (1, 8, Million, Voters)   \n",
        "28          (Voting, Voter)         (1, Situation, Democrats, Racist)   \n",
        "29             (new, voter)                (10, counts, voter, fraud)   \n",
        "30         (voting, rights)                     (16, States, ASU, Ph)   \n",
        "31         (2014, Election)    (1800s, Election, 2014, Ill-Concealed)   \n",
        "32     (Answers, Questions)             (1960s, Ground, Texas, Voter)   \n",
        "33           (Close, Races)         (1964, Louisiana, Literacy, test)   \n",
        "34        (Difference, New)     (19th, Century, Style, Balkinization)   \n",
        "35      (Election, Results)      (1st, statewide, election, problems)   \n",
        "36     (FRONTLINE, Answers)                 (2, Loretta, Lynch, Eric)   \n",
        "37             (ID, Racist)            (2013, Last, Minute, Decision)   \n",
        "38              (ID, Voter)           (2014, Beyond, Horserace, It's)   \n",
        "39             (ID, Voting)        (2014, Coverage, Democracy, First)   \n",
        "40             (ID, battle)    (2014, Election, George, Soros-Funded)   \n",
        "41    (Justice, Department)              (2014, Election, New, Rules)   \n",
        "42            (Know, Voter)  (2014, Ill-Concealed, Prejudice, Voting)   \n",
        "43           (Laws, Passed)            (2014, Media, Wrap-Up, Voters)   \n",
        "44       (Minority, Voters)        (2014, Protecting, Voting, Rights)   \n",
        "45       (Much, Difference)   (2014, Research-based, best, practices)   \n",
        "46            (New, Mexico)                (2014, S.C., model, voter)   \n",
        "47             (New, Voter)                  (2014, Ted, Kennedy, Jr)   \n",
        "48       (Nominee, Loretta)                   (2014, Voter, ID, Laws)   \n",
        "49         (Nominee, Lynch)                (2014, results, Texas, ID)   \n",
        "\n",
        "                       top_trigrams        top_unig top_unig_stemmed  \n",
        "0                 (Voter, ID, Laws)           Voter            voter  \n",
        "1                 (voter, ID, laws)              ID               id  \n",
        "2                  (Voter, ID, Law)           voter              law  \n",
        "3                  (voter, ID, law)          Voting           voting  \n",
        "4                (Lynch, Voter, ID)            Laws         election  \n",
        "5                (Texas, Voter, ID)        Election            fraud  \n",
        "6       (New, Voting, Restrictions)           Texas             vote  \n",
        "7              (Obama, AG, Nominee)           Fraud              new  \n",
        "8             (Voter, Fraud, Voter)             law            texas  \n",
        "9                  (new, voter, ID)           Obama            state  \n",
        "10           (AG, Nominee, Loretta)            laws            obama  \n",
        "11             (AG, Nominee, Lynch)            2014             2014  \n",
        "12        (Difference, New, Voting)            Vote           ballot  \n",
        "13  (FRONTLINE, Answers, Questions)             New      suppression  \n",
        "14             (Fraud, Voter, I.D.)          voting              day  \n",
        "15               (ID, Laws, Passed)          Voters            photo  \n",
        "16                (ID, Laws, Voter)           fraud            right  \n",
        "17                 (ID, law, voter)            vote       republican  \n",
        "18           (Laws, Passed, Racist)             Day          turnout  \n",
        "19          (Loretta, Lynch, Voter)     Suppression              get  \n",
        "20          (Much, Difference, New)             GOP             poll  \n",
        "21        (Nominee, Loretta, Lynch)              AG              gop  \n",
        "22          (Nominee, Lynch, Voter)             Law            video  \n",
        "23    (Passed, Racist, Southerners)           Lynch               ag  \n",
        "24                 (Photo, ID, law)             new            lynch  \n",
        "25                (Pick, Voter, ID)          voters          midterm  \n",
        "26          (Racist, Must, Stopped)          Racist          problem  \n",
        "27      (Racist, Southerners, Must)      Republican             race  \n",
        "28     (Southerners, Must, Stopped)        election            woman  \n",
        "29              (Voter, ID, Racist)           photo            could  \n",
        "30               (Voter, ID, Voter)           state         democrat  \n",
        "31                (Voter, ID, laws)           Could             make  \n",
        "32     (Voting, Restrictions, Make)         Loretta          nominee  \n",
        "33            (Voting, Rights, Act)            Make          polling  \n",
        "34           (Voting, Voter, fraud)         Nominee           racist  \n",
        "35              (law, voter, fraud)           Photo           report  \n",
        "36                 (photo, ID, law)           Races             time  \n",
        "37        (vote, suppressed, Voter)     Republicans         american  \n",
        "38              (voter, ID, battle)         Turnout            black  \n",
        "39            (voter, fraud, worst)           Video             case  \n",
        "40            (..., voting, social)            gets        convicted  \n",
        "41              (000, People, It's)         turnout             didn  \n",
        "42                 (03, 2013, Last)         Ballots            judge  \n",
        "43                (0600, Voter, ID)           Black             know  \n",
        "44          (0700, Mark, Obenshain)          Caught          loretta  \n",
        "45                  (1, 8, Million)       Convicted         minority  \n",
        "46        (1, Situation, Democrats)            I.D.          opinion  \n",
        "47              (10, counts, voter)  Identification         question  \n",
        "48                (16, States, ASU)            It's             rule  \n",
        "49          (1800s, Election, 2014)          Kansas             test  "
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(title_df[\"top_bigrams\"][0][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "[u'voter', u'id']"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getBisAndTrisForUnigram(top_unigs,top_bigrams,top_trigrams):\n",
      "    finallist ={}\n",
      "\n",
      "    for word,count in top_unigs[:15]:\n",
      "        finallist[word] = []\n",
      "        for bigram,count in top_bigrams[:15]:\n",
      "            if word in bigram:\n",
      "                added=False\n",
      "                for trigram,count in top_trigrams[:25]:\n",
      "                    b1,b2 = bigram\n",
      "                    if b1.lower() in trigram.lower() and b2.lower() in trigram.low:\n",
      "                        finallist[word].append(trigram)\n",
      "                        added=True\n",
      "                if added==False:\n",
      "                    finallist[word].append(bigram)\n",
      "\n",
      "    return finallist\n",
      "\n",
      "\n",
      "        \n",
      "finallist = getBisAndTrisForUnigram(title_df[\"top_unig\"],title_df[\"top_bigrams\"],title_df[\"top_trigrams\"])\n",
      "for item in  finallist.items():\n",
      "    print item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'obama', [(u'obama', u'ag', u'nominee')])\n",
        "(u'voter', [(u'voter', u'id', u'laws'), (u'voter', u'id', u'law'), (u'texas', u'voter', u'id'), (u'lynch', u'voter', u'id'), (u'new', u'voter', u'id'), (u'case', u'voter', u'id'), (u'fraud', u'voter', u'id'), (u'get', u'voter', u'id'), (u'id', u'law', u'voter'), (u'voter', u'fraud', u'voter'), (u'fraud', u'voter', u'i.d.'), (u'voter', u'fraud', u'confirmed'), (u'fraud', u'voter', u'id'), (u'voter', u'suppression'), (u'voter', u'fraud', u'voter'), (u'fraud', u'voter', u'i.d.'), (u'voter', u'fraud', u'confirmed'), (u'fraud', u'voter', u'id'), (u'new', u'voter', u'id'), (u'texas', u'voter', u'id')])\n",
        "(u'voters', [])\n",
        "(u'day', [(u'election', u'day')])\n",
        "(u'fraud', [(u'voter', u'fraud', u'voter'), (u'fraud', u'voter', u'i.d.'), (u'voter', u'fraud', u'confirmed'), (u'fraud', u'voter', u'id'), (u'voter', u'fraud', u'voter'), (u'fraud', u'voter', u'i.d.'), (u'voter', u'fraud', u'confirmed'), (u'fraud', u'voter', u'id')])\n",
        "(u'election', [(u'election', u'day'), (u'election', u'2014')])\n",
        "(u'suppression', [(u'voter', u'suppression')])\n",
        "(u'2014', [(u'election', u'2014')])\n",
        "(u'vote', [])\n",
        "(u'new', [(u'new', u'voter', u'id')])\n",
        "(u'texas', [(u'texas', u'voter', u'id')])\n",
        "(u'voting', [(u'fix', u'voting', u'rights')])\n",
        "(u'id', [(u'voter', u'id', u'laws'), (u'voter', u'id', u'law'), (u'texas', u'voter', u'id'), (u'lynch', u'voter', u'id'), (u'new', u'voter', u'id'), (u'case', u'voter', u'id'), (u'fraud', u'voter', u'id'), (u'get', u'voter', u'id'), (u'id', u'law', u'voter'), (u'voter', u'id', u'laws'), (u'id', u'laws', u'new'), (u'id', u'laws', u'passed'), (u'voter', u'id', u'law'), (u'photo', u'id', u'law'), (u'id', u'law', u'voter'), (u'photo', u'id', u'law')])\n",
        "(u'law', [(u'voter', u'id', u'law'), (u'photo', u'id', u'law'), (u'id', u'law', u'voter')])\n",
        "(u'laws', [(u'voter', u'id', u'laws'), (u'id', u'laws', u'new'), (u'id', u'laws', u'passed')])\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTrigramsForBiGrams(top_bigrams,top_trigrams):\n",
      "    finallist ={}\n",
      "\n",
      "    for bigram,count in top_bigrams[:15]:\n",
      "        finallist[bigram] = []\n",
      "        for trigram,count in top_trigrams[:30]:\n",
      "            b1,b2 = bigram\n",
      "            if b1 in trigram and b2 in trigram:\n",
      "                finallist[bigram].append(trigram)\n",
      "    return finallist\n",
      "    \n",
      "        \n",
      "finallist = getTrigramsForBiGrams(title_df[\"top_bigrams\"],title_df[\"top_trigrams\"])\n",
      "for item in  finallist.items():\n",
      "    print item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "((u'election', u'2014'), [])\n",
        "((u'loretta', u'lynch'), [(u'loretta', u'lynch', u'voter')])\n",
        "((u'ag', u'nominee'), [(u'obama', u'ag', u'nominee'), (u'ag', u'nominee', u'loretta'), (u'ag', u'nominee', u'lynch')])\n",
        "((u'voter', u'fraud'), [(u'voter', u'fraud', u'voter'), (u'fraud', u'voter', u'i.d.'), (u'voter', u'fraud', u'confirmed'), (u'fraud', u'voter', u'id'), (u'law', u'voter', u'fraud')])\n",
        "((u'voter', u'suppression'), [])\n",
        "((u'voting', u'rights'), [(u'fix', u'voting', u'rights')])\n",
        "((u'texas', u'voter'), [(u'texas', u'voter', u'id')])\n",
        "((u'id', u'laws'), [(u'voter', u'id', u'laws'), (u'id', u'laws', u'new'), (u'id', u'laws', u'passed'), (u'id', u'laws', u'voter')])\n",
        "((u'election', u'day'), [])\n",
        "((u'photo', u'id'), [(u'photo', u'id', u'law')])\n",
        "((u'voter', u'id'), [(u'voter', u'id', u'laws'), (u'voter', u'id', u'law'), (u'texas', u'voter', u'id'), (u'lynch', u'voter', u'id'), (u'new', u'voter', u'id'), (u'case', u'voter', u'id'), (u'fraud', u'voter', u'id'), (u'get', u'voter', u'id'), (u'id', u'law', u'voter'), (u'id', u'laws', u'voter')])\n",
        "((u'obama', u'ag'), [(u'obama', u'ag', u'nominee')])\n",
        "((u'fraud', u'voter'), [(u'voter', u'fraud', u'voter'), (u'fraud', u'voter', u'i.d.'), (u'voter', u'fraud', u'confirmed'), (u'fraud', u'voter', u'id'), (u'law', u'voter', u'fraud')])\n",
        "((u'new', u'voter'), [(u'new', u'voter', u'id')])\n",
        "((u'id', u'law'), [(u'voter', u'id', u'law'), (u'photo', u'id', u'law'), (u'id', u'law', u'voter')])\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTrisAndNgramsForBiGrams(top_bigrams,top_trigrams,top_ngrams):\n",
      "    finallist ={}\n",
      "    for b1,b2 in top_bigrams[:15]:\n",
      "        finallist[(b1,b2)] = []\n",
      "        for t1,t2,t3 in top_trigrams[:30]:\n",
      "            added=False\n",
      "#             b1,b2 = bigram\n",
      "#             t1,t2,t3 = trigram\n",
      "            if b1.lower() in [t1.lower(),t2.lower(),t3.lower()] and b2.lower() in [t1.lower(),t2.lower(),t3.lower()]:\n",
      "                \n",
      "                for ngram in top_ngrams[:30]:\n",
      "                    ngramstring = \" \".join(ngram)\n",
      "                    if t1.lower() in ngramstring.lower() and t2.lower() in ngramstring.lower() and t3.lower() in ngramstring.lower():\n",
      "                        finallist[(b1,b2)].append(ngram)\n",
      "                        added = True\n",
      "                if added == False:        \n",
      "                    finallist[(b1,b2)].append((t1,t2,t3))\n",
      "    return finallist\n",
      "keywords =  getTrisAndNgramsForBiGrams(title_df[\"top_bigrams\"],title_df[\"top_trigrams\"],title_df[\"top_ngrams\"])           \n",
      "finallist = getTrisAndNgramsForBiGrams(title_df[\"top_bigrams\"],title_df[\"top_trigrams\"],title_df[\"top_ngrams\"])\n",
      "for item in  finallist.items():\n",
      "    print item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "((u'Obama', u'AG'), [(u'Obama', u'AG', u'Nominee', u'Lynch')])\n",
        "((u'Loretta', u'Lynch'), [(u'Loretta', u'Lynch', u'Voter', u'ID'), (u'Nominee', u'Loretta', u'Lynch', u'Voter'), (u'AG', u'Nominee', u'Loretta', u'Lynch'), (u'Nominee', u'Loretta', u'Lynch', u'Voter')])\n",
        "((u'ID', u'Laws'), [(u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'ID', u'Laws', u'Passed', u'Racist'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter')])\n",
        "((u'Voter', u'Fraud'), [(u'ID', u'law', u'voter', u'fraud'), (u'Voter', u'Fraud', u'Voter', u'I.D.'), (u'law', u'voter', u'fraud', u'worst'), (u'10', u'counts', u'voter', u'fraud'), (u'Voter', u'Fraud', u'Voter', u'I.D.')])\n",
        "((u'Voter', u'Suppression'), [])\n",
        "((u'AG', u'Nominee'), [(u'Obama', u'AG', u'Nominee', u'Lynch'), (u'AG', u'Nominee', u'Loretta', u'Lynch'), (u'AG', u'Nominee', u'Loretta', u'Lynch'), (u'AG', u'Nominee', u'Lynch', u'Voter'), (u'Obama', u'AG', u'Nominee', u'Lynch')])\n",
        "((u'ID', u'laws'), [(u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'ID', u'Laws', u'Passed', u'Racist'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter')])\n",
        "((u'Election', u'2014'), [])\n",
        "((u'Election', u'Day'), [])\n",
        "((u'Voter', u'ID'), [(u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'Loretta', u'Lynch', u'Voter', u'ID'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Nominee', u'Lynch', u'Voter', u'ID'), (u'Texas', u'Voter', u'ID', u'Law'), (u'new', u'voter', u'ID', u'law'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'Pick', u'Voter', u'ID'), (u'Voter', u'ID', u'Racist')])\n",
        "((u'Photo', u'ID'), [(u'Photo', u'ID', u'law', u'voter')])\n",
        "((u'voter', u'ID'), [(u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'Loretta', u'Lynch', u'Voter', u'ID'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Nominee', u'Lynch', u'Voter', u'ID'), (u'Texas', u'Voter', u'ID', u'Law'), (u'new', u'voter', u'ID', u'law'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'Pick', u'Voter', u'ID'), (u'Voter', u'ID', u'Racist')])\n",
        "((u'ID', u'Law'), [(u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'Photo', u'ID', u'law', u'voter')])\n",
        "((u'voter', u'fraud'), [(u'ID', u'law', u'voter', u'fraud'), (u'Voter', u'Fraud', u'Voter', u'I.D.'), (u'law', u'voter', u'fraud', u'worst'), (u'10', u'counts', u'voter', u'fraud'), (u'Voter', u'Fraud', u'Voter', u'I.D.')])\n",
        "((u'ID', u'law'), [(u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'ID', u'law', u'voter', u'fraud'), (u'Lynch', u'Voter', u'ID', u'Laws'), (u'Photo', u'ID', u'law', u'voter'), (u'Texas', u'Voter', u'ID', u'Law'), (u'Voter', u'ID', u'Laws', u'Passed'), (u'Voter', u'ID', u'Laws', u'Voter'), (u'new', u'voter', u'ID', u'law'), (u'Photo', u'ID', u'law', u'voter')])\n"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running it against other datasets"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "#Gamergate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gamergate = readFilestoList(\"C:\\Users\\st.johns\\Desktop\\\\GamerGate\\\\GamerGate\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 317
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diction_gamergate = jsonToDict(gamergate)\n",
      "articles_df_gamergate = tokenizeDictionaryContentToDf(diction_gamergate)\n",
      "# articles_df_gamergate.head(25)\n",
      "articles_df_gamergate = docsIntoSents('article', articles_df_gamergate)\n",
      "articles_df_gamergate = sentsIntoTokens('sent_tokenized', articles_df_gamergate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 324
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "title_df_gamergate = CreateNgramsOnTitle(articles_df_gamergate)\n",
      "title_df_gamergate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3416\n",
        "2162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>top_bigrams</th>\n",
        "      <th>top_ngrams</th>\n",
        "      <th>top_trigrams</th>\n",
        "      <th>top_unig</th>\n",
        "      <th>top_unig_stemmed</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>            (Grand, Theft)</td>\n",
        "      <td>                     (Grand, Theft, Auto, 5)</td>\n",
        "      <td>                (Grand, Theft, Auto)</td>\n",
        "      <td>  GamerGate</td>\n",
        "      <td>  gamergate</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>             (Theft, Auto)</td>\n",
        "      <td>                     (Grand, Theft, Auto, V)</td>\n",
        "      <td>                    (Theft, Auto, 5)</td>\n",
        "      <td>     Target</td>\n",
        "      <td>       game</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>                  (GTA, V)</td>\n",
        "      <td>           (25, Invisible, Benefits, Gaming)</td>\n",
        "      <td>                    (Theft, Auto, V)</td>\n",
        "      <td>  Australia</td>\n",
        "      <td>     target</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>                 (Auto, 5)</td>\n",
        "      <td>         (Invisible, Benefits, Gaming, Male)</td>\n",
        "      <td>       (Invisible, Benefits, Gaming)</td>\n",
        "      <td>          V</td>\n",
        "      <td>  australia</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>       (Target, Australia)</td>\n",
        "      <td>                 (pulls, Grand, Theft, Auto)</td>\n",
        "      <td>           (25, Invisible, Benefits)</td>\n",
        "      <td>        GTA</td>\n",
        "      <td>          v</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>                 (Auto, V)</td>\n",
        "      <td>   (20th, Anniversary, Edition, PlayStation)</td>\n",
        "      <td>            (Benefits, Gaming, Male)</td>\n",
        "      <td>       Auto</td>\n",
        "      <td>        gta</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>                  (GTA, 5)</td>\n",
        "      <td>                  (5, Back, Target, Shelves)</td>\n",
        "      <td>             (Gamergate, done, ruin)</td>\n",
        "      <td>      Grand</td>\n",
        "      <td>       auto</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>              (Zoe, Quinn)</td>\n",
        "      <td>      (Anniversary, Edition, PlayStation, 4)</td>\n",
        "      <td>          (Target, Australia, pulls)</td>\n",
        "      <td>      Theft</td>\n",
        "      <td>      grand</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>       (Anita, Sarkeesian)</td>\n",
        "      <td>            (Australia, pulls, Grand, Theft)</td>\n",
        "      <td>                  (Tweets, per, day)</td>\n",
        "      <td>          5</td>\n",
        "      <td>      theft</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>        (Benefits, Gaming)</td>\n",
        "      <td>                     (Auto, 5, Back, Target)</td>\n",
        "      <td>               (pulls, Grand, Theft)</td>\n",
        "      <td>  Gamergate</td>\n",
        "      <td>          5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>     (Invisible, Benefits)</td>\n",
        "      <td>          (Back, Target, Shelves, Australia)</td>\n",
        "      <td>        (20th, Anniversary, Edition)</td>\n",
        "      <td>     Gaming</td>\n",
        "      <td>     gaming</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>           (25, Invisible)</td>\n",
        "      <td>              (Dev, Reneges, Plan, Withhold)</td>\n",
        "      <td>                   (5, Back, Target)</td>\n",
        "      <td>      Kmart</td>\n",
        "      <td>      shelf</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>             (Brianna, Wu)</td>\n",
        "      <td>          (GamerGate, Harasses, Brianna, Wu)</td>\n",
        "      <td> (Anniversary, Edition, PlayStation)</td>\n",
        "      <td>  gamergate</td>\n",
        "      <td>      video</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>            (Gaming, Male)</td>\n",
        "      <td>           (Gamergate, done, ruin, people's)</td>\n",
        "      <td>           (Australia, pulls, Grand)</td>\n",
        "      <td>      Games</td>\n",
        "      <td> censorship</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>      (Shelves, Australia)</td>\n",
        "      <td>                 (Indie, Dev, Reneges, Plan)</td>\n",
        "      <td>                     (Auto, 5, Back)</td>\n",
        "      <td>        ...</td>\n",
        "      <td>      kmart</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>        (Australia, pulls)</td>\n",
        "      <td>               (Plan, Withhold, Steam, Keys)</td>\n",
        "      <td>             (Back, Target, Shelves)</td>\n",
        "      <td> censorship</td>\n",
        "      <td>        ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>               (BGotD, 12)</td>\n",
        "      <td>                   (Put, Grand, Theft, Auto)</td>\n",
        "      <td>                (Dev, Reneges, Plan)</td>\n",
        "      <td>    shelves</td>\n",
        "      <td>  interview</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>         (Gamergate, done)</td>\n",
        "      <td>              (Quinn, Gamergate, done, ruin)</td>\n",
        "      <td>           (Edition, PlayStation, 4)</td>\n",
        "      <td>       2014</td>\n",
        "      <td>       2014</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>              (Star, Wars)</td>\n",
        "      <td>            (Reneges, Plan, Withhold, Steam)</td>\n",
        "      <td>                   (GTA, V, shelves)</td>\n",
        "      <td>         25</td>\n",
        "      <td>         25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>             (Steam, Keys)</td>\n",
        "      <td>        (Steam, Keys, GamerGate, Supporters)</td>\n",
        "      <td>      (GamerGate, Harasses, Brianna)</td>\n",
        "      <td>      Anita</td>\n",
        "      <td>      anita</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>             (Tweets, per)</td>\n",
        "      <td>           (Target, Australia, pulls, Grand)</td>\n",
        "      <td>             (Harasses, Brianna, Wu)</td>\n",
        "      <td>       Game</td>\n",
        "      <td>        day</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>              (V, shelves)</td>\n",
        "      <td>                      (Theft, Auto, 5, Back)</td>\n",
        "      <td>               (I'm, sexist, mother)</td>\n",
        "      <td>      Quinn</td>\n",
        "      <td>       it's</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>            (Video, Games)</td>\n",
        "      <td>               (Tweets, per, day, gamergate)</td>\n",
        "      <td>               (Indie, Dev, Reneges)</td>\n",
        "      <td>      Video</td>\n",
        "      <td> journalism</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>              (done, ruin)</td>\n",
        "      <td>              (Withdraw, Grand, Theft, Auto)</td>\n",
        "      <td>       (Keys, GamerGate, Supporters)</td>\n",
        "      <td>       game</td>\n",
        "      <td>        new</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>           (game, shelves)</td>\n",
        "      <td>          (Withhold, Steam, Keys, GamerGate)</td>\n",
        "      <td>             (Plan, Withhold, Steam)</td>\n",
        "      <td>     gaming</td>\n",
        "      <td>     people</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>    (gamergate, GamerGate)</td>\n",
        "      <td>               (Zoe, Quinn, Gamergate, done)</td>\n",
        "      <td>                    (Pulled, GTA, V)</td>\n",
        "      <td> Australian</td>\n",
        "      <td>       pull</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>               (http, www)</td>\n",
        "      <td>               (done, ruin, people's, lives)</td>\n",
        "      <td>                 (Put, Grand, Theft)</td>\n",
        "      <td>    Edition</td>\n",
        "      <td>     pulled</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>                (per, day)</td>\n",
        "      <td>         (game, encourages, players, commit)</td>\n",
        "      <td>            (Quinn, Gamergate, done)</td>\n",
        "      <td>       Male</td>\n",
        "      <td>      quinn</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>            (pulls, Grand)</td>\n",
        "      <td>           (game, shelves, sexual, violence)</td>\n",
        "      <td>           (Reneges, Plan, Withhold)</td>\n",
        "      <td>     Pulled</td>\n",
        "      <td>       stop</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>        (sexual, violence)</td>\n",
        "      <td>            (per, day, gamergate, gamergate)</td>\n",
        "      <td>              (Rock, Paper, Shotgun)</td>\n",
        "      <td>    Shelves</td>\n",
        "      <td>      tweet</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>       (20th, Anniversary)</td>\n",
        "      <td>    (shelves, sexual, violence, controversy)</td>\n",
        "      <td>            (Steam, Keys, GamerGate)</td>\n",
        "      <td>        Zoe</td>\n",
        "      <td>   violence</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td>                 (5, Back)</td>\n",
        "      <td>         ($15, won't, hotwheels, explicitly)</td>\n",
        "      <td>               (Target, Kmart, pull)</td>\n",
        "      <td>        com</td>\n",
        "      <td> australian</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td>               (5, Target)</td>\n",
        "      <td>            ($40, 892, Kickstarter, project)</td>\n",
        "      <td>        (Target, Shelves, Australia)</td>\n",
        "      <td>   violence</td>\n",
        "      <td>       back</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>           (Also, Pulling)</td>\n",
        "      <td>          (..., Anti-GG, Narratives, anyone)</td>\n",
        "      <td>            (Withdraw, Grand, Theft)</td>\n",
        "      <td>         12</td>\n",
        "      <td>    benefit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>    (Anniversary, Edition)</td>\n",
        "      <td>             (..., Gamergate, FemFreq, Devi)</td>\n",
        "      <td>             (Withhold, Steam, Keys)</td>\n",
        "      <td>   Benefits</td>\n",
        "      <td>        com</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>    (Australian, Retailer)</td>\n",
        "      <td>                     (..., I'd, rather, see)</td>\n",
        "      <td>             (Zoe, Quinn, Gamergate)</td>\n",
        "      <td>        I'm</td>\n",
        "      <td>      could</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>            (Back, Target)</td>\n",
        "      <td>          (..., People, petitioning, Target)</td>\n",
        "      <td>         (day, gamergate, gamergate)</td>\n",
        "      <td>  Invisible</td>\n",
        "      <td>    edition</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>           (Brad, Wardell)</td>\n",
        "      <td>         (..., Possible, conflict, interest)</td>\n",
        "      <td>              (done, ruin, people's)</td>\n",
        "      <td> Journalism</td>\n",
        "      <td>        get</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td>          (David, Gallant)</td>\n",
        "      <td>                       (..., Well, Shit, 25)</td>\n",
        "      <td>       (encourages, players, commit)</td>\n",
        "      <td> Sarkeesian</td>\n",
        "      <td>         gg</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td>            (Dev, Reneges)</td>\n",
        "      <td>          (..., http, www, rockpapershotgun)</td>\n",
        "      <td>         (game, encourages, players)</td>\n",
        "      <td>      games</td>\n",
        "      <td>         go</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td>    (Edition, PlayStation)</td>\n",
        "      <td>                  (..., sucking, free, time)</td>\n",
        "      <td>             (game, shelves, sexual)</td>\n",
        "      <td>     people</td>\n",
        "      <td>  invisible</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td> (Endorsements, YouTubers)</td>\n",
        "      <td>              (000, Signatures, Single, Day)</td>\n",
        "      <td>               (per, day, gamergate)</td>\n",
        "      <td>      pulls</td>\n",
        "      <td>       male</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td>     (Feminist, Frequency)</td>\n",
        "      <td>         (000, Users, Hacked, Whistleblower)</td>\n",
        "      <td>             (ruin, people's, lives)</td>\n",
        "      <td>          r</td>\n",
        "      <td>        zoe</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43</th>\n",
        "      <td>              (GAMES, ART)</td>\n",
        "      <td> (01, the-monday-papers-4, Challenge, Anita)</td>\n",
        "      <td>     (sexual, violence, controversy)</td>\n",
        "      <td>          4</td>\n",
        "      <td>         12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44</th>\n",
        "      <td>    (GamerGate, Blacklist)</td>\n",
        "      <td>                     (03, 12, New, conflitc)</td>\n",
        "      <td>         (shelves, sexual, violence)</td>\n",
        "      <td>    Brianna</td>\n",
        "      <td>        dev</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td>        (GamerGate, Check)</td>\n",
        "      <td>              (03, 2014, Jasperge107, Grand)</td>\n",
        "      <td>                 (www, youtube, com)</td>\n",
        "      <td>         GG</td>\n",
        "      <td>  developer</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td>     (GamerGate, Harasses)</td>\n",
        "      <td>    (09, 01, the-monday-papers-4, Challenge)</td>\n",
        "      <td>             ($15, won't, hotwheels)</td>\n",
        "      <td>      Gamer</td>\n",
        "      <td>   feminist</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td>   (GamerGate, Supporters)</td>\n",
        "      <td>                    (1, 2014, Samsung, Rock)</td>\n",
        "      <td>             ($40, 892, Kickstarter)</td>\n",
        "      <td>      Indie</td>\n",
        "      <td>       free</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td>   (GamerGate, supporters)</td>\n",
        "      <td>              (100, Ways, Anita, Sarkeesian)</td>\n",
        "      <td>          (..., Anti-GG, Narratives)</td>\n",
        "      <td>       It's</td>\n",
        "      <td>       girl</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td>       (Games, Journalism)</td>\n",
        "      <td>        (11vfU, GamerGate, Actually, ethics)</td>\n",
        "      <td>           (..., Gamergate, FemFreq)</td>\n",
        "      <td>        New</td>\n",
        "      <td>        i'm</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 319,
       "text": [
        "                  top_bigrams                                   top_ngrams  \\\n",
        "0              (Grand, Theft)                      (Grand, Theft, Auto, 5)   \n",
        "1               (Theft, Auto)                      (Grand, Theft, Auto, V)   \n",
        "2                    (GTA, V)            (25, Invisible, Benefits, Gaming)   \n",
        "3                   (Auto, 5)          (Invisible, Benefits, Gaming, Male)   \n",
        "4         (Target, Australia)                  (pulls, Grand, Theft, Auto)   \n",
        "5                   (Auto, V)    (20th, Anniversary, Edition, PlayStation)   \n",
        "6                    (GTA, 5)                   (5, Back, Target, Shelves)   \n",
        "7                (Zoe, Quinn)       (Anniversary, Edition, PlayStation, 4)   \n",
        "8         (Anita, Sarkeesian)             (Australia, pulls, Grand, Theft)   \n",
        "9          (Benefits, Gaming)                      (Auto, 5, Back, Target)   \n",
        "10      (Invisible, Benefits)           (Back, Target, Shelves, Australia)   \n",
        "11            (25, Invisible)               (Dev, Reneges, Plan, Withhold)   \n",
        "12              (Brianna, Wu)           (GamerGate, Harasses, Brianna, Wu)   \n",
        "13             (Gaming, Male)            (Gamergate, done, ruin, people's)   \n",
        "14       (Shelves, Australia)                  (Indie, Dev, Reneges, Plan)   \n",
        "15         (Australia, pulls)                (Plan, Withhold, Steam, Keys)   \n",
        "16                (BGotD, 12)                    (Put, Grand, Theft, Auto)   \n",
        "17          (Gamergate, done)               (Quinn, Gamergate, done, ruin)   \n",
        "18               (Star, Wars)             (Reneges, Plan, Withhold, Steam)   \n",
        "19              (Steam, Keys)         (Steam, Keys, GamerGate, Supporters)   \n",
        "20              (Tweets, per)            (Target, Australia, pulls, Grand)   \n",
        "21               (V, shelves)                       (Theft, Auto, 5, Back)   \n",
        "22             (Video, Games)                (Tweets, per, day, gamergate)   \n",
        "23               (done, ruin)               (Withdraw, Grand, Theft, Auto)   \n",
        "24            (game, shelves)           (Withhold, Steam, Keys, GamerGate)   \n",
        "25     (gamergate, GamerGate)                (Zoe, Quinn, Gamergate, done)   \n",
        "26                (http, www)                (done, ruin, people's, lives)   \n",
        "27                 (per, day)          (game, encourages, players, commit)   \n",
        "28             (pulls, Grand)            (game, shelves, sexual, violence)   \n",
        "29         (sexual, violence)             (per, day, gamergate, gamergate)   \n",
        "30        (20th, Anniversary)     (shelves, sexual, violence, controversy)   \n",
        "31                  (5, Back)          ($15, won't, hotwheels, explicitly)   \n",
        "32                (5, Target)             ($40, 892, Kickstarter, project)   \n",
        "33            (Also, Pulling)           (..., Anti-GG, Narratives, anyone)   \n",
        "34     (Anniversary, Edition)              (..., Gamergate, FemFreq, Devi)   \n",
        "35     (Australian, Retailer)                      (..., I'd, rather, see)   \n",
        "36             (Back, Target)           (..., People, petitioning, Target)   \n",
        "37            (Brad, Wardell)          (..., Possible, conflict, interest)   \n",
        "38           (David, Gallant)                        (..., Well, Shit, 25)   \n",
        "39             (Dev, Reneges)           (..., http, www, rockpapershotgun)   \n",
        "40     (Edition, PlayStation)                   (..., sucking, free, time)   \n",
        "41  (Endorsements, YouTubers)               (000, Signatures, Single, Day)   \n",
        "42      (Feminist, Frequency)          (000, Users, Hacked, Whistleblower)   \n",
        "43               (GAMES, ART)  (01, the-monday-papers-4, Challenge, Anita)   \n",
        "44     (GamerGate, Blacklist)                      (03, 12, New, conflitc)   \n",
        "45         (GamerGate, Check)               (03, 2014, Jasperge107, Grand)   \n",
        "46      (GamerGate, Harasses)     (09, 01, the-monday-papers-4, Challenge)   \n",
        "47    (GamerGate, Supporters)                     (1, 2014, Samsung, Rock)   \n",
        "48    (GamerGate, supporters)               (100, Ways, Anita, Sarkeesian)   \n",
        "49        (Games, Journalism)         (11vfU, GamerGate, Actually, ethics)   \n",
        "\n",
        "                           top_trigrams    top_unig top_unig_stemmed  \n",
        "0                  (Grand, Theft, Auto)   GamerGate        gamergate  \n",
        "1                      (Theft, Auto, 5)      Target             game  \n",
        "2                      (Theft, Auto, V)   Australia           target  \n",
        "3         (Invisible, Benefits, Gaming)           V        australia  \n",
        "4             (25, Invisible, Benefits)         GTA                v  \n",
        "5              (Benefits, Gaming, Male)        Auto              gta  \n",
        "6               (Gamergate, done, ruin)       Grand             auto  \n",
        "7            (Target, Australia, pulls)       Theft            grand  \n",
        "8                    (Tweets, per, day)           5            theft  \n",
        "9                 (pulls, Grand, Theft)   Gamergate                5  \n",
        "10         (20th, Anniversary, Edition)      Gaming           gaming  \n",
        "11                    (5, Back, Target)       Kmart            shelf  \n",
        "12  (Anniversary, Edition, PlayStation)   gamergate            video  \n",
        "13            (Australia, pulls, Grand)       Games       censorship  \n",
        "14                      (Auto, 5, Back)         ...            kmart  \n",
        "15              (Back, Target, Shelves)  censorship              ...  \n",
        "16                 (Dev, Reneges, Plan)     shelves        interview  \n",
        "17            (Edition, PlayStation, 4)        2014             2014  \n",
        "18                    (GTA, V, shelves)          25               25  \n",
        "19       (GamerGate, Harasses, Brianna)       Anita            anita  \n",
        "20              (Harasses, Brianna, Wu)        Game              day  \n",
        "21                (I'm, sexist, mother)       Quinn             it's  \n",
        "22                (Indie, Dev, Reneges)       Video       journalism  \n",
        "23        (Keys, GamerGate, Supporters)        game              new  \n",
        "24              (Plan, Withhold, Steam)      gaming           people  \n",
        "25                     (Pulled, GTA, V)  Australian             pull  \n",
        "26                  (Put, Grand, Theft)     Edition           pulled  \n",
        "27             (Quinn, Gamergate, done)        Male            quinn  \n",
        "28            (Reneges, Plan, Withhold)      Pulled             stop  \n",
        "29               (Rock, Paper, Shotgun)     Shelves            tweet  \n",
        "30             (Steam, Keys, GamerGate)         Zoe         violence  \n",
        "31                (Target, Kmart, pull)         com       australian  \n",
        "32         (Target, Shelves, Australia)    violence             back  \n",
        "33             (Withdraw, Grand, Theft)          12          benefit  \n",
        "34              (Withhold, Steam, Keys)    Benefits              com  \n",
        "35              (Zoe, Quinn, Gamergate)         I'm            could  \n",
        "36          (day, gamergate, gamergate)   Invisible          edition  \n",
        "37               (done, ruin, people's)  Journalism              get  \n",
        "38        (encourages, players, commit)  Sarkeesian               gg  \n",
        "39          (game, encourages, players)       games               go  \n",
        "40              (game, shelves, sexual)      people        invisible  \n",
        "41                (per, day, gamergate)       pulls             male  \n",
        "42              (ruin, people's, lives)           r              zoe  \n",
        "43      (sexual, violence, controversy)           4               12  \n",
        "44          (shelves, sexual, violence)     Brianna              dev  \n",
        "45                  (www, youtube, com)          GG        developer  \n",
        "46              ($15, won't, hotwheels)       Gamer         feminist  \n",
        "47              ($40, 892, Kickstarter)       Indie             free  \n",
        "48           (..., Anti-GG, Narratives)        It's             girl  \n",
        "49            (..., Gamergate, FemFreq)         New              i'm  "
       ]
      }
     ],
     "prompt_number": 319
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "keyterms_gamergate = getTrisAndNgramsForBiGrams(title_df_gamergate[\"top_bigrams\"],title_df_gamergate[\"top_trigrams\"],title_df_gamergate[\"top_ngrams\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 320
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print keyterms_gamergate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{(u'Shelves', u'Australia'): [], (u'25', u'Invisible'): [(u'25', u'Invisible', u'Benefits', u'Gaming')], (u'Anita', u'Sarkeesian'): [], (u'Auto', u'5'): [(u'Grand', u'Theft', u'Auto', u'5'), (u'Theft', u'Auto', u'5', u'Back'), (u'Auto', u'5', u'Back', u'Target'), (u'Theft', u'Auto', u'5', u'Back')], (u'GTA', u'V'): [(u'GTA', u'V', u'shelves'), (u'Pulled', u'GTA', u'V')], (u'Grand', u'Theft'): [(u'Grand', u'Theft', u'Auto', u'5'), (u'Grand', u'Theft', u'Auto', u'V'), (u'pulls', u'Grand', u'Theft', u'Auto'), (u'Put', u'Grand', u'Theft', u'Auto'), (u'Withdraw', u'Grand', u'Theft', u'Auto'), (u'pulls', u'Grand', u'Theft', u'Auto'), (u'Australia', u'pulls', u'Grand', u'Theft'), (u'Put', u'Grand', u'Theft', u'Auto')], (u'Gaming', u'Male'): [(u'Invisible', u'Benefits', u'Gaming', u'Male')], (u'Auto', u'V'): [(u'Grand', u'Theft', u'Auto', u'V')], (u'Theft', u'Auto'): [(u'Grand', u'Theft', u'Auto', u'5'), (u'Grand', u'Theft', u'Auto', u'V'), (u'pulls', u'Grand', u'Theft', u'Auto'), (u'Put', u'Grand', u'Theft', u'Auto'), (u'Withdraw', u'Grand', u'Theft', u'Auto'), (u'Grand', u'Theft', u'Auto', u'5'), (u'Theft', u'Auto', u'5', u'Back'), (u'Grand', u'Theft', u'Auto', u'V')], (u'Zoe', u'Quinn'): [], (u'Invisible', u'Benefits'): [(u'25', u'Invisible', u'Benefits', u'Gaming'), (u'Invisible', u'Benefits', u'Gaming', u'Male'), (u'25', u'Invisible', u'Benefits', u'Gaming')], (u'Benefits', u'Gaming'): [(u'25', u'Invisible', u'Benefits', u'Gaming'), (u'Invisible', u'Benefits', u'Gaming', u'Male'), (u'Invisible', u'Benefits', u'Gaming', u'Male')], (u'Brianna', u'Wu'): [(u'GamerGate', u'Harasses', u'Brianna', u'Wu')], (u'GTA', u'5'): [], (u'Target', u'Australia'): [(u'Target', u'Australia', u'pulls', u'Grand')]}\n"
       ]
      }
     ],
     "prompt_number": 330
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentences_gamergate = GetSentencesBasedOnTerms(articles_df_gamergate,keyterms_gamergate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 325
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key in sentences_gamergate.keys():\n",
      "    print key, len(sentences_gamergate[key])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'Shelves', u'Australia') 15\n",
        "(u'25', u'Invisible') 2\n",
        "(u'Anita', u'Sarkeesian') 43\n",
        "(u'Auto', u'5') 20\n",
        "(u'GTA', u'V') 17\n",
        "(u'Grand', u'Theft') 73\n",
        "(u'Gaming', u'Male') 3\n",
        "(u'Auto', u'V') 68\n",
        "(u'Theft', u'Auto') 73\n",
        "(u'Zoe', u'Quinn') 80\n",
        "(u'Invisible', u'Benefits') 3\n",
        "(u'Benefits', u'Gaming') 3\n",
        "(u'Brianna', u'Wu') 0\n",
        "(u'GTA', u'5') 32\n",
        "(u'Target', u'Australia') 0\n"
       ]
      }
     ],
     "prompt_number": 331
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyphrases_gamergate = GetFinalListOfChunks(sentences_gamergate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 336
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print keyphrases_gamergate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'GameCity festival', u'Eron Gjoni', u'significant review', u'\" mature', u'Brianna Wu', u'Brandon Boyer', u'Tropes vs Women', u'\" Grand Theft Auto V \"', u'video game encourages players', u'Anita Sarkeesian', u'majority view', u'women survivors', u'misogynistic GTA', u'online petition', u'social media', u'25 Invisible Benefits', u'Please Target', u'video game Grand Theft Auto V ( GTA V )', u'Phil Fish', u'Jim Sterling', u'sex industry', u'org p target-withdraw-grand-theft-auto-5-this-sickening-game-encourages-players-to-commit-sexual-violence-and-kill-women', u'\" Gamers', u'store shelves', u'Tim Schafer', u'2014 The Game Developers Choice awards', u') get Grand Theft Auto', u'original deceptive petition', u'Several retailers', u'selling GTA5', u'Grand Theft Auto Games Kmart', u'groundbreaking entertainment properties', u'Eron s', u'au medias', u\"game's depiction\", u'bomb threats', u'press release', u'2014 Target Australia', u'Grand Theft Auto IV', u'2013 Zoe Quinn releases Depression Quest', u'horrific violence', u'\" open-world', u'kill women', u'GTA series', u'org Petition', u'San Andreas \"', u'( Link', u'sexual content', u'Video Games producer Jonathan McIntosh', u'many hit titles', u'Gaming While Male \"', u'strong feedback', u'controversial Tropes', u'female characters', u'female gamers', u\"Target's response\"]\n"
       ]
      }
     ],
     "prompt_number": 361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunksbyarticle = GetChunksListForArticle(keyphrases_gamergate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 338
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abr_dictionary = CreateAbbreviationsDictionary(articles_df_gamergate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "360\n"
       ]
      }
     ],
     "prompt_number": 356
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for kp in keyphrases_gamergate:\n",
      "    for term in kp:\n",
      "        if term in abr_dictionary:\n",
      "            val = abr_dictionary[term]\n",
      "            term.replace"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 360
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting sentences based on the ngrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetSentencesBasedOnTerms(articles_df,keywords):\n",
      "    \n",
      "    finalsents ={}\n",
      "    #list of keywords\n",
      "    for key in keywords.keys():\n",
      "        finalsents[key] =[]\n",
      "        #article\n",
      "        for art in articles_df[\"sent_tokenized\"]:\n",
      "            #sentences\n",
      "            for sent in art:\n",
      "                #handling len == 0\n",
      "                if len(keywords[key])== 0:\n",
      "                    if key[0].lower() in sent.lower() and key[1].lower() in sent.lower():\n",
      "                        finalsents[key].append(RegTokenizeWords(sent))\n",
      "                else:\n",
      "                    #terms for each keyword\n",
      "                    for term in keywords[key]:\n",
      "                        if len(term) == 3:\n",
      "                            if term[0].lower() in sent.lower() and term[1].lower() in sent.lower() and term[2].lower() in sent.lower():\n",
      "                                finalsents[key].append(RegTokenizeWords(sent))\n",
      "                                break\n",
      "                        if len(term) == 4:\n",
      "                            if term[0].lower() in sent.lower() and term[1].lower() in sent.lower() and term[2].lower() in sent.lower() and term[3].lower() in sent.lower():\n",
      "                                finalsents[key].append(RegTokenizeWords(sent))\n",
      "                                break\n",
      "    return finalsents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 322
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "finalsents = GetSentencesBasedOnTerms(articles_df)\n",
      "for key in finalsents.keys():\n",
      "    print key, len(finalsents[key])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'Election', u'2014') 113\n",
        "(u'Obama', u'AG') 6\n",
        "(u'ID', u'laws') 382\n",
        "(u'Voter', u'Fraud') 90\n",
        "(u'Voter', u'Suppression') 87\n",
        "(u'AG', u'Nominee') 7\n",
        "(u'voter', u'ID') 618\n",
        "(u'ID', u'Laws') 382\n",
        "(u'Loretta', u'Lynch') 9\n",
        "(u'Election', u'Day') 392\n",
        "(u'Photo', u'ID') 121\n",
        "(u'Voter', u'ID') 618\n",
        "(u'ID', u'law') 612\n",
        "(u'voter', u'fraud') 90\n",
        "(u'ID', u'Law') 612\n"
       ]
      }
     ],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "string.join(finalsents[(u'Obama', u'AG')][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 297,
       "text": [
        "u'( DAILY CALLER ) President Obama\\u2019s Attorney General nominee Loretta Lynch said that voter ID laws are meant to reverse Dr. Martin Luther King , Jr.\\u2019s accomplishments and promised that DOJ lawsuits against \\u201cDeep South\\u201d states with voter ID laws will continue .'"
       ]
      }
     ],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Noun phrase chunker\n",
      "#Gets you the noun phrases\n",
      "def SlightlyModifiedChuangChunker(sent):\n",
      "    grammar = \"NP: {<CD>*(((<JJ>|<N.*>)+(<N.*>|<CD>))|<N.*>)}\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    result = cp.parse(sent)\n",
      "    return result\n",
      "\n",
      "def parseImportantNps(sent):\n",
      "    grammar = r\"\"\"\n",
      "    N-N: {<DET|CD.*>?<J*|N.*>+<N.*>} # chunk DET/Cardinal w/optional ADJ or N with proper noun\n",
      "           {<NNP.*>+<NNP.*>}             # chunk solo proper nouns only\n",
      "    \"\"\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    return cp.parse(sent)\n",
      "\n",
      "#Run the chunker against a Chunker with a specific grammar\n",
      "def ChunkASection(sents,Chunker):\n",
      "    chunkedlist = []\n",
      "    for sent in sents:\n",
      "        chunks =  Chunker(sent)\n",
      "        for chunk in chunks:\n",
      "            if(type(chunk)==type(chunks)):\n",
      "                temp =''\n",
      "                for leaf in chunk.leaves():\n",
      "                    temp += leaf[0]+' '\n",
      "                chunkedlist.append(temp.strip())\n",
      "    return chunkedlist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetChunksForEachTopic(diction, chunker):\n",
      "    finalChunksByKey = {}\n",
      "    for key in diction.keys():\n",
      "        finalChunksByKey[key] = []\n",
      "        tagged_sents = []\n",
      "        for sent in diction[key]:\n",
      "            tagged_sents.append(nltk.pos_tag(sent))\n",
      "        finalChunksByKey[key].extend(ChunkASection(tagged_sents,chunker))\n",
      "    return finalChunksByKey"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#break chunks into groups by length\n",
      "def getPhraseLengths(chunkfd):\n",
      "    lenMore = []\n",
      "    len3 = []\n",
      "    len2 = []\n",
      "    len1 = []\n",
      "    combined = {}\n",
      "    \n",
      "    for c in chunkfd:\n",
      "        if len(c.split()) > 3:\n",
      "            lenMore.append(c)\n",
      "        if len(c.split()) == 3:\n",
      "            len3.append(c)\n",
      "        if len(c.split()) == 2:\n",
      "            len2.append(c)\n",
      "        if len(c.split()) == 1:\n",
      "            len1.append(c)\n",
      "            \n",
      "    len1 = mergeTerms(len1)\n",
      "    len2 = mergeTerms(len2)\n",
      "    len3 = mergeTerms(len3)\n",
      "    lenMore = mergeTerms(lenMore)\n",
      "    \n",
      "    return mergeTerms2Lists(len2, len3), mergeTerms2Lists(len3, lenMore)\n",
      " \n",
      "    \n",
      "#merge ngrams into same length other ngrams\n",
      "def mergeTerms(list1):\n",
      "    \n",
      "    results = []\n",
      "    list2 = set(list1)\n",
      "    \n",
      "    for i in list2: \n",
      "        flag = True\n",
      "        for j in list2:\n",
      "            if i.lower() in j.lower() and i != j:\n",
      "                results.append(j)\n",
      "                flag = False\n",
      "                \n",
      "        if flag == True and i not in results: \n",
      "            results.append(i)\n",
      "    \n",
      "    return set(results)\n",
      "\n",
      "\n",
      "#merge shorter length terms into longer length terms\n",
      "def mergeTerms2Lists(shortlenlist, longerlenlist):\n",
      "    termMapping = {}\n",
      "    \n",
      "    for j in longerlenlist:\n",
      "        termMapping[j] = []\n",
      "    for i in shortlenlist: \n",
      "        flag = True\n",
      "        for j in longerlenlist:\n",
      "            if i.lower() in j.lower():\n",
      "                termMapping[j].append(i)\n",
      "                flag = False\n",
      "        if flag == True:\n",
      "            termMapping[i] = []\n",
      "    \n",
      "    return termMapping"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# finalsents = GetSentencesBasedOnTerms(articles_df)\n",
      "    \n",
      "def GetFinalListOfChunks(finalsents):\n",
      "    fc =[]\n",
      "    chunksByBigram =  GetChunksForEachTopic(finalsents,parseImportantNps)\n",
      "    for key in chunksByBigram.keys():\n",
      "        fd = nltk.FreqDist(chunksByBigram[key])\n",
      "        fc.extend([key for key,val in fd.items()[:10]])\n",
      "    _2n3, _3n4 = getPhraseLengths(fc)\n",
      "    return mergeTerms2Lists(_2n3.keys(),_3n4.keys()).keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 335
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyphrases = GetFinalListOfChunks(finalsents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 309
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for key in x.keys():\n",
      "    fdchunks = nltk.FreqDist(x[key])\n",
      "    #run the chunk scoring algo instead\n",
      "    print key, fdchunks.items()[:15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'election', u'2014') [(u'law', 17), (u'2014 election', 15), (u'2014 general election', 10), (u'voter', 10), (u'effect', 9), (u'voters', 9), (u'election', 8), (u'election 2014', 8), (u'click', 7), (u'al secretary', 6), (u'ballot', 5), (u'ballots', 5), (u'league', 5), (u'november 4', 5), (u'polls', 5)]\n",
        "(u'loretta', u'lynch') [(u'laws', 7), (u'voter', 7), (u'jr', 4), (u'deep south', 3), (u'doj lawsuits', 3), (u'dr', 3), (u'id laws', 3), (u'loretta lynch', 3), (u'martin luther', 3), (u'president obama', 3), (u's accomplishments', 3), (u'attorney general', 2), (u'attorney general nominee loretta lynch', 2), (u'minorities', 2), (u'president', 2)]\n",
        "(u'voter', u'fraud') [(u'voter', 55), (u'laws', 50), (u'voter fraud', 46), (u'fraud', 16), (u'law', 12), (u'broken', 9), (u'disenfranchisement map', 9), (u'hollow defense', 9), (u'judge postpones pa voter', 9), (u'last campaign ad', 9), (u'presidential election election expert richard hasen', 9), (u'rights act', 9), (u's commission fix', 9), (u'state ufo sightings', 9), (u'supreme court guts', 9)]\n",
        "(u'voter', u'suppression') [(u'voter suppression', 46), (u'states', 10), (u'voters', 8), (u'laws', 6), (u'suppression', 6), (u'\"', 5), (u'many hard facts', 5), (u'political hysteria', 5), (u'republicans', 5), (u'voter', 5), (u'control', 4), (u'evidence', 4), (u'polls', 4), (u'race-based voter suppression', 4), (u'study', 4)]\n",
        "(u'ag', u'nominee') [(u'news', 1), (u'outgoing ag eric holder', 1), (u'president barack obama s attorney general nominee loretta lynch', 1), (u'radical \"', 1), (u'video', 1)]\n",
        "(u'texas', u'voter') [(u'law', 52), (u'texas', 48), (u'voter', 28), (u'state', 23), (u'voters', 14), (u'texas voter', 12), (u'supreme court', 11), (u'new voter id law', 10), (u'effect', 8), (u'voter id law', 7), (u'id law', 6), (u'texas s', 6), (u'decision', 5), (u'election', 5), (u'oct', 5)]\n",
        "(u'id', u'laws') [(u'laws', 32), (u'voter', 23), (u'lynch', 10), (u'new voter id laws', 10), (u'\"', 7), (u'deep south', 7), (u'id laws', 7), (u'voter id laws', 7), (u'dr', 6), (u'people', 6), (u'speech', 6), (u'states', 6), (u'doj lawsuits', 5), (u'voters', 5), (u'country', 4)]\n",
        "(u'election', u'day') [(u'election day', 152), (u'voters', 53), (u'polls', 24), (u'election', 17), (u'voter', 17), (u'day', 16), (u'people', 14), (u'ballot', 13), (u'fraud', 12), (u'order', 11), (u'state', 11), (u'democrats', 10), (u'provisional ballot', 10), (u'law', 9), (u'year', 9)]\n",
        "(u'photo', u'id') [(u'law', 25), (u'voter', 12), (u'effect', 9), (u'texas', 9), (u'state', 8), (u'court', 7), (u'photo', 7), (u'arkansas', 5), (u'oct', 5), (u'strict photo voter', 5), (u'voter id law', 5), (u'election', 4), (u'election day', 4), (u'fact', 4), (u'part', 4)]\n",
        "(u'voter', u'id')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [(u'voter', 128), (u'law', 93), (u'laws', 88), (u'texas', 52), (u'voter fraud', 44), (u'state', 42), (u'voters', 30), (u'new voter id law', 22), (u'people', 21), (u'polls', 20), (u'supreme court', 18), (u'effect', 17), (u'year', 17), (u'\"', 16), (u'fraud', 16)]\n",
        "(u'obama', u'ag') [(u'news', 1), (u'outgoing ag eric holder', 1), (u'president barack obama s attorney general nominee loretta lynch', 1), (u'radical \"', 1), (u'video', 1)]\n",
        "(u'fraud', u'voter') [(u'voter', 55), (u'laws', 50), (u'voter fraud', 46), (u'fraud', 16), (u'law', 12), (u'broken', 9), (u'disenfranchisement map', 9), (u'hollow defense', 9), (u'judge postpones pa voter', 9), (u'last campaign ad', 9), (u'presidential election election expert richard hasen', 9), (u'rights act', 9), (u's commission fix', 9), (u'state ufo sightings', 9), (u'supreme court guts', 9)]\n",
        "(u'new', u'voter') [(u'new voter id law', 22), (u'voter', 17), (u'law', 14), (u'voters', 14), (u'laws', 12), (u'texas', 12), (u'state', 11), (u'new voter id laws', 10), (u'year', 10), (u'effect', 7), (u'first time', 6), (u'people', 6), (u'polls', 6), (u'alabama', 4), (u'country', 4)]\n",
        "(u'voting', u'rights') [(u'laws', 16), (u'voter', 16), (u'voter fraud', 16), (u'broken', 8), (u'disenfranchisement map', 8), (u'hollow defense', 8), (u'judge postpones pa voter', 8), (u'last campaign ad', 8), (u'law', 8), (u'presidential election election expert richard hasen', 8), (u'rights act', 8), (u's commission fix', 8), (u'state ufo sightings', 8), (u'supreme court guts', 8), (u'system', 8)]\n",
        "(u'id', u'law') [(u'law', 88), (u'voter', 64), (u'texas', 48), (u'state', 31), (u'laws', 24), (u'voters', 24), (u'new voter id law', 22), (u'voter fraud', 21), (u'supreme court', 16), (u'effect', 15), (u'voter id law', 15), (u'polls', 12), (u'texas voter', 12), (u'year', 11), (u'broken', 9)]\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Abbr. expander"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetShortWords(dataframe):\n",
      "    short_words=[]\n",
      "    for art in dataframe[\"tokenized_article\"]:\n",
      "        for word in art:\n",
      "            word = word.encode('ascii', errors='backslashreplace')\n",
      "            word = word.replace(\".\", \"\")\n",
      "            if len(word) < 4 and len(word)>1 and str.isupper(word):\n",
      "                short_words.append(word)\n",
      "    if short_words!=[]:\n",
      "        short_words = list(set(short_words))\n",
      "    return short_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetBigWords2(dataframe):\n",
      "    big_words=[]\n",
      "    for art in dataframe[\"tokenized_article\"]:\n",
      "        bigrams = nltk.bigrams(art)\n",
      "        for w1,w2 in bigrams:\n",
      "            w1 = w1.encode('ascii', errors='backslashreplace')\n",
      "            w2 = w2.encode('ascii', errors='backslashreplace')\n",
      "            if \".\" not in w1 and \".\" not in w2:\n",
      "                if str.isupper(str(w1)[0]) and str.isupper(str(w2)[0]) and not str.isupper(str(w1)) and not str.isupper(str(w2)):\n",
      "                    big_words.append((w1,w2))\n",
      "    return big_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetBigWords3(dataframe):\n",
      "    big_words3=[]\n",
      "    for art in dataframe[\"tokenized_article\"]:\n",
      "        trigrams = nltk.trigrams(art)\n",
      "        for w1,w2,w3 in trigrams:\n",
      "            w1 = w1.encode('ascii', errors='backslashreplace')\n",
      "            w2 = w2.encode('ascii', errors='backslashreplace')\n",
      "            w3 = w3.encode('ascii', errors='backslashreplace')\n",
      "            if \".\" not in w1 and \".\" not in w2 and \".\" not in w3:\n",
      "                if str.isupper(str(w1)[0]) and str.isupper(str(w2)[0]) and str.isupper(str(w3)[0]) and not str.isupper(str(w1)) and not str.isupper(str(w2))  and not str.isupper(str(w3)):\n",
      "                    big_words3.append((w1,w2,w3))\n",
      "    return big_words3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def CreateAbbreviationsMatch(short_words,big_words,big_words3):\n",
      "    abbrMatch = {}\n",
      "    for abbr in short_words:\n",
      "        letters = list(abbr)\n",
      "        abbrMatch[abbr] =[]\n",
      "        if len(letters) == 2:\n",
      "            expanded = big_words\n",
      "        elif len(letters) == 3:\n",
      "            expanded = big_words3\n",
      "        else:\n",
      "            #should be unreachable\n",
      "            continue\n",
      "        for term in expanded:\n",
      "            for index in range(0,len(letters)):\n",
      "                if abbr[index] != term[index][0]:\n",
      "                    break\n",
      "                if index == (len(letters)-1):\n",
      "                    abbrMatch[abbr].append(term)\n",
      "            #dedup-ing the expanded forms\n",
      "        if abbrMatch[abbr] != []:\n",
      "            fd = nltk.FreqDist(abbrMatch[abbr])\n",
      "            abbrMatch[abbr] = fd.items()[0][0]\n",
      "    return abbrMatch\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def CreateAbbreviationsDictionary(dataframe):\n",
      "    short_words = GetShortWords(dataframe)\n",
      "    big_words2 = GetBigWords2(dataframe)\n",
      "    big_words3 = GetBigWords3(dataframe)\n",
      "    return CreateAbbreviationsMatch(short_words,big_words2,big_words3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 343
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "absEx = CreateAbbreviationsDictionary(articles_df_gamergate)\n",
      "for key in absEx.keys():\n",
      "    if absEx[key]!= []:\n",
      "        print key, absEx[key]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "360\n",
        "NYC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ('New', 'York', 'City')\n",
        "FMA ('Frequently', 'Made', 'Accusations')\n",
        "UAE ('United', 'Arab', 'Emirates')\n",
        "GW ('Gaming', 'While')\n",
        "GG ('Gone', 'Girl')\n",
        "GF ('Game', 'Front')\n",
        "GA ('Game', 'Awards')\n",
        "GO ('Global', 'Offensive')\n",
        "GM ('Gawker', 'Media')\n",
        "SNL ('Saturday', 'Night', 'Live')\n",
        "FTP ('Frequency', 'Tweets', 'Polygon')\n",
        "FTW ('Farrell', 'The', 'War')\n",
        "IGF ('Indie', 'Games', 'Festival')\n",
        "FTC ('Find', 'This', 'Campaign')\n",
        "AW ('Ask', 'Women')\n",
        "ME ('Managing', 'Editor')\n",
        "MG ('Metal', 'Gear')\n",
        "MA ('Me', 'Anything\\\\u201d')\n",
        "MB ('Matt', 'Bruenig')\n",
        "MO ('Mandarin', 'Oriental')\n",
        "MN ('Morning', 'News')\n",
        "CBS ('Caged', 'Bird', 'Sings')\n",
        "RWS ('Running', 'With', 'Scissors')\n",
        "MS ('Matt', 'Stone')\n",
        "NOT ('News', 'Of', 'The')\n",
        "MY ('Milo', 'Yiannopoulos')\n",
        "FC ('First', 'Class')\n",
        "FL ('Fantasy', 'Life')\n",
        "FCC ('Federal', 'Communications', 'Commission')\n",
        "SS ('Samit', 'Sarkar')\n",
        "SW ('Star', 'Wars')\n",
        "SV ('Silicon', 'Valley')\n",
        "EDM ('Editor', 'Dallas', 'Morning')\n",
        "SO ('Scrolls', 'Online')\n",
        "CAN ('Comments', 'Angela', 'Night')\n",
        "LA ('Leigh', 'Alexander')\n",
        "LW ('Lead', 'Writer')\n",
        "GIF ('Global', 'Intelligence', 'Files')\n",
        "TFW ('Total', 'Female', 'White')\n",
        "EGM ('Electronic', 'Gaming', 'Monthly')\n",
        "RT ('Race', 'Team')\n",
        "FGM ('Female', 'Genital', 'Mutilation')\n",
        "RC ('Radio', 'City')\n",
        "SAW ('Scan', 'Another', 'Website')\n",
        "APE ('As', 'President', 'Eisenhower')\n",
        "ED ('Encyclopedia', 'Dramatica')\n",
        "EA ('Electronic', 'Arts')\n",
        "OXM ('Official', 'Xbox', 'Magazine')\n",
        "AFP ('Adult', 'Female', 'Passengers')\n",
        "II ('Inbox', 'Invites')\n",
        "IA ('In', 'August')\n",
        "RMS ('Reviews', 'Meet', 'Sophia')\n",
        "GTA ('Grand', 'Theft', 'Auto')\n",
        "BBC ('Bay', 'Bowls', 'Club')\n",
        "XD ('Xav', 'De')\n",
        "KC ('Kate', 'Cox')\n",
        "KB ('Ken', 'Burns')\n",
        "KS ('Keyboard', 'Shortcuts')\n",
        "DO ('DirectX', 'OpenGL')\n",
        "DM ('Defy', 'Media')\n",
        "AAA ('After', 'Al', 'Akhbar')\n",
        "BPD ('Borderline', 'Personality', 'Disorder')\n",
        "DC ('Developers', 'Choice')\n",
        "DR ('Danielle', 'Riendeau')\n",
        "DP ('Died', 'Percent')\n",
        "FYC ('Fine', 'Young', 'Capitalists')\n",
        "RPS ('Rock', 'Paper', 'Shotgun')\n",
        "PS ('Percent', 'Survived')\n",
        "MLP ('My', 'Little', 'Pony')\n",
        "GOT ('Global', 'Offensive', 'Trade')\n",
        "LGB ('Lesbian', 'Gay', 'Bisexual')\n",
        "QA ('Quote', 'Anyone')\n",
        "WE ('Website', 'Enter')\n",
        "WD ('Wed', 'Dec')\n",
        "WB ('What', 'Brad')\n",
        "WH ('White', 'House')\n",
        "JJ ('Joel', 'Johnson')\n",
        "GPA ('GamerGate', 'Patreon', 'Account')\n",
        "PHP ('Polytron', 'Hack', 'Phil')\n",
        "PR ('Peoples\\\\u2019', 'Rights')\n",
        "PC ('Parent', 'Company')\n",
        "PG ('Platinum', 'Games')\n",
        "PK ('Parramore', 'Kidz')\n",
        "PL ('Patrick', 'Lindsey')\n",
        "PM ('Platinum', 'Mix')\n",
        "ANY ('Am', 'Not', 'Your')\n",
        "YWU ('Yemen', 'Women', 'Union')\n",
        "DJ ('Dad', 'Jokes')\n",
        "CK ('Cassandra', 'Khaw')\n",
        "CA ('Chris', 'Avellone')\n",
        "CD ('Cherbourg', 'Died')\n",
        "SRS ('Screen', 'Ryan', 'Scott')\n",
        "CS ('Cool', 'Stuff')\n",
        "CP ('Carolyn', 'Petit')\n",
        "WAS ('When', 'Al', 'Sharpton')\n",
        "WAR ('War', 'Against', 'Rape')\n",
        "CT ('Crew', 'Total')\n",
        "DIY ('Deep', 'Into', 'You')\n",
        "VA ('Virgin', 'Airlines')\n",
        "IP ('In', 'Pakistan')\n",
        "IS ('In', 'September')\n",
        "IT ('If', 'Target')\n",
        "VP ('Various', 'Petitions')\n",
        "VS ('Visual', 'Studio')\n",
        "IM ('If', 'Marvel')\n",
        "IN ('In', 'November')\n",
        "IE ('In', 'English')\n",
        "ID ('Ireland', 'Died')\n",
        "IF ('Intelligence', 'Files')\n",
        "BE ('BBCode', 'Embed')\n",
        "BB ('Brandon', 'Boyer')\n",
        "BS ('Bowls', 'South')\n",
        "BY ('Back', 'Yard')\n",
        "ON ('Of', 'Nature')\n",
        "OK ('Orange', 'Kid')\n",
        "OH ('Online', 'Harassment')\n",
        "OF ('Operation', 'Full')\n",
        "OC ('Over', 'Censorship')\n",
        "OR ('One', 'Reviewed')\n",
        "OP ('One', 'Piece')\n",
        "HS ('Hoff', 'Sommers')\n",
        "GJP ('Game', 'Journo', 'Pros')\n",
        "HE ('Harm', 'Ethical')\n",
        "RON ('Rules', 'Of', 'Nature')\n",
        "AMA ('All', 'Minorities', 'And')\n",
        "UT ('Ultimate', 'Team')\n",
        "UP ('Ubisoft', 'Platforms')\n",
        "US ('United', 'States')\n",
        "UN ('United', 'Nations')\n",
        "UK ('Ubisoft', 'Kiev')\n",
        "IDE ('Interesting', 'Discussions', 'External')\n",
        "NJ ('New', 'Jersey')\n",
        "NO ('Nalangu', 'Ole')\n",
        "NC ('Nick', 'Chester')\n",
        "NG ('Nathan', 'Grayson')\n",
        "NY ('New', 'York')\n",
        "NZ ('New', 'Zealand\\\\u2019s')\n",
        "NP ('No', 'Participation')\n",
        "TES ('The', 'Escapist', 'Savethekitsune')\n",
        "SJW ('Social', 'Justice', 'Warriors')\n",
        "GDC ('Game', 'Developers', 'Choice')\n",
        "TWO ('The', 'Wise', 'Old')\n",
        "TX ('The', 'Xblig')\n",
        "TV ('The', 'Verge')\n",
        "TW ('The', 'Walking')\n",
        "TS ('Total', 'Survived')\n",
        "TO ('Tapped', 'Out')\n",
        "TL ('The', 'Last')\n",
        "TM ('Total', 'Male')\n",
        "TF ('The', 'Fine')\n",
        "EST ('Executive', 'Summary', 'This')\n",
        "AI ('And', 'I\\\\u2019m')\n",
        "AM ('Alexander', 'Macris')\n",
        "AN ('Angela', 'Night')\n",
        "AP ('Allistair', 'Pinsof')\n",
        "AS ('Anita', 'Sarkeesian')\n",
        "AU ('Arena', 'Ultimax')\n",
        "AT ('Ars', 'Technica')\n",
        "FPS ('First', 'Person', 'Scholar')\n",
        "AV ('Archived', 'Versions')\n",
        "PKZ ('Parramore', 'Kidz', 'Zone')\n"
       ]
      }
     ],
     "prompt_number": 355
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Get Articles that contain key phrases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyphrases"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 333,
       "text": [
        "[u'2014 election law blog',\n",
        " u'eligible voters',\n",
        " u'bogey man stories',\n",
        " u'polling place',\n",
        " u'voter registration',\n",
        " u'Disenfranchisement Map',\n",
        " u'citizenship requirement',\n",
        " u'many hard facts',\n",
        " u'government-issued photo identification',\n",
        " u'U.S. Supreme Court',\n",
        " u'State UFO Sightings Are More Common Than Voter Fraud The Hollow Defense',\n",
        " u'Voter ID Laws Will Obama',\n",
        " u'doj lawsuits',\n",
        " u'taxpayer money',\n",
        " u'strict photo voter ID law',\n",
        " u'election results',\n",
        " u'voter identification laws',\n",
        " u'Attorney General Eric Holder',\n",
        " u'al secretary',\n",
        " u'political hysteria',\n",
        " u'2014 midterm elections',\n",
        " u'Commission Fix Our Broken Voting System',\n",
        " u'new voter ID law',\n",
        " u's commission fix',\n",
        " u'Supreme Court Guts Voting Rights Act The Last Campaign Ad Ever Judge Postpones PA Voter ID Law Until After Presidential Election Election Expert Richard Hasen',\n",
        " u'poll workers',\n",
        " u'early voting',\n",
        " u'public housing',\n",
        " u'DOJ lawsuits',\n",
        " u'Deep South',\n",
        " u'radical \"',\n",
        " u'new documentary',\n",
        " u'women voters',\n",
        " u'voter-ID laws',\n",
        " u'long beach',\n",
        " u'suppress black voting',\n",
        " u'u.s. supreme court',\n",
        " u'north carolina',\n",
        " u'president obama',\n",
        " u'texas s',\n",
        " u'attorney general nominee loretta lynch',\n",
        " u'disenfranchisement map',\n",
        " u'Attorney General nominee Loretta Lynch',\n",
        " u'Election Day',\n",
        " u'deep south',\n",
        " u'President Obama',\n",
        " u'election officials',\n",
        " u'2014 general election',\n",
        " u\"texas's new voter id law\",\n",
        " u'minority voters',\n",
        " u'same-day registration',\n",
        " u'president barack obama s attorney general nominee loretta lynch',\n",
        " u'election 2014',\n",
        " u'outgoing ag eric holder',\n",
        " u'black voters',\n",
        " u'new voter id law',\n",
        " u'election fraud',\n",
        " u'Martin Luther King',\n",
        " u'2014 elections',\n",
        " u'1-800-274-8683 alabama votes lwval',\n",
        " u'federal court',\n",
        " u'election day',\n",
        " u'North Carolina',\n",
        " u'AL Secretary',\n",
        " u'Justice Department',\n",
        " u'texas voter',\n",
        " u'first time',\n",
        " u'provisional ballot',\n",
        " u'new law',\n",
        " u'new voter id laws',\n",
        " u'zero tolerance policies',\n",
        " u'race-based voter suppression',\n",
        " u's accomplishments']"
       ]
      }
     ],
     "prompt_number": 333
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetChunksListForArticle(keyphrases):\n",
      "    articleChunksList = []\n",
      "    for art in articles_df[\"article\"]:\n",
      "        articleChunksList.append([term for term in keyphrases if term in art])\n",
      "    return articleChunksList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 328
    }
   ],
   "metadata": {}
  }
 ]
}
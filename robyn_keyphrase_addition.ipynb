{
 "metadata": {
  "gist_id": "f00815cbe158a89cf35e",
  "name": "",
  "signature": "sha256:f75356d2ce1b5e886f83d5e72f686fd386b843f222b82ce57e8baae4ca1dedab"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk, string\n",
      "from nltk.corpus import stopwords, brown\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from nltk.collocations import *\n",
      "import codecs, os, json, glob\n",
      "from bs4 import BeautifulSoup\n",
      "from nltk.corpus import wordnet as wn\n",
      "from pandas import DataFrame\n",
      "import pandas as pd\n",
      "wnlemmatizer = nltk.WordNetLemmatizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Baseline Algorithm: Frequency Distribution on Unigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#freq dist function from set of corpus tokens\n",
      "\n",
      "def freqBigramsFromTokens(tokenList):\n",
      "    #modify this list based on corpus\n",
      "    punc = ['.',',', ';', '--', '(', ')', ':', '``', '\\'\\'', '?']\n",
      "    #additional words that should be treated like stopwords after initial assessment of performance\n",
      "    mod_num = ['one','two','three','four','five','first', 'second','third','fourth','fifth', \\\n",
      "               'could','should','would','might','must','will','can']\n",
      "    #concatenate stopwords, punctuation, + special modals/numbers/cardinals list\n",
      "    sw_p = nltk.corpus.stopwords.words('english') + punc + mod_num\n",
      "    wnl_lemmas = [wnlemmatizer.lemmatize(word.lower()) for word in tokenList if word.lower() not in sw_p]\n",
      "    fd = nltk.FreqDist(bigrams(wnl_lemmas))\n",
      "    top_n = fd.items()[:50]\n",
      "    top_n_vals = fd.values()[:50]\n",
      "    i = 0\n",
      "    print '%-20s' % 'WORD PAIR ', '%-20s' % 'BIGRAM COUNT'\n",
      "    for b in top_n:\n",
      "        print '%-12s' % b[0][0], '%-12s' % b[0][1], '%-16d' % top_n_vals[i]\n",
      "        i=i+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Functions Used for Reading Files from Directory, Tokenizing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#function to get string from file\n",
      "def loadCorpusAsString(pathToFile):\n",
      "    snippets = open(pathToFile, \"r\")\n",
      "    text_list = snippets.readlines()\n",
      "    snippets.close()\n",
      "    text_string = reduce(lambda x, y: x + ' ' + y.strip('\\t'), text_list)\n",
      "    return text_string\n",
      "\n",
      "\n",
      "#function to get string from file\n",
      "def loadJsonCorpusAsString(path):\n",
      "    snippets = open(path, \"r\")\n",
      "    text_list = json.loads(snippets.readlines())\n",
      "    text_string = reduce(lambda x, y: x + ' ' + y.strip('\\t'), text_list)\n",
      "    snippets.close()\n",
      "    return text_string\n",
      "\n",
      "\n",
      "#read file as unicode\n",
      "def loadCorpusAsUnicodeString(path):\n",
      "    rawtext = codecs.open(path,'r','utf-8').read()\n",
      "    return rawtext\n",
      "\n",
      "#tokenize into sentences\n",
      "def tokenizeCorpusFromTuples(title_content_tuples):\n",
      "    #tokenize into sentences\n",
      "    tokenizer = RegexpTokenizer('\\w+\\'\\w*|\\S+|[\\.!?,;:&-]') \n",
      "    '''\n",
      "    \\w+          strings of text, words\n",
      "    |            OR\n",
      "    [\\.!?,;:&-]  leave in meaningful punctuation\n",
      "    '''\n",
      "    #deal with title + contents tuples\n",
      "    docs = []\n",
      "    for i in title_content_tuples:\n",
      "        string = str(i[0]) + ' ' + str(i[1])\n",
      "        docs = docs + string\n",
      "    \n",
      "    #tokenize into words, removing punctuation\n",
      "    docs = docs.encode('iso-8859-1', 'ignore')\n",
      "    tokens = tokenizer.tokenize(docs)\n",
      "    #remove periods at end of strings, double commas, and weird double commas for more accurate FreqDist\n",
      "    tokens_clean = [t.rstrip('.').strip('\\'\\'').lstrip('``') for t in tokens]\n",
      "    return tokens_clean\n",
      "\n",
      "#tokenize into sentences\n",
      "def tokenizeCorpus(string):\n",
      "    #tokenize into sentences\n",
      "    tokenizer = RegexpTokenizer('\\w+\\'\\w*|\\S+|[\\.!?,;:&-]') \n",
      "    '''\n",
      "    \\w+          strings of text, words\n",
      "    |            OR\n",
      "    [\\.!?,;:&-]  leave in meaningful punctuation\n",
      "    '''\n",
      "    #tokenize into words, removing punctuation\n",
      "    string = string.encode('iso-8859-1', 'ignore') \n",
      "    tokens = tokenizer.tokenize(string)\n",
      "    #remove periods at end of strings, double commas, and weird double commas for more accurate FreqDist\n",
      "    tokens_clean = [t.rstrip('.').strip('\\'\\'').strip(')').strip('(').lstrip('``') for t in tokens]\n",
      "    return tokens_clean\n",
      "\n",
      "\n",
      "def htmlToTuples(filelist):\n",
      "    articles = {}\n",
      "    for f in filelist:\n",
      "        html = loadCorpusAsString(f)\n",
      "        soup = BeautifulSoup(html)\n",
      "        if soup.metadata.attrs['title'] not in articles:\n",
      "            articles[soup.metadata.attrs['title']] = soup.body.contents.pop()\n",
      "    return list(articles.iteritems())\n",
      "\n",
      "\n",
      "#read in film review corpus\n",
      "def getFreqBigramsfromFile(path):\n",
      "    corpus_string = loadCorpusAsString(path)\n",
      "    tokenized_corpus = tokenizeCorpus(corpus_string)\n",
      "    fd = freqBigramsFromTokens(tokenized_corpus)\n",
      "    return fd\n",
      "\n",
      "#read in film review corpus\n",
      "def getFreqBigramsfromCollection(file_list):\n",
      "    corpus_string = concatFilesUnicode(file_list)\n",
      "    tokenized_corpus = tokenizeCorpus(corpus_string)\n",
      "    fd = freqBigramsFromTokens(tokenized_corpus)\n",
      "    return fd\n",
      "\n",
      "#read in film review corpus\n",
      "def getFreqBigramsfromHTMLfiles(file_list):\n",
      "    title_content_tuples = htmlToTuples(file_list)\n",
      "    tokenized_corpus = tokenizeCorpusFromTuples(title_content_tuples)\n",
      "    fd = freqBigramsFromTokens(tokenized_corpus)\n",
      "    return fd\n",
      "\n",
      "#run functions separately on documents in corpus (can I pass functions as args to functions?)\n",
      "def runFunctionsOnFiles(file_list, func):\n",
      "    corpus = [loadCorpusAsString(f) for f in file_list]\n",
      "    for doc in corpus:\n",
      "        func(doc)\n",
      "        \n",
      "#from list of files, return concatenated string of all their contents        \n",
      "def concatFilesUnicode(file_list):\n",
      "    #load each file as string into list\n",
      "    corpus_list = [loadCorpusAsUnicodeString(f) for f in file_list]\n",
      "    #concatenate strings into single string\n",
      "    c = ''\n",
      "    for s in corpus_list:\n",
      "        c = c + s\n",
      "    #return string of entire corpus\n",
      "    return c\n",
      "\n",
      "def concatFiles(file_list):\n",
      "    #load each file as string into list\n",
      "    corpus_list = [loadCorpusAsString(f) for f in file_list]\n",
      "    #concatenate strings\n",
      "    c = ''\n",
      "    for s in corpus_list:\n",
      "        c = c + s\n",
      "    #return string of entire corpus\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#function to get string from file\n",
      "def loadJsonCorpusAsString(path):\n",
      "    snippets = open(path, \"r\")\n",
      "    text_list = snippets.readlines()\n",
      "    text_string = reduce(lambda x, y: x + ' ' + y.strip('\\t'), text_list)\n",
      "    snippets.close()\n",
      "    return text_string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Step 1. Read Files from Directory into List"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get list of files\n",
      "def readFilestoList(path):\n",
      "    filelist = []\n",
      "    for file in glob.glob(os.path.join(path, '*.json')):\n",
      "        filelist.append(file)\n",
      "    return filelist\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def jsonToTuples(filelist):\n",
      "    articles = []\n",
      "    for filepath in filelist:\n",
      "        with open(filepath, 'r') as f:\n",
      "            j = json.load(f)\n",
      "            if 'objects' in j.keys():\n",
      "                if 'title' in j['objects'][0]:\n",
      "                    articles.append((j['objects'][0]['title'], j['objects'][0]['text']))\n",
      "    return articles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "voterID = readFilestoList('data/voterID_clean/')  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "votID = jsonToTuples(voterID)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Step 2. Read Titles and Text into Tuple List"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Step 3. Put Titles, Content into Dataframe & Tokenize Both"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create df for titles & content\n",
      "#tokenize titles and content\n",
      "def tokenizeTitlesContentToDf(tuples):\n",
      "    articles = []\n",
      "    titles = []\n",
      "    for i in tuples:\n",
      "        articles.append(i[1])\n",
      "        titles.append(i[0])\n",
      "\n",
      "    data = {'article': articles, 'title': titles}\n",
      "    df = DataFrame(data)\n",
      "    df['tokenized_article'] = df['article'].map(nltk.word_tokenize)\n",
      "    df['tokenized_title'] = df['title'].map(nltk.word_tokenize)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# health_it_df = tokenizeTitlesContentToDf(title_content_health_it)\n",
      "df_votID = tokenizeTitlesContentToDf(votID)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>article</th>\n",
        "      <th>title</th>\n",
        "      <th>tokenized_article</th>\n",
        "      <th>tokenized_title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> This is a voter suppression tactic as capper a...</td>\n",
        "      <td> Republican Milwaukee Supervisor Sends Out Fals...</td>\n",
        "      <td> [This, is, a, voter, suppression, tactic, as, ...</td>\n",
        "      <td> [Republican, Milwaukee, Supervisor, Sends, Out...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Brennan Center for Justice\\nVoting is now unde...</td>\n",
        "      <td>   On the Ground: Texas Voter ID Troubles Continue</td>\n",
        "      <td> [Brennan, Center, for, Justice, Voting, is, no...</td>\n",
        "      <td> [On, the, Ground, :, Texas, Voter, ID, Trouble...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Democrats are Racist\\nWhen will the Black Comm...</td>\n",
        "      <td>                              Democrats are Racist</td>\n",
        "      <td> [Democrats, are, Racist, When, will, the, Blac...</td>\n",
        "      <td>                          [Democrats, are, Racist]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Hey Everyone!\\nLet's share this meme tonight a...</td>\n",
        "      <td>                                   Timeline Photos</td>\n",
        "      <td> [Hey, Everyone, !, Let, 's, share, this, meme,...</td>\n",
        "      <td>                                [Timeline, Photos]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Rumor Control - Stay tuned! We'll respond to r...</td>\n",
        "      <td>                  Rules and Information for Voters</td>\n",
        "      <td> [Rumor, Control, -, Stay, tuned, !, We, 'll, r...</td>\n",
        "      <td>            [Rules, and, Information, for, Voters]</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "                                             article  \\\n",
        "0  This is a voter suppression tactic as capper a...   \n",
        "1  Brennan Center for Justice\\nVoting is now unde...   \n",
        "2  Democrats are Racist\\nWhen will the Black Comm...   \n",
        "3  Hey Everyone!\\nLet's share this meme tonight a...   \n",
        "4  Rumor Control - Stay tuned! We'll respond to r...   \n",
        "\n",
        "                                               title  \\\n",
        "0  Republican Milwaukee Supervisor Sends Out Fals...   \n",
        "1    On the Ground: Texas Voter ID Troubles Continue   \n",
        "2                               Democrats are Racist   \n",
        "3                                    Timeline Photos   \n",
        "4                   Rules and Information for Voters   \n",
        "\n",
        "                                   tokenized_article  \\\n",
        "0  [This, is, a, voter, suppression, tactic, as, ...   \n",
        "1  [Brennan, Center, for, Justice, Voting, is, no...   \n",
        "2  [Democrats, are, Racist, When, will, the, Blac...   \n",
        "3  [Hey, Everyone, !, Let, 's, share, this, meme,...   \n",
        "4  [Rumor, Control, -, Stay, tuned, !, We, 'll, r...   \n",
        "\n",
        "                                     tokenized_title  \n",
        "0  [Republican, Milwaukee, Supervisor, Sends, Out...  \n",
        "1  [On, the, Ground, :, Texas, Voter, ID, Trouble...  \n",
        "2                           [Democrats, are, Racist]  \n",
        "3                                 [Timeline, Photos]  \n",
        "4             [Rules, and, Information, for, Voters]  "
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID['spanish_check'] = df_votID['tokenized_article'].map(nltk.FreqDist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng = df_votID[df_votID['spanish_check'].apply(lambda r: 'los' in r)==False]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(df_votID_eng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "457"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(df_votID_eng[df_votID_eng['spanish_check'].apply(lambda r: 'los' in r)==True])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#functions for tokenizing sentences\n",
      "def listToTokens(sentenceList):\n",
      "    tokenized_sents = [nltk.word_tokenize(sent.strip('(').strip(')')) for sent in sentenceList]\n",
      "    return tokenized_sents\n",
      "\n",
      "def tagTokens(tokenList):\n",
      "    tagged_sents = [nltk.pos_tag(sent) for sent in tokenList]\n",
      "    return tagged_sents\n",
      "\n",
      "def tagTitle(title):\n",
      "    tagged_title = [nltk.pos_tag(title)]\n",
      "    return tagged_title\n",
      "\n",
      "\n",
      "#functions for adding columns to df of sentence tokenized, word tokenized, and pos tagged text\n",
      "def docsIntoSents(columnname, df):\n",
      "    df['sent_tokenized'] = df[columnname].map(nltk.sent_tokenize)\n",
      "    return df\n",
      "    \n",
      "def sentsIntoTokens(columnname, df):\n",
      "    df['word_tokenized'] = df[columnname].map(listToTokens)\n",
      "    return df\n",
      "    \n",
      "def tokensPOStag(columnname, df, option='article'):\n",
      "    if option=='article':\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTokens)\n",
      "        return df\n",
      "    else:\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTitle)\n",
      "        return df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng = docsIntoSents('article', df_votID_eng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:17: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng = sentsIntoTokens('sent_tokenized', df_votID_eng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:21: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng = tokensPOStag('word_tokenized', df_votID_eng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:5: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng = tokensPOStag('tokenized_title', df_votID_eng, option='title')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:9: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#concatenate all rows in two of the columns of a dataframe\n",
      "def createCorpusMultiColumns(df, columnName1, columnname2):\n",
      "    corpus = []\n",
      "    for row in df[columnName1]:\n",
      "        corpus.extend(row)\n",
      "    for row in df[columnname2]:\n",
      "        corpus.extend(row)\n",
      "    return corpus\n",
      "\n",
      "def createCorpusSingleColumn(df, columnName1):\n",
      "    corpus = []\n",
      "    for row in df[columnName1]:\n",
      "        corpus.extend(row)\n",
      "    return corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Step 4. Concatenate Titles & Text into \"Corpus\" for Each Directory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# votID_corpus = createCorpusSingleColumn(df_votID_2, 'word_tokenized')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Pattern-Based Collocations (Noun- & Verb-Phrase Chunking)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#look for important noun phrase patterns, either nouns preceded by Det+Adj or simply compound nouns\n",
      "def parseImportantNps():\n",
      "    grammar = r\"\"\"\n",
      "    N-N: {<DET|CD.*>?<J*|N.*>+<N.*>} # chunk DET/Cardinal w/optional ADJ or N with proper noun\n",
      "           {<NNP.*>+<NNP.*>}             # chunk solo proper nouns only\n",
      "    \"\"\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    return cp, 'N-N'\n",
      "\n",
      "\n",
      "#function to chunk \n",
      "def chunk(tagged, func=parseImportantNps):\n",
      "    chunks = []\n",
      "    leaves = []\n",
      "    cp, cn = func()\n",
      "    for i in tagged:\n",
      "        tree = cp.parse(i)\n",
      "        for subtree in tree.subtrees():\n",
      "            if subtree.node == cn:\n",
      "                leaflist = [leaf[0] for leaf in subtree.leaves()]\n",
      "                chunks.append(subtree.leaves())\n",
      "                leaves.append(' '.join(leaflist))\n",
      "    return leaves\n",
      "        \n",
      "#show the proper nouns as strings without their tags\n",
      "def getChunksAsStrings(chunk_list):\n",
      "    phrases = []\n",
      "    for i in chunk_list:\n",
      "        phrase = ''\n",
      "        for j in i:\n",
      "            phrase = phrase + j[0] + ' '\n",
      "        phrases.append(phrase)\n",
      "    return phrases    \n",
      "\n",
      "\n",
      "def freqDistChunks(preprocessed, func=1):\n",
      "    chunks = chunk(preprocessed, func=func)\n",
      "    chunks_only = getChunksAsStrings(chunks)\n",
      "    chks = FreqDist(chunks_only)  \n",
      "    if func==1:\n",
      "        n_list = []\n",
      "        print 'Important Noun Phrases'\n",
      "        for n in chks.items():\n",
      "            if n[1] > 5:\n",
      "                print '%-10s' % n[0], '%-10s' % n[1]\n",
      "                n_list.append(['%-10s' % n[0], '%-10s' % n[1]])\n",
      "        return n_list\n",
      "    elif func==2:\n",
      "        p_list = []\n",
      "        print 'Important Predicate Phrases'\n",
      "        for p in chks.items():\n",
      "            if p[1] > 5:\n",
      "                print '%-10s' % p[0], '%-10s' % p[1]\n",
      "                p_list.append(['%-10s' % p[0], '%-10s' % p[1]])\n",
      "        return p_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function to add new column with tagged tokens (whether from article or title) to df\n",
      "def tokensPOStag(columnname, df, option='article'):\n",
      "    if option=='article':\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTokens)\n",
      "        return df\n",
      "    else:\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTitle)\n",
      "        return df\n",
      "\n",
      "def chunkColumn(columnname, df):\n",
      "    columntitle = 'chunked_%s' %columnname\n",
      "    df[columntitle] = df[columnname].map(chunk)\n",
      "    return df\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>article</th>\n",
        "      <th>title</th>\n",
        "      <th>tokenized_article</th>\n",
        "      <th>tokenized_title</th>\n",
        "      <th>spanish_check</th>\n",
        "      <th>sent_tokenized</th>\n",
        "      <th>word_tokenized</th>\n",
        "      <th>pos_tagged_tokenized_title</th>\n",
        "      <th>pos_tagged_word_tokenized</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> This is a voter suppression tactic as capper a...</td>\n",
        "      <td> Republican Milwaukee Supervisor Sends Out Fals...</td>\n",
        "      <td> [This, is, a, voter, suppression, tactic, as, ...</td>\n",
        "      <td> [Republican, Milwaukee, Supervisor, Sends, Out...</td>\n",
        "      <td> {u'a': 9, u',': 8, u'the': 8, u'of': 7, u'that...</td>\n",
        "      <td> [This is a voter suppression tactic as capper ...</td>\n",
        "      <td> [[This, is, a, voter, suppression, tactic, as,...</td>\n",
        "      <td> [[(Republican, JJ), (Milwaukee, NNP), (Supervi...</td>\n",
        "      <td> [[(This, DT), (is, VBZ), (a, DT), (voter, NN),...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Brennan Center for Justice\\nVoting is now unde...</td>\n",
        "      <td>   On the Ground: Texas Voter ID Troubles Continue</td>\n",
        "      <td> [Brennan, Center, for, Justice, Voting, is, no...</td>\n",
        "      <td> [On, the, Ground, :, Texas, Voter, ID, Trouble...</td>\n",
        "      <td> {u',': 94, u'to': 75, u'the': 73, u'she': 55, ...</td>\n",
        "      <td> [Brennan Center for Justice\\nVoting is now und...</td>\n",
        "      <td> [[Brennan, Center, for, Justice, Voting, is, n...</td>\n",
        "      <td> [[(On, IN), (the, DT), (Ground, NNP), (:, :), ...</td>\n",
        "      <td> [[(Brennan, NNP), (Center, NNP), (for, IN), (J...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Democrats are Racist\\nWhen will the Black Comm...</td>\n",
        "      <td>                              Democrats are Racist</td>\n",
        "      <td> [Democrats, are, Racist, When, will, the, Blac...</td>\n",
        "      <td>                          [Democrats, are, Racist]</td>\n",
        "      <td> {u'to': 32, u',': 27, u'and': 22, u'Democrats'...</td>\n",
        "      <td> [Democrats are Racist\\nWhen will the Black Com...</td>\n",
        "      <td> [[Democrats, are, Racist, When, will, the, Bla...</td>\n",
        "      <td>   [[(Democrats, NNS), (are, VBP), (Racist, NNP)]]</td>\n",
        "      <td> [[(Democrats, NNS), (are, VBP), (Racist, NNP),...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Hey Everyone!\\nLet's share this meme tonight a...</td>\n",
        "      <td>                                   Timeline Photos</td>\n",
        "      <td> [Hey, Everyone, !, Let, 's, share, this, meme,...</td>\n",
        "      <td>                                [Timeline, Photos]</td>\n",
        "      <td> {u'!': 2, u'''': 2, u'and': 2, u''s': 1, u',':...</td>\n",
        "      <td> [Hey Everyone!, Let's share this meme tonight ...</td>\n",
        "      <td> [[Hey, Everyone, !], [Let, 's, share, this, me...</td>\n",
        "      <td>                [[(Timeline, NNP), (Photos, NNP)]]</td>\n",
        "      <td> [[(Hey, PRP), (Everyone, NNP), (!, .)], [(Let,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Rumor Control - Stay tuned! We'll respond to r...</td>\n",
        "      <td>                  Rules and Information for Voters</td>\n",
        "      <td> [Rumor, Control, -, Stay, tuned, !, We, 'll, r...</td>\n",
        "      <td>            [Rules, and, Information, for, Voters]</td>\n",
        "      <td> {u'!': 1, u''ll': 1, u',': 1, u'-': 1, u'.': 1...</td>\n",
        "      <td> [Rumor Control - Stay tuned!, We'll respond to...</td>\n",
        "      <td> [[Rumor, Control, -, Stay, tuned, !], [We, 'll...</td>\n",
        "      <td> [[(Rules, NNS), (and, CC), (Information, NNP),...</td>\n",
        "      <td> [[(Rumor, NNP), (Control, NNP), (-, :), (Stay,...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "                                             article  \\\n",
        "0  This is a voter suppression tactic as capper a...   \n",
        "1  Brennan Center for Justice\\nVoting is now unde...   \n",
        "2  Democrats are Racist\\nWhen will the Black Comm...   \n",
        "3  Hey Everyone!\\nLet's share this meme tonight a...   \n",
        "4  Rumor Control - Stay tuned! We'll respond to r...   \n",
        "\n",
        "                                               title  \\\n",
        "0  Republican Milwaukee Supervisor Sends Out Fals...   \n",
        "1    On the Ground: Texas Voter ID Troubles Continue   \n",
        "2                               Democrats are Racist   \n",
        "3                                    Timeline Photos   \n",
        "4                   Rules and Information for Voters   \n",
        "\n",
        "                                   tokenized_article  \\\n",
        "0  [This, is, a, voter, suppression, tactic, as, ...   \n",
        "1  [Brennan, Center, for, Justice, Voting, is, no...   \n",
        "2  [Democrats, are, Racist, When, will, the, Blac...   \n",
        "3  [Hey, Everyone, !, Let, 's, share, this, meme,...   \n",
        "4  [Rumor, Control, -, Stay, tuned, !, We, 'll, r...   \n",
        "\n",
        "                                     tokenized_title  \\\n",
        "0  [Republican, Milwaukee, Supervisor, Sends, Out...   \n",
        "1  [On, the, Ground, :, Texas, Voter, ID, Trouble...   \n",
        "2                           [Democrats, are, Racist]   \n",
        "3                                 [Timeline, Photos]   \n",
        "4             [Rules, and, Information, for, Voters]   \n",
        "\n",
        "                                       spanish_check  \\\n",
        "0  {u'a': 9, u',': 8, u'the': 8, u'of': 7, u'that...   \n",
        "1  {u',': 94, u'to': 75, u'the': 73, u'she': 55, ...   \n",
        "2  {u'to': 32, u',': 27, u'and': 22, u'Democrats'...   \n",
        "3  {u'!': 2, u'''': 2, u'and': 2, u''s': 1, u',':...   \n",
        "4  {u'!': 1, u''ll': 1, u',': 1, u'-': 1, u'.': 1...   \n",
        "\n",
        "                                      sent_tokenized  \\\n",
        "0  [This is a voter suppression tactic as capper ...   \n",
        "1  [Brennan Center for Justice\\nVoting is now und...   \n",
        "2  [Democrats are Racist\\nWhen will the Black Com...   \n",
        "3  [Hey Everyone!, Let's share this meme tonight ...   \n",
        "4  [Rumor Control - Stay tuned!, We'll respond to...   \n",
        "\n",
        "                                      word_tokenized  \\\n",
        "0  [[This, is, a, voter, suppression, tactic, as,...   \n",
        "1  [[Brennan, Center, for, Justice, Voting, is, n...   \n",
        "2  [[Democrats, are, Racist, When, will, the, Bla...   \n",
        "3  [[Hey, Everyone, !], [Let, 's, share, this, me...   \n",
        "4  [[Rumor, Control, -, Stay, tuned, !], [We, 'll...   \n",
        "\n",
        "                          pos_tagged_tokenized_title  \\\n",
        "0  [[(Republican, JJ), (Milwaukee, NNP), (Supervi...   \n",
        "1  [[(On, IN), (the, DT), (Ground, NNP), (:, :), ...   \n",
        "2    [[(Democrats, NNS), (are, VBP), (Racist, NNP)]]   \n",
        "3                 [[(Timeline, NNP), (Photos, NNP)]]   \n",
        "4  [[(Rules, NNS), (and, CC), (Information, NNP),...   \n",
        "\n",
        "                           pos_tagged_word_tokenized  \n",
        "0  [[(This, DT), (is, VBZ), (a, DT), (voter, NN),...  \n",
        "1  [[(Brennan, NNP), (Center, NNP), (for, IN), (J...  \n",
        "2  [[(Democrats, NNS), (are, VBP), (Racist, NNP),...  \n",
        "3  [[(Hey, PRP), (Everyone, NNP), (!, .)], [(Let,...  \n",
        "4  [[(Rumor, NNP), (Control, NNP), (-, :), (Stay,...  "
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#blank articles\n",
      "df_votID_eng[df_votID_eng.pos_tagged_word_tokenized.apply(lambda r: len(r[0]))==0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>article</th>\n",
        "      <th>title</th>\n",
        "      <th>tokenized_article</th>\n",
        "      <th>tokenized_title</th>\n",
        "      <th>spanish_check</th>\n",
        "      <th>sent_tokenized</th>\n",
        "      <th>word_tokenized</th>\n",
        "      <th>pos_tagged_tokenized_title</th>\n",
        "      <th>pos_tagged_word_tokenized</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>57 </th>\n",
        "      <td> </td>\n",
        "      <td>                          Harrison Beacher Realtor</td>\n",
        "      <td> []</td>\n",
        "      <td>                      [Harrison, Beacher, Realtor]</td>\n",
        "      <td> {}</td>\n",
        "      <td> []</td>\n",
        "      <td> [[]]</td>\n",
        "      <td> [[(Harrison, NNP), (Beacher, NNP), (Realtor, N...</td>\n",
        "      <td> [[]]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>108</th>\n",
        "      <td> </td>\n",
        "      <td> ACLU demands secretary of state change 'illega...</td>\n",
        "      <td> []</td>\n",
        "      <td> [ACLU, demands, secretary, of, state, change, ...</td>\n",
        "      <td> {}</td>\n",
        "      <td> []</td>\n",
        "      <td> [[]]</td>\n",
        "      <td> [[(ACLU, NNP), (demands, NNS), (secretary, JJ)...</td>\n",
        "      <td> [[]]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>146</th>\n",
        "      <td> </td>\n",
        "      <td> ACLU demands secretary of state change 'illega...</td>\n",
        "      <td> []</td>\n",
        "      <td> [ACLU, demands, secretary, of, state, change, ...</td>\n",
        "      <td> {}</td>\n",
        "      <td> []</td>\n",
        "      <td> [[]]</td>\n",
        "      <td> [[(ACLU, NNP), (demands, NNS), (secretary, JJ)...</td>\n",
        "      <td> [[]]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>291</th>\n",
        "      <td> </td>\n",
        "      <td>           Voter-ID backer catches Dems in the act</td>\n",
        "      <td> []</td>\n",
        "      <td>   [Voter-ID, backer, catches, Dems, in, the, act]</td>\n",
        "      <td> {}</td>\n",
        "      <td> []</td>\n",
        "      <td> [[]]</td>\n",
        "      <td> [[(Voter-ID, JJ), (backer, NN), (catches, NNS)...</td>\n",
        "      <td> [[]]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>443</th>\n",
        "      <td> </td>\n",
        "      <td>    Dianna Duran Secretary of State 2014_ Voter ID</td>\n",
        "      <td> []</td>\n",
        "      <td> [Dianna, Duran, Secretary, of, State, 2014_, V...</td>\n",
        "      <td> {}</td>\n",
        "      <td> []</td>\n",
        "      <td> [[]]</td>\n",
        "      <td> [[(Dianna, NNP), (Duran, NNP), (Secretary, NNP...</td>\n",
        "      <td> [[]]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>498</th>\n",
        "      <td> </td>\n",
        "      <td>   Long-stalled voter ID legislation gets new life</td>\n",
        "      <td> []</td>\n",
        "      <td> [Long-stalled, voter, ID, legislation, gets, n...</td>\n",
        "      <td> {}</td>\n",
        "      <td> []</td>\n",
        "      <td> [[]]</td>\n",
        "      <td> [[(Long-stalled, JJ), (voter, NN), (ID, NNP), ...</td>\n",
        "      <td> [[]]</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "    article                                              title  \\\n",
        "57                                    Harrison Beacher Realtor   \n",
        "108          ACLU demands secretary of state change 'illega...   \n",
        "146          ACLU demands secretary of state change 'illega...   \n",
        "291                    Voter-ID backer catches Dems in the act   \n",
        "443             Dianna Duran Secretary of State 2014_ Voter ID   \n",
        "498            Long-stalled voter ID legislation gets new life   \n",
        "\n",
        "    tokenized_article                                    tokenized_title  \\\n",
        "57                 []                       [Harrison, Beacher, Realtor]   \n",
        "108                []  [ACLU, demands, secretary, of, state, change, ...   \n",
        "146                []  [ACLU, demands, secretary, of, state, change, ...   \n",
        "291                []    [Voter-ID, backer, catches, Dems, in, the, act]   \n",
        "443                []  [Dianna, Duran, Secretary, of, State, 2014_, V...   \n",
        "498                []  [Long-stalled, voter, ID, legislation, gets, n...   \n",
        "\n",
        "    spanish_check sent_tokenized word_tokenized  \\\n",
        "57             {}             []           [[]]   \n",
        "108            {}             []           [[]]   \n",
        "146            {}             []           [[]]   \n",
        "291            {}             []           [[]]   \n",
        "443            {}             []           [[]]   \n",
        "498            {}             []           [[]]   \n",
        "\n",
        "                            pos_tagged_tokenized_title  \\\n",
        "57   [[(Harrison, NNP), (Beacher, NNP), (Realtor, N...   \n",
        "108  [[(ACLU, NNP), (demands, NNS), (secretary, JJ)...   \n",
        "146  [[(ACLU, NNP), (demands, NNS), (secretary, JJ)...   \n",
        "291  [[(Voter-ID, JJ), (backer, NN), (catches, NNS)...   \n",
        "443  [[(Dianna, NNP), (Duran, NNP), (Secretary, NNP...   \n",
        "498  [[(Long-stalled, JJ), (voter, NN), (ID, NNP), ...   \n",
        "\n",
        "    pos_tagged_word_tokenized  \n",
        "57                       [[]]  \n",
        "108                      [[]]  \n",
        "146                      [[]]  \n",
        "291                      [[]]  \n",
        "443                      [[]]  \n",
        "498                      [[]]  "
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng['sent_tokenized'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "[u'This is a voter suppression tactic as capper at Crooks and Liars notes.',\n",
        " u'Milwaukee County Supervisor Deanna Alexander is a Republican\\u2019s Republican.',\n",
        " u'Alexander won her office with a late race-baiting flier against her African American opponent.',\n",
        " u'She\\u2019s appeared at CPAC, was named a \\u201crising star\\u201d by dark money group American Majority, illegally accepted free legal representation from a Bradley Foundation funded lawyer, supports gay bashing Chick Fil A and has accused Texas gubernatorial candidate Wendy Davis of supporting infanticide.',\n",
        " u'Yeah, she\\u2019s a real pip, alright.',\n",
        " u'So it comes as no surprise to us in Milwaukee that she used taxpayer money to mail out 7,000 copies of her newsletter which included the information that a photo ID would be needed to vote on Election Day:\\nThe first problem with this is the fact that US Supreme Court blocked the implementation of this voter suppression law for this election\\u2026\\nDespite the fact that it cost taxpayers thousands of dollars to send out the original mailer and thousands of dollars more to send out the correction, I have a feeling that we won\\u2019t hear from the conservatives about this waste and fraud.',\n",
        " u'For me, the unanswered question is that why Alexander sent out only 7,000 of these mailers when she represents more than 50,000 people.',\n",
        " u'You don\\u2019t suppose that these mailers were targeted at a certain class of voters, do you?']"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng = chunkColumn('pos_tagged_word_tokenized', df_votID_eng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: parsing empty text\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:14: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng['article_chunks'] = df_votID_eng.pos_tagged_word_tokenized.apply(chunk)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: parsing empty text\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Warning: parsing empty text"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:1: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>article</th>\n",
        "      <th>title</th>\n",
        "      <th>tokenized_article</th>\n",
        "      <th>tokenized_title</th>\n",
        "      <th>spanish_check</th>\n",
        "      <th>sent_tokenized</th>\n",
        "      <th>word_tokenized</th>\n",
        "      <th>pos_tagged_tokenized_title</th>\n",
        "      <th>pos_tagged_word_tokenized</th>\n",
        "      <th>chunked_pos_tagged_word_tokenized</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> This is a voter suppression tactic as capper a...</td>\n",
        "      <td> Republican Milwaukee Supervisor Sends Out Fals...</td>\n",
        "      <td> [This, is, a, voter, suppression, tactic, as, ...</td>\n",
        "      <td> [Republican, Milwaukee, Supervisor, Sends, Out...</td>\n",
        "      <td> {u'a': 9, u',': 8, u'the': 8, u'of': 7, u'that...</td>\n",
        "      <td> [This is a voter suppression tactic as capper ...</td>\n",
        "      <td> [[This, is, a, voter, suppression, tactic, as,...</td>\n",
        "      <td> [[(Republican, JJ), (Milwaukee, NNP), (Supervi...</td>\n",
        "      <td> [[(This, DT), (is, VBZ), (a, DT), (voter, NN),...</td>\n",
        "      <td> [voter suppression, Liars notes, Milwaukee Cou...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Brennan Center for Justice\\nVoting is now unde...</td>\n",
        "      <td>   On the Ground: Texas Voter ID Troubles Continue</td>\n",
        "      <td> [Brennan, Center, for, Justice, Voting, is, no...</td>\n",
        "      <td> [On, the, Ground, :, Texas, Voter, ID, Trouble...</td>\n",
        "      <td> {u',': 94, u'to': 75, u'the': 73, u'she': 55, ...</td>\n",
        "      <td> [Brennan Center for Justice\\nVoting is now und...</td>\n",
        "      <td> [[Brennan, Center, for, Justice, Voting, is, n...</td>\n",
        "      <td> [[(On, IN), (the, DT), (Ground, NNP), (:, :), ...</td>\n",
        "      <td> [[(Brennan, NNP), (Center, NNP), (for, IN), (J...</td>\n",
        "      <td> [Brennan Center, Justice Voting, voter ID laws...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Democrats are Racist\\nWhen will the Black Comm...</td>\n",
        "      <td>                              Democrats are Racist</td>\n",
        "      <td> [Democrats, are, Racist, When, will, the, Blac...</td>\n",
        "      <td>                          [Democrats, are, Racist]</td>\n",
        "      <td> {u'to': 32, u',': 27, u'and': 22, u'Democrats'...</td>\n",
        "      <td> [Democrats are Racist\\nWhen will the Black Com...</td>\n",
        "      <td> [[Democrats, are, Racist, When, will, the, Bla...</td>\n",
        "      <td>   [[(Democrats, NNS), (are, VBP), (Racist, NNP)]]</td>\n",
        "      <td> [[(Democrats, NNS), (are, VBP), (Racist, NNP),...</td>\n",
        "      <td> [Racist When, Black Community tell, STOP insul...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Hey Everyone!\\nLet's share this meme tonight a...</td>\n",
        "      <td>                                   Timeline Photos</td>\n",
        "      <td> [Hey, Everyone, !, Let, 's, share, this, meme,...</td>\n",
        "      <td>                                [Timeline, Photos]</td>\n",
        "      <td> {u'!': 2, u'''': 2, u'and': 2, u''s': 1, u',':...</td>\n",
        "      <td> [Hey Everyone!, Let's share this meme tonight ...</td>\n",
        "      <td> [[Hey, Everyone, !], [Let, 's, share, this, me...</td>\n",
        "      <td>                [[(Timeline, NNP), (Photos, NNP)]]</td>\n",
        "      <td> [[(Hey, PRP), (Everyone, NNP), (!, .)], [(Let,...</td>\n",
        "      <td>                         [meme tonight, Keep Calm]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Rumor Control - Stay tuned! We'll respond to r...</td>\n",
        "      <td>                  Rules and Information for Voters</td>\n",
        "      <td> [Rumor, Control, -, Stay, tuned, !, We, 'll, r...</td>\n",
        "      <td>            [Rules, and, Information, for, Voters]</td>\n",
        "      <td> {u'!': 1, u''ll': 1, u',': 1, u'-': 1, u'.': 1...</td>\n",
        "      <td> [Rumor Control - Stay tuned!, We'll respond to...</td>\n",
        "      <td> [[Rumor, Control, -, Stay, tuned, !], [We, 'll...</td>\n",
        "      <td> [[(Rules, NNS), (and, CC), (Information, NNP),...</td>\n",
        "      <td> [[(Rumor, NNP), (Control, NNP), (-, :), (Stay,...</td>\n",
        "      <td> [Rumor Control, further questions, please cont...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "                                             article  \\\n",
        "0  This is a voter suppression tactic as capper a...   \n",
        "1  Brennan Center for Justice\\nVoting is now unde...   \n",
        "2  Democrats are Racist\\nWhen will the Black Comm...   \n",
        "3  Hey Everyone!\\nLet's share this meme tonight a...   \n",
        "4  Rumor Control - Stay tuned! We'll respond to r...   \n",
        "\n",
        "                                               title  \\\n",
        "0  Republican Milwaukee Supervisor Sends Out Fals...   \n",
        "1    On the Ground: Texas Voter ID Troubles Continue   \n",
        "2                               Democrats are Racist   \n",
        "3                                    Timeline Photos   \n",
        "4                   Rules and Information for Voters   \n",
        "\n",
        "                                   tokenized_article  \\\n",
        "0  [This, is, a, voter, suppression, tactic, as, ...   \n",
        "1  [Brennan, Center, for, Justice, Voting, is, no...   \n",
        "2  [Democrats, are, Racist, When, will, the, Blac...   \n",
        "3  [Hey, Everyone, !, Let, 's, share, this, meme,...   \n",
        "4  [Rumor, Control, -, Stay, tuned, !, We, 'll, r...   \n",
        "\n",
        "                                     tokenized_title  \\\n",
        "0  [Republican, Milwaukee, Supervisor, Sends, Out...   \n",
        "1  [On, the, Ground, :, Texas, Voter, ID, Trouble...   \n",
        "2                           [Democrats, are, Racist]   \n",
        "3                                 [Timeline, Photos]   \n",
        "4             [Rules, and, Information, for, Voters]   \n",
        "\n",
        "                                       spanish_check  \\\n",
        "0  {u'a': 9, u',': 8, u'the': 8, u'of': 7, u'that...   \n",
        "1  {u',': 94, u'to': 75, u'the': 73, u'she': 55, ...   \n",
        "2  {u'to': 32, u',': 27, u'and': 22, u'Democrats'...   \n",
        "3  {u'!': 2, u'''': 2, u'and': 2, u''s': 1, u',':...   \n",
        "4  {u'!': 1, u''ll': 1, u',': 1, u'-': 1, u'.': 1...   \n",
        "\n",
        "                                      sent_tokenized  \\\n",
        "0  [This is a voter suppression tactic as capper ...   \n",
        "1  [Brennan Center for Justice\\nVoting is now und...   \n",
        "2  [Democrats are Racist\\nWhen will the Black Com...   \n",
        "3  [Hey Everyone!, Let's share this meme tonight ...   \n",
        "4  [Rumor Control - Stay tuned!, We'll respond to...   \n",
        "\n",
        "                                      word_tokenized  \\\n",
        "0  [[This, is, a, voter, suppression, tactic, as,...   \n",
        "1  [[Brennan, Center, for, Justice, Voting, is, n...   \n",
        "2  [[Democrats, are, Racist, When, will, the, Bla...   \n",
        "3  [[Hey, Everyone, !], [Let, 's, share, this, me...   \n",
        "4  [[Rumor, Control, -, Stay, tuned, !], [We, 'll...   \n",
        "\n",
        "                          pos_tagged_tokenized_title  \\\n",
        "0  [[(Republican, JJ), (Milwaukee, NNP), (Supervi...   \n",
        "1  [[(On, IN), (the, DT), (Ground, NNP), (:, :), ...   \n",
        "2    [[(Democrats, NNS), (are, VBP), (Racist, NNP)]]   \n",
        "3                 [[(Timeline, NNP), (Photos, NNP)]]   \n",
        "4  [[(Rules, NNS), (and, CC), (Information, NNP),...   \n",
        "\n",
        "                           pos_tagged_word_tokenized  \\\n",
        "0  [[(This, DT), (is, VBZ), (a, DT), (voter, NN),...   \n",
        "1  [[(Brennan, NNP), (Center, NNP), (for, IN), (J...   \n",
        "2  [[(Democrats, NNS), (are, VBP), (Racist, NNP),...   \n",
        "3  [[(Hey, PRP), (Everyone, NNP), (!, .)], [(Let,...   \n",
        "4  [[(Rumor, NNP), (Control, NNP), (-, :), (Stay,...   \n",
        "\n",
        "                   chunked_pos_tagged_word_tokenized  \n",
        "0  [voter suppression, Liars notes, Milwaukee Cou...  \n",
        "1  [Brennan Center, Justice Voting, voter ID laws...  \n",
        "2  [Racist When, Black Community tell, STOP insul...  \n",
        "3                          [meme tonight, Keep Calm]  \n",
        "4  [Rumor Control, further questions, please cont...  "
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng['article_chunks'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "[u'voter suppression',\n",
        " u'Liars notes',\n",
        " u'Milwaukee County Supervisor Deanna Alexander',\n",
        " u'late race-baiting flier',\n",
        " u'African American opponent',\n",
        " u'\\u201crising star\\u201d',\n",
        " u'dark money group American Majority',\n",
        " u'free legal representation',\n",
        " u'Bradley Foundation',\n",
        " u'Chick Fil A',\n",
        " u'Texas gubernatorial candidate Wendy Davis',\n",
        " u'real pip',\n",
        " u'taxpayer money',\n",
        " u'photo ID',\n",
        " u'Election Day',\n",
        " u'first problem',\n",
        " u'US Supreme Court',\n",
        " u'voter suppression law',\n",
        " u'election\\u2026 Despite',\n",
        " u'taxpayers thousands',\n",
        " u'original mailer',\n",
        " u'Alexander sent',\n",
        " u'certain class']"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_votID_eng.title.count(), len(df_votID_eng.title.unique())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "(457, 295)"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_chunks = []\n",
      "for chunk in df_votID_eng['article_chunks']:\n",
      "    corpus_chunks.extend(chunk)\n",
      "     \n",
      "chunk_fd = nltk.FreqDist(corpus_chunks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freqchunks = chunk_fd.keys()[:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunk_fd.items()[10], chunk_fd.items()[100], chunk_fd.items()[1000], chunk_fd.items()[10000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "((u'strict photo voter ID law', 245),\n",
        " (u'provisional ballot pursuant', 70),\n",
        " (u'Mike Brown', 8),\n",
        " (u'[ constitutional ] question', 1))"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunk_fd.items()[:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "[(u'provisional ballot', 1483),\n",
        " (u'photo ID', 536),\n",
        " (u'Election Day', 350),\n",
        " (u'North Carolina', 341),\n",
        " (u'expiration date', 323),\n",
        " (u'2014 general election', 283),\n",
        " (u'religious objection', 281),\n",
        " (u'voter ID law', 272),\n",
        " (u'voter fraud', 272),\n",
        " (u'bank statement', 255),\n",
        " (u'strict photo voter ID law', 245),\n",
        " (u'birth certificate', 220),\n",
        " (u'other government document', 214),\n",
        " (u'government check', 213),\n",
        " (u'voter ID laws', 205),\n",
        " (u'Supreme Court', 195),\n",
        " (u'voter ID', 188),\n",
        " (u'polling place', 183),\n",
        " (u'election official', 182),\n",
        " (u'U.S. Supreme Court', 179),\n",
        " (u'Arkansas Supreme Court', 178),\n",
        " (u'reasonable impediment', 175),\n",
        " (u'photo identification', 173),\n",
        " (u'attorney general', 156),\n",
        " (u'poll workers', 148),\n",
        " (u'current utility bill', 145),\n",
        " (u'social security number', 142),\n",
        " (u'voter ID legislation', 142),\n",
        " (u'U.S. government', 141),\n",
        " (u'non-photo ID law', 141),\n",
        " (u'county election commission', 140),\n",
        " (u'electoral board', 140),\n",
        " (u'United States', 138),\n",
        " (u'driver\\u2019s license', 132),\n",
        " (u'provisional ballots', 132),\n",
        " (u'Voting Rights Act', 124),\n",
        " (u'election officials', 123),\n",
        " (u'regular ballot', 120),\n",
        " (u'student IDs', 113),\n",
        " (u'identification document', 107),\n",
        " (u'poll book', 107),\n",
        " (u'student ID card', 107),\n",
        " (u'valid photo identification', 107),\n",
        " (u'challenged voter affidavit', 106),\n",
        " (u'general election', 106),\n",
        " (u'registration record', 106),\n",
        " (u'voter affidavit', 106),\n",
        " (u') NOTE', 105),\n",
        " (u'federal government', 105),\n",
        " (u'non-photo voter registration card', 105)]"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_sents = createCorpusSingleColumn(df_votID_eng, 'sent_tokenized')\n",
      "all_sents[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "[u'This is a voter suppression tactic as capper at Crooks and Liars notes.',\n",
        " u'Milwaukee County Supervisor Deanna Alexander is a Republican\\u2019s Republican.']"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freqchunks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "[u'provisional ballot',\n",
        " u'photo ID',\n",
        " u'Election Day',\n",
        " u'North Carolina',\n",
        " u'expiration date',\n",
        " u'2014 general election',\n",
        " u'religious objection',\n",
        " u'voter ID law',\n",
        " u'voter fraud',\n",
        " u'bank statement',\n",
        " u'strict photo voter ID law',\n",
        " u'birth certificate',\n",
        " u'other government document',\n",
        " u'government check',\n",
        " u'voter ID laws',\n",
        " u'Supreme Court',\n",
        " u'voter ID',\n",
        " u'polling place',\n",
        " u'election official',\n",
        " u'U.S. Supreme Court',\n",
        " u'Arkansas Supreme Court',\n",
        " u'reasonable impediment',\n",
        " u'photo identification',\n",
        " u'attorney general',\n",
        " u'poll workers',\n",
        " u'current utility bill',\n",
        " u'social security number',\n",
        " u'voter ID legislation',\n",
        " u'U.S. government',\n",
        " u'non-photo ID law',\n",
        " u'county election commission',\n",
        " u'electoral board',\n",
        " u'United States',\n",
        " u'driver\\u2019s license',\n",
        " u'provisional ballots',\n",
        " u'Voting Rights Act',\n",
        " u'election officials',\n",
        " u'regular ballot',\n",
        " u'student IDs',\n",
        " u'identification document',\n",
        " u'poll book',\n",
        " u'student ID card',\n",
        " u'valid photo identification',\n",
        " u'challenged voter affidavit',\n",
        " u'general election',\n",
        " u'registration record',\n",
        " u'voter affidavit',\n",
        " u') NOTE',\n",
        " u'federal government',\n",
        " u'non-photo voter registration card']"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imp_sents_dict = {} # get sentences with a particular word in them\n",
      "\n",
      "for fc in freqchunks:\n",
      "    imp_sents = []\n",
      "    imp_sents_dict[fc] = imp_sents\n",
      "    for sent in all_sents:\n",
      "        if sent.find(fc) != -1:\n",
      "            imp_sents.append(sent)\n",
      "            \n",
      "for l in imp_sents_dict.values():\n",
      "    print len(l)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "85\n",
        "352\n",
        "154\n",
        "142\n",
        "837\n",
        "331\n",
        "253\n",
        "366\n",
        "534\n",
        "284\n",
        "214\n",
        "487\n",
        "182\n",
        "213\n",
        "214\n",
        "141\n",
        "145\n",
        "169\n",
        "105\n",
        "1078\n",
        "174\n",
        "379\n",
        "1872\n",
        "212\n",
        "145\n",
        "108\n",
        "359\n",
        "128\n",
        "1303\n",
        "212\n",
        "122\n",
        "619\n",
        "248\n",
        "246\n",
        "281\n",
        "322\n",
        "418\n",
        "283\n",
        "140\n",
        "247\n",
        "0\n",
        "144\n",
        "476\n",
        "291\n",
        "141\n",
        "107\n",
        "318\n",
        "149\n",
        "1804\n",
        "70\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_sents = []\n",
      "\n",
      "for article in df_votID_eng['sent_tokenized']:\n",
      "    for s in article:\n",
      "        total_sents.append(s)\n",
      "    \n",
      "len(total_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "24080"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_sents = []\n",
      "for l in imp_sents_dict.values():\n",
      "    for sent in l:\n",
      "        all_sents.extend(l)\n",
      "\n",
      "sents_of_interest = set(all_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "sent_dict = {}\n",
      "\n",
      "for sent in sents_of_interest:\n",
      "    chunks_contained = {}\n",
      "    fcs = []\n",
      "    score = 0\n",
      "    \n",
      "    if sent not in sent_dict:\n",
      "        sent_dict[sent] = chunks_contained\n",
      "        chunks_contained['fcs'] = fcs\n",
      "        \n",
      "        \n",
      "        for fc in freqchunks:\n",
      "            if sent.find(fc) != -1:\n",
      "                fcs.append(fc)\n",
      "                score = score + (len(fc.split())**2)\n",
      "        chunks_contained['score'] = int(score)\n",
      "\n",
      "sent_dict.items()[-10:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "[(u'It now is pending before the U.S. Supreme Court.',\n",
        "  {'fcs': [u'Supreme Court', u'U.S. Supreme Court'], 'score': 13}),\n",
        " (u\"Mississippi\\n\\xa723-15-563\\n-A driver's license\\n-A photo ID card issued by a branch, department, or entity of the State of Mississippi\\n-A United States passport\\n-A government employee ID card\\n-A firearms license\\n-A student photo ID issued by an accredited Mississippi university, college, or community/junior college\\n-A United States military ID\\n-A tribal photo ID\\n-Any other photo ID issued by any branch, department, agency or entity of the United States government or any state government\\n-A Mississippi Voter Identification Card\\nAn individual without ID can cast an affidavit ballot which will be counted if the individual returns to the appropriate circuit clerk within five days after the election and shows government-issued photo ID.\",\n",
        "  {'fcs': [u'photo ID', u'United States'], 'score': 8}),\n",
        " (u'The state attorney general has asked the Wisconsin Supreme Court to intervene and reinstate the law before the November election.',\n",
        "  {'fcs': [u'Supreme Court', u'attorney general'], 'score': 8}),\n",
        " (u'In a vehement dissent in a recent case where the Supreme Court overturned a Texas decision and held that the State of Texas could move forward with possibly the strictest voter ID law in the nation, Ginsburg criticized Texas for disenfranchising hundreds of thousands of voters who, because they lived hours from any office that could issue the \\u201cproper\\u201d ID form, would be cut off from voting without the state making reasonable efforts to resolve that or to make sure people knew there was an alternate state-issued free ID they could get.',\n",
        "  {'fcs': [u'voter ID law', u'Supreme Court', u'voter ID'], 'score': 17}),\n",
        " (u'In Alabama, voter fraud is punishable by up to two years in prison and a $2,000 fine.',\n",
        "  {'fcs': [u'voter fraud'], 'score': 4}),\n",
        " (u'Nov. 2000: A vote was cast in the general election in Miami, FL, in the name of Andre Alism\\xe9, who had died in 1997.',\n",
        "  {'fcs': [u'general election'], 'score': 4}),\n",
        " (u'The most important point: In virtually any instance, a voter will be able to cast a ballot, regardless of whether he/she has a photo ID.',\n",
        "  {'fcs': [u'photo ID'], 'score': 4}),\n",
        " (u'By contrast, beliefs about the prevalence of fraud by election officials show far less of a partisan skew, with 16 percent of Republicans, 21 percent of independents and 14 percent of Democrats (and 17 percent of Wisconsin voters over all) thinking that this affects a few thousand votes or more each election.',\n",
        "  {'fcs': [u'election official', u'election officials'], 'score': 8}),\n",
        " (u'People of color are more likely to be disenfranchised by these laws since they are less likely to have photo ID than the general population.',\n",
        "  {'fcs': [u'photo ID'], 'score': 4}),\n",
        " (u'\\u201cTotal spending on Senate races reached $200 million in October alone, significantly more than in the same period before the 2010 midterms.\\u201d\\nThose dollars, unleashed by the Supreme Court\\u2019s decision in Citizens United, are particularly hard to track.',\n",
        "  {'fcs': [u'Supreme Court'], 'score': 4})]"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "summ_sents = list(sent_dict.items())\n",
      "summ_sents.sort(key=lambda x: x[1]['score']) \n",
      "summ_sents[-10:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "[(u\"Existing law:\\n-Virginia voter registration card\\n-Social Security card\\n-Valid Virginia driver's license\\n-Any other identification card issued by a government agency of the Commonwealth, one of its political subdivisions, or the United States\\n-Employee identification card containing a photograph\\n-Any valid student ID card issued by any institution of higher education located in Virginia\\n-Copy of a current utility bill, bank statement, government check or paycheck that shows the name and address of the voter\\n-Concealed handgun permit\\nNew law (all must be current and valid and bear a photo of the voter):\\n-Virginia voter registration card\\n-United States passport\\n-Virginia driver's license\\n-Any other identification card issued by a government agency of the Commonwealth, one of its political subdivisions, or the United States\\n-Concealed handgun permit\\n-Any valid student ID card issued by any institution of higher education located in Virginia\\n-Employee identification card\\nAny voter who does not show one of the forms of identification specified in this subsection shall be offered a provisional ballot marked ID-ONLY that requires no follow-up action by the registrar or electoral board other than matching submitted identification documents from the voter for the electoral board to make a determination on whether to count the ballot.\",\n",
        "  {'fcs': [u'provisional ballot',\n",
        "    u'bank statement',\n",
        "    u'government check',\n",
        "    u'current utility bill',\n",
        "    u'electoral board',\n",
        "    u'United States',\n",
        "    u'identification document',\n",
        "    u'student ID card'],\n",
        "   'score': 42}),\n",
        " (u'North Carolina also enacted a strict photo voter ID law in 2013, with an implementation date in 2016.',\n",
        "  {'fcs': [u'North Carolina',\n",
        "    u'voter ID law',\n",
        "    u'strict photo voter ID law',\n",
        "    u'voter ID'],\n",
        "   'score': 42}),\n",
        " (u'But these efforts have come up against a series of cumbersome voter ID laws that have made it harder for people to vote, buttressed by the U.S. Supreme Court ruling invalidating key parts of the Voting Rights Act.',\n",
        "  {'fcs': [u'voter ID law',\n",
        "    u'voter ID laws',\n",
        "    u'Supreme Court',\n",
        "    u'voter ID',\n",
        "    u'U.S. Supreme Court',\n",
        "    u'Voting Rights Act'],\n",
        "   'score': 44}),\n",
        " (u'Mandela supported and put into place strict photo voter ID laws in South Africa.',\n",
        "  {'fcs': [u'voter ID law',\n",
        "    u'strict photo voter ID law',\n",
        "    u'voter ID laws',\n",
        "    u'voter ID'],\n",
        "   'score': 47}),\n",
        " (u\"[1] Arkansas's strict photo voter ID law was struck down by the Arkansas Supreme Court, leaving a pre-existing non-strict, non-photo law in effect.\",\n",
        "  {'fcs': [u'voter ID law',\n",
        "    u'strict photo voter ID law',\n",
        "    u'Supreme Court',\n",
        "    u'voter ID',\n",
        "    u'Arkansas Supreme Court'],\n",
        "   'score': 51}),\n",
        " (u'[5] Texas enacted in 2011 a strict photo voter ID law, replacing its existing non-strict, non-photo ID law.',\n",
        "  {'fcs': [u'photo ID',\n",
        "    u'voter ID law',\n",
        "    u'strict photo voter ID law',\n",
        "    u'voter ID',\n",
        "    u'non-photo ID law'],\n",
        "   'score': 51}),\n",
        " (u'Ohio\\n\\xa73503.16(B)(1)(a) and 3505.18(A)(1)\\n-Current and valid photo identification, defined as a document that shows the individual\\u2019s name and current address, includes a photograph, includes an expiration date that has not passed, and was issued by the U.S. government or the state of Ohio\\n-Current utility bill\\n-Current bank statement\\n-Current government check, paycheck or other government document\\nA voter who has but declines to provide identification may cast a provisional ballot upon providing a social security number or the last four digits of a social security number.',\n",
        "  {'fcs': [u'provisional ballot',\n",
        "    u'expiration date',\n",
        "    u'bank statement',\n",
        "    u'other government document',\n",
        "    u'government check',\n",
        "    u'photo identification',\n",
        "    u'social security number',\n",
        "    u'U.S. government',\n",
        "    u'valid photo identification'],\n",
        "   'score': 51}),\n",
        " (u\"The Arkansas Supreme Court struck down on Oct. 15 Arkansas' 2013 strict photo voter ID law.\",\n",
        "  {'fcs': [u'voter ID law',\n",
        "    u'strict photo voter ID law',\n",
        "    u'Supreme Court',\n",
        "    u'voter ID',\n",
        "    u'Arkansas Supreme Court'],\n",
        "   'score': 51}),\n",
        " (u'The U.S. Supreme Court on Oct. 18 permitted Texas to use and enforce its strict photo voter ID law for the November 2014 election.',\n",
        "  {'fcs': [u'voter ID law',\n",
        "    u'strict photo voter ID law',\n",
        "    u'Supreme Court',\n",
        "    u'voter ID',\n",
        "    u'U.S. Supreme Court'],\n",
        "   'score': 51}),\n",
        " (u\"Per a U.S. Supreme Court order on October 9, Wisconsin's strict photo voter ID law will not be implemented for the 2014 general election.\",\n",
        "  {'fcs': [u'2014 general election',\n",
        "    u'voter ID law',\n",
        "    u'strict photo voter ID law',\n",
        "    u'Supreme Court',\n",
        "    u'voter ID',\n",
        "    u'U.S. Supreme Court',\n",
        "    u'general election'],\n",
        "   'score': 64})]"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def integrate_ngrams(new):\n",
      "    \"Takes a list of integrates lists of different sized ngrams\"\n",
      "    out = []\n",
      "    orig_reps = []\n",
      "    \n",
      "    for t in new:\n",
      "        if type(t)!='str':\n",
      "            rep = \" \".join(t)\n",
      "        else:\n",
      "            rep = t\n",
      "        \n",
      "        if not any([rep in o_rep for o_rep in orig_reps]):\n",
      "            out.append(t)\n",
      "    \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in summ_sents:\n",
      "    if len(i[1]['fcs']) > 3:\n",
      "        print i[1]['fcs']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'photo ID', u'photo identification', u'U.S. government', u'driver\\u2019s license']\n",
        "[u'North Carolina', u'polling place', u'election official', u'election officials']\n",
        "[u'photo ID', u'election official', u'poll workers', u'election officials']\n",
        "[u'photo identification', u'U.S. government', u'United States', u'driver\\u2019s license']\n",
        "[u'photo ID', u'Election Day', u'election official', u'election officials']\n",
        "[u'provisional ballot', u'provisional ballots', u'poll book', u'general election']\n",
        "[u'photo ID', u'election official', u'election officials', u'regular ballot']\n",
        "[u'provisional ballot', u'photo ID', u'North Carolina', u'provisional ballots']\n",
        "[u'North Carolina', u'polling place', u'election official', u'election officials']\n",
        "[u'provisional ballot', u'Election Day', u'election official', u'election officials']\n",
        "[u'provisional ballot', u'photo ID', u'Election Day', u'photo identification']\n",
        "[u'provisional ballot', u'election official', u'provisional ballots', u'election officials']\n",
        "[u'photo ID', u'Supreme Court', u'photo identification', u'general election']\n",
        "[u'photo ID', u'voter fraud', u'polling place', u'general election']\n",
        "[u'provisional ballot', u'religious objection', u'photo identification', u'United States']\n",
        "[u'provisional ballot', u'North Carolina', u'provisional ballots', u'federal government']\n",
        "[u'Election Day', u'election official', u'poll workers', u'election officials']\n",
        "[u'provisional ballot', u'election official', u'provisional ballots', u'election officials', u'regular ballot']\n",
        "[u'Supreme Court', u'voter ID', u'United States', u'Voting Rights Act']\n",
        "[u'photo ID', u'Supreme Court', u'United States', u'Voting Rights Act']\n",
        "[u'election official', u'election officials', u'challenged voter affidavit', u'voter affidavit']\n",
        "[u'provisional ballot', u'photo identification', u'valid photo identification', u'registration record']\n",
        "[u'photo identification', u'attorney general', u'valid photo identification', u'voter affidavit']\n",
        "[u'photo ID', u'bank statement', u'government check', u'current utility bill']\n",
        "[u'photo ID', u'voter ID law', u'Supreme Court', u'voter ID']\n",
        "[u'photo ID', u'bank statement', u'current utility bill', u'United States']\n",
        "[u'provisional ballot', u'expiration date', u'U.S. government', u'United States', u'general election', u'registration record']\n",
        "[u'provisional ballot', u'photo ID', u'voter ID', u'photo identification', u'driver\\u2019s license', u'federal government']\n",
        "[u'photo ID', u'Election Day', u'Supreme Court', u'election official', u'poll workers', u'election officials']\n",
        "[u'provisional ballot', u'voter ID', u'election official', u'election officials', u'regular ballot', u'federal government']\n",
        "[u'photo ID', u'expiration date', u'photo identification', u'student ID card', u'voter affidavit']\n",
        "[u'provisional ballot', u'bank statement', u'other government document', u'government check', u'photo identification']\n",
        "[u'provisional ballot', u'birth certificate', u'polling place', u'reasonable impediment', u'county election commission']\n",
        "[u'provisional ballot', u'religious objection', u'polling place', u'reasonable impediment', u'student ID card']\n",
        "[u'provisional ballot', u'bank statement', u'other government document', u'government check', u'election official']\n",
        "[u'North Carolina', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'Arkansas Supreme Court']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter ID laws', u'voter ID', u'United States']\n",
        "[u'Supreme Court', u'voter ID', u'U.S. Supreme Court', u'Voting Rights Act']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'U.S. Supreme Court']\n",
        "[u'voter ID law', u'voter ID laws', u'voter ID', u'general election']\n",
        "[u'Election Day', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter ID laws', u'Supreme Court', u'voter ID']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'Election Day', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'photo ID', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter ID laws', u'voter ID', u'photo identification']\n",
        "[u'voter ID law', u'voter ID laws', u'Supreme Court', u'voter ID']\n",
        "[u'photo ID', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter ID laws', u'voter ID', u'United States']\n",
        "[u'voter ID law', u'voter ID', u'polling place', u'Voting Rights Act']\n",
        "[u'voter ID law', u'voter ID laws', u'Supreme Court', u'voter ID']\n",
        "[u'North Carolina', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'Election Day', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'photo ID', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter ID laws', u'voter ID', u'polling place']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'U.S. Supreme Court']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'U.S. Supreme Court']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter ID laws', u'voter ID', u'United States']\n",
        "[u'photo ID', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'U.S. Supreme Court']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'Arkansas Supreme Court']\n",
        "[u'photo ID', u'bank statement', u'other government document', u'current utility bill']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'Election Day', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'2014 general election', u'Supreme Court', u'U.S. Supreme Court', u'general election']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter ID laws', u'Supreme Court', u'voter ID']\n",
        "[u'North Carolina', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'Voting Rights Act']\n",
        "[u'North Carolina', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'Arkansas Supreme Court']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'Election Day', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'Voting Rights Act']\n",
        "[u'North Carolina', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'Voting Rights Act']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID']\n",
        "[u'provisional ballot', u'Election Day', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'photo ID', u'voter ID law', u'voter ID laws', u'Supreme Court', u'voter ID']\n",
        "[u'Election Day', u'North Carolina', u'voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'photo ID', u'voter ID law', u'voter ID laws', u'voter ID', u'photo identification']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'Voting Rights Act', u'federal government']\n",
        "[u'bank statement', u'other government document', u'government check', u'current utility bill', u'federal government']\n",
        "[u'voter ID law', u'voter ID laws', u'voter ID', u'election official', u'election officials']\n",
        "[u'voter ID law', u'voter fraud', u'voter ID laws', u'voter ID', u'student IDs']\n",
        "[u'photo ID', u'bank statement', u'other government document', u'government check', u'current utility bill']\n",
        "[u'North Carolina', u'voter ID law', u'Supreme Court', u'voter ID', u'Voting Rights Act']\n",
        "[u'photo ID', u'voter ID law', u'voter ID laws', u'voter ID', u'polling place']\n",
        "[u'voter ID law', u'voter ID laws', u'voter ID', u'Voting Rights Act']\n",
        "[u'provisional ballot', u'photo ID', u'reasonable impediment', u'federal government', u'non-photo voter registration card']\n",
        "[u'photo ID', u'expiration date', u'Supreme Court', u'voter ID', u'Arkansas Supreme Court', u'U.S. government', u'identification document']\n",
        "[u'photo ID', u'North Carolina', u'voter ID law', u'voter ID laws', u'voter ID', u'United States']\n",
        "[u'provisional ballot', u'photo ID', u'2014 general election', u'provisional ballots', u'student ID card', u'general election']\n",
        "[u'voter ID law', u'voter ID laws', u'Supreme Court', u'voter ID', u'Voting Rights Act']\n",
        "[u'voter ID law', u'Supreme Court', u'voter ID', u'U.S. Supreme Court', u'Voting Rights Act']\n",
        "[u'provisional ballot', u'bank statement', u'birth certificate', u'other government document', u'government check', u'current utility bill', u'U.S. government']\n",
        "[u'bank statement', u'other government document', u'government check', u'photo identification', u'current utility bill', u'valid photo identification']\n",
        "[u'provisional ballot', u'bank statement', u'government check', u'current utility bill', u'electoral board', u'United States', u'identification document', u'student ID card']\n",
        "[u'North Carolina', u'voter ID law', u'strict photo voter ID law', u'voter ID']\n",
        "[u'voter ID law', u'voter ID laws', u'Supreme Court', u'voter ID', u'U.S. Supreme Court', u'Voting Rights Act']\n",
        "[u'voter ID law', u'strict photo voter ID law', u'voter ID laws', u'voter ID']\n",
        "[u'voter ID law', u'strict photo voter ID law', u'Supreme Court', u'voter ID', u'Arkansas Supreme Court']\n",
        "[u'photo ID', u'voter ID law', u'strict photo voter ID law', u'voter ID', u'non-photo ID law']\n",
        "[u'provisional ballot', u'expiration date', u'bank statement', u'other government document', u'government check', u'photo identification', u'social security number', u'U.S. government', u'valid photo identification']\n",
        "[u'voter ID law', u'strict photo voter ID law', u'Supreme Court', u'voter ID', u'Arkansas Supreme Court']\n",
        "[u'voter ID law', u'strict photo voter ID law', u'Supreme Court', u'voter ID', u'U.S. Supreme Court']\n",
        "[u'2014 general election', u'voter ID law', u'strict photo voter ID law', u'Supreme Court', u'voter ID', u'U.S. Supreme Court', u'general election']\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ord_freqchunks = sorted(freqchunks, key=len)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ord_freqchunks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "[u') NOTE',\n",
        " u'photo ID',\n",
        " u'voter ID',\n",
        " u'poll book',\n",
        " u'voter fraud',\n",
        " u'student IDs',\n",
        " u'Election Day',\n",
        " u'voter ID law',\n",
        " u'poll workers',\n",
        " u'voter ID laws',\n",
        " u'Supreme Court',\n",
        " u'polling place',\n",
        " u'United States',\n",
        " u'North Carolina',\n",
        " u'bank statement',\n",
        " u'regular ballot',\n",
        " u'expiration date',\n",
        " u'U.S. government',\n",
        " u'electoral board',\n",
        " u'student ID card',\n",
        " u'voter affidavit',\n",
        " u'government check',\n",
        " u'attorney general',\n",
        " u'non-photo ID law',\n",
        " u'driver\\u2019s license',\n",
        " u'general election',\n",
        " u'birth certificate',\n",
        " u'election official',\n",
        " u'Voting Rights Act',\n",
        " u'provisional ballot',\n",
        " u'U.S. Supreme Court',\n",
        " u'election officials',\n",
        " u'federal government',\n",
        " u'religious objection',\n",
        " u'provisional ballots',\n",
        " u'registration record',\n",
        " u'photo identification',\n",
        " u'current utility bill',\n",
        " u'voter ID legislation',\n",
        " u'2014 general election',\n",
        " u'reasonable impediment',\n",
        " u'Arkansas Supreme Court',\n",
        " u'social security number',\n",
        " u'identification document',\n",
        " u'strict photo voter ID law',\n",
        " u'other government document',\n",
        " u'county election commission',\n",
        " u'valid photo identification',\n",
        " u'challenged voter affidavit',\n",
        " u'non-photo voter registration card']"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = ['an apple', 'apple', 'banana and an apple']\n",
      "integrate_ngrams(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "['an apple', 'apple', 'banana and an apple']"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get FD of chunks (or other method for getting keyphrases) across corpus\n",
      "#pull out all sentences with those keyphrases in them from corpus into mini corpus\n",
      "#look at all sentences\n",
      "#chunk for all verbs and look for phrases within these sentences\n",
      "#develop a matrix (docs & )\n",
      "#what are all the things that are associated \n",
      "#reduce chunks to get summary (get to tag cloud -- THIS IS OUR BASELINE)\n",
      "\n",
      "\n",
      "#then try on additional hashtag set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "___________________"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Second Approach: Collocations"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Statistics-based Bigrams & Trigrams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Part II. Collocations <br>\n",
      "* Statistics-based Collocations (PMI, Chi-squared, etc)\n",
      "* Syntactic-Pattern-Based Collocations (as in Justeson & Katz)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, I took an approach of comparing similar but different bigram collocation finder algorithms to see if less restrictive or more restrictive formulas yielded better results. Less generally means that I'll accept those that occur more infrequently AND in a larger \"window size\", so they can span other text. More restrictive is the opposite."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create tokens from string\n",
      "def getTokens(string):\n",
      "    sentences = nltk.sent_tokenize(string)\n",
      "    tokenized_sents = [nltk.word_tokenize(sent.strip('(').strip(')')) for sent in sentences]\n",
      "    tokens = [unicode(w,\"latin-1\") for i in tokenized_sents for w in i]\n",
      "    return tokens\n",
      "\n",
      "#1\n",
      "#bigrams that appear at least 5 times within a window size of 6 words, excluding any bigram \n",
      "#with a token of fewer than 3 chars; return the 20 best according to the PMI measure\n",
      "def getBiCollocations(word_list):\n",
      "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
      "    #look for bigrams near each other in a window of 10\n",
      "    finder = BigramCollocationFinder.from_words(word_list, window_size=10)\n",
      "    finder.apply_freq_filter(3)\n",
      "    ignored_words = nltk.corpus.stopwords.words('english')\n",
      "    finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
      "    return finder.nbest(bigram_measures.pmi, 50)  \n",
      "\n",
      "#2\n",
      "#bigrams that appear at least 10 times within a window size of 4 words, excluding any bigram \n",
      "#with a token of fewer than 3 chars; return the 20 best according to the PMI measure\n",
      "def getBiCollocations2(word_list):\n",
      "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
      "    #look for bigrams near each other in a window of 4\n",
      "    finder = BigramCollocationFinder.from_words(word_list, window_size=4)\n",
      "    finder.apply_freq_filter(5)\n",
      "    ignored_words = nltk.corpus.stopwords.words('english')\n",
      "    finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
      "    return finder.nbest(bigram_measures.pmi, 50)  \n",
      "\n",
      "#3\n",
      "#find trigrams that appear at least 3 times, excluding any bigram with a token of fewer than 3 \n",
      "#chars; return the 20 best according to the PMI measure\n",
      "def getTriCollocations(word_list):\n",
      "    trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
      "    finder = TrigramCollocationFinder.from_words(word_list)\n",
      "    finder.apply_freq_filter(2)\n",
      "    ignored_words = nltk.corpus.stopwords.words('english')\n",
      "    finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
      "    return finder.nbest(trigram_measures.pmi, 20)  \n",
      "      \n",
      "\n",
      "#prettifies the display of bigram and trigram collocation functions\n",
      "def findCollocsfromTokens(tokens, func=1):\n",
      "    if func == 1:\n",
      "        bi = getBiCollocations(tokens)\n",
      "        print 'Important Bigram Collocations (Loose Measures)'\n",
      "        print \n",
      "        for e in bi:\n",
      "            print '%-10s' % e[0], '%-10s' % e[1]\n",
      "    elif func == 2:\n",
      "        bi2 = getBiCollocations2(tokens)\n",
      "        print 'Important Bigram Collocations (Restrictive Measures)'\n",
      "        print\n",
      "        for f in bi2:\n",
      "            print '%-10s' % f[0], '%-10s' % f[1]\n",
      "    elif func == 3: \n",
      "        tri = getTriCollocations(tokens)\n",
      "        print 'Important Trigram Collocations'\n",
      "        print\n",
      "        for j in tri:\n",
      "            print '%-10s' % j[0], '%-10s' % j[1], '%-10s' % j[2]\n",
      "    else: \n",
      "        print 'func takes either 1, 2, or 3 as values'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "______"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
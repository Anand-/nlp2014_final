{
 "metadata": {
  "gist_id": "f00815cbe158a89cf35e",
  "name": "",
  "signature": "sha256:dffc8730ab31bbb5e904b9af19046f909dd901264b9f10ffe4f32af269aa57a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk, string\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from nltk.collocations import *\n",
      "import codecs, os, json, glob\n",
      "from bs4 import BeautifulSoup\n",
      "from nltk.corpus import wordnet as wn\n",
      "from pandas import DataFrame\n",
      "import pandas as pd\n",
      "import get_sents\n",
      "\n",
      "wnlemmatizer = nltk.WordNetLemmatizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get list of files\n",
      "def readFilestoList(path):\n",
      "    filelist = []\n",
      "    for file in glob.glob(os.path.join(path, '*.json')):\n",
      "        filelist.append(file)\n",
      "    return filelist  \n",
      "\n",
      "def jsonToTuples(filelist):\n",
      "    articles = []\n",
      "    for filepath in filelist:\n",
      "        with open(filepath, 'r') as f:\n",
      "            j = json.load(f)\n",
      "            if 'objects' in j.keys():\n",
      "                if 'title' in j['objects'][0]:\n",
      "                    articles.append((j['objects'][0]['title'], j['objects'][0]['text']))\n",
      "    return articles\n",
      "\n",
      "\n",
      "#read json to dictionary, dedupes articles by title only\n",
      "def jsonToDict(filelist):\n",
      "    articles = {}\n",
      "    for filepath in filelist:\n",
      "        with open(filepath, 'r') as f:\n",
      "            j = json.load(f)\n",
      "            if 'objects' in j.keys():\n",
      "                if 'title' in j['objects'][0]:\n",
      "                    articles[j['objects'][0]['title']]=j['objects'][0]['text']\n",
      "    return articles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1. Read in content from directory, dedupe articles by title"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r\"([A-Z]\\.)+|\\w+([-']\\w+)*|\\$?\\d+(\\.\\d+)?%?|\\.\\.\\.|[][.,;\\\"'?():-_`]\"\n",
      "\n",
      "#tokenize all words in article without sentence tokenizing\n",
      "def RegTokenizeWords(wordlist):\n",
      "    return [word.lower() for word in nltk.regexp_tokenize(wordlist,pattern)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#check for English\n",
      "def languageCheck(text):\n",
      "    fd = nltk.FreqDist(nltk.word_tokenize(text))\n",
      "    topwords = [key.lower() for key in fd.keys()[:15]]\n",
      "    \n",
      "    if \"the\" not in topwords:\n",
      "#         print \"BAD TOPWORDS: \", topwords\n",
      "        return False\n",
      "    else:\n",
      "#         print \"GOOD TOPWORDS: \", topwords\n",
      "        return True\n",
      "    \n",
      "\n",
      "#create df for titles & content tokenize titles and content\n",
      "def tokenizeDictionaryContentToDf(titles_content):\n",
      "    articles = []\n",
      "    titles = []\n",
      "    for title, article in titles_content.items():\n",
      "        if(languageCheck(article)):\n",
      "            articles.append(article)\n",
      "            titles.append(title)\n",
      "\n",
      "    data = {'article': articles, 'title': titles}\n",
      "    df = DataFrame(data)\n",
      "    df['tokenized_article'] = df['article'].map(nltk.sent_tokenize)\n",
      "    df['tokenized_title'] = df['title'].map(nltk.word_tokenize)\n",
      "    df['tokenized_title2'] = df['title'].map(RegTokenizeWords)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2. Break articles into title and text, tokenize both into sentences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vid_list = readFilestoList('data/voterID_clean/')\n",
      "vid = jsonToDict(vid_list)\n",
      "df_vid = tokenizeDictionaryContentToDf(vid)\n",
      "df_vid.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>article</th>\n",
        "      <th>title</th>\n",
        "      <th>tokenized_article</th>\n",
        "      <th>tokenized_title</th>\n",
        "      <th>tokenized_title2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> If Angelina Jolie hasn\u2019t changed her voter reg...</td>\n",
        "      <td>          How Many Women Won\u2019t Be Allowed to Vote?</td>\n",
        "      <td> [If Angelina Jolie hasn\u2019t changed her voter re...</td>\n",
        "      <td> [How, Many, Women, Won\u2019t, Be, Allowed, to, Vot...</td>\n",
        "      <td> [how, many, women, won, t, be, allowed, to, vo...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> by Ian Millhiser Posted on November 4, 2014 at...</td>\n",
        "      <td> How Black Students Are Reportedly Being Disenf...</td>\n",
        "      <td> [by Ian Millhiser Posted on November 4, 2014 a...</td>\n",
        "      <td> [How, Black, Students, Are, Reportedly, Being,...</td>\n",
        "      <td> [how, black, students, are, reportedly, being,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http:...</td>\n",
        "      <td> James OKeefe Offered a Bus Load of Ballots in ...</td>\n",
        "      <td> [BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http...</td>\n",
        "      <td> [James, OKeefe, Offered, a, Bus, Load, of, Bal...</td>\n",
        "      <td> [james, okeefe, offered, a, bus, load, of, bal...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Insufficient voting machines and poll workers ...</td>\n",
        "      <td> Being white on Election Day means you probably...</td>\n",
        "      <td> [Insufficient voting machines and poll workers...</td>\n",
        "      <td> [Being, white, on, Election, Day, means, you, ...</td>\n",
        "      <td> [being, white, on, election, day, means, you, ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jenny Huong Dao, Opinions Contributor\\nNovembe...</td>\n",
        "      <td>     Texas Voter ID law discourages voter security</td>\n",
        "      <td> [Jenny Huong Dao, Opinions Contributor\\nNovemb...</td>\n",
        "      <td> [Texas, Voter, ID, law, discourages, voter, se...</td>\n",
        "      <td> [texas, voter, id, law, discourages, voter, se...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "                                             article  \\\n",
        "0  If Angelina Jolie hasn\u2019t changed her voter reg...   \n",
        "1  by Ian Millhiser Posted on November 4, 2014 at...   \n",
        "2  BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http:...   \n",
        "3  Insufficient voting machines and poll workers ...   \n",
        "4  Jenny Huong Dao, Opinions Contributor\\nNovembe...   \n",
        "\n",
        "                                               title  \\\n",
        "0           How Many Women Won\u2019t Be Allowed to Vote?   \n",
        "1  How Black Students Are Reportedly Being Disenf...   \n",
        "2  James OKeefe Offered a Bus Load of Ballots in ...   \n",
        "3  Being white on Election Day means you probably...   \n",
        "4      Texas Voter ID law discourages voter security   \n",
        "\n",
        "                                   tokenized_article  \\\n",
        "0  [If Angelina Jolie hasn\u2019t changed her voter re...   \n",
        "1  [by Ian Millhiser Posted on November 4, 2014 a...   \n",
        "2  [BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http...   \n",
        "3  [Insufficient voting machines and poll workers...   \n",
        "4  [Jenny Huong Dao, Opinions Contributor\\nNovemb...   \n",
        "\n",
        "                                     tokenized_title  \\\n",
        "0  [How, Many, Women, Won\u2019t, Be, Allowed, to, Vot...   \n",
        "1  [How, Black, Students, Are, Reportedly, Being,...   \n",
        "2  [James, OKeefe, Offered, a, Bus, Load, of, Bal...   \n",
        "3  [Being, white, on, Election, Day, means, you, ...   \n",
        "4  [Texas, Voter, ID, law, discourages, voter, se...   \n",
        "\n",
        "                                    tokenized_title2  \n",
        "0  [how, many, women, won, t, be, allowed, to, vo...  \n",
        "1  [how, black, students, are, reportedly, being,...  \n",
        "2  [james, okeefe, offered, a, bus, load, of, bal...  \n",
        "3  [being, white, on, election, day, means, you, ...  \n",
        "4  [texas, voter, id, law, discourages, voter, se...  "
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3. Tokenize text into sentences, tokenize sentences into words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#functions for tokenizing sentences\n",
      "def listToTokens(sentenceList):\n",
      "    tokenized_sents = [nltk.word_tokenize(sent.strip('(').strip(')')) for sent in sentenceList]\n",
      "    return tokenized_sents\n",
      "\n",
      "def tagTokens(tokenList):\n",
      "    tagged_sents = [nltk.pos_tag(sent) for sent in tokenList]\n",
      "    return tagged_sents\n",
      "\n",
      "def tagTitle(title):\n",
      "    tagged_title = [nltk.pos_tag(title)]\n",
      "    return tagged_title\n",
      "\n",
      "\n",
      "#functions for adding columns to df of sentence tokenized, word tokenized, and pos tagged text\n",
      "def docsIntoSents(columnname, df):\n",
      "    df['sent_tokenized'] = df[columnname].map(nltk.sent_tokenize)\n",
      "    return df\n",
      "    \n",
      "def sentsIntoTokens(columnname, df):\n",
      "    df['word_tokenized'] = df[columnname].map(listToTokens)\n",
      "    return df\n",
      "    \n",
      "def tokensPOStag(columnname, df, option='article'):\n",
      "    if option=='article':\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTokens)\n",
      "        return df\n",
      "    else:\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTitle)\n",
      "        return df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_vid = docsIntoSents('article', df_vid)\n",
      "df_vid = sentsIntoTokens('sent_tokenized', df_vid)\n",
      "df_vid = tokensPOStag('word_tokenized', df_vid)\n",
      "df_vid = tokensPOStag('tokenized_title', df_vid, option='title')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4. POS tag both title and text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_vid.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>article</th>\n",
        "      <th>title</th>\n",
        "      <th>tokenized_article</th>\n",
        "      <th>tokenized_title</th>\n",
        "      <th>tokenized_title2</th>\n",
        "      <th>sent_tokenized</th>\n",
        "      <th>word_tokenized</th>\n",
        "      <th>pos_tagged_word_tokenized</th>\n",
        "      <th>pos_tagged_tokenized_title</th>\n",
        "      <th>article_chunks</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> If Angelina Jolie hasn\u2019t changed her voter reg...</td>\n",
        "      <td>          How Many Women Won\u2019t Be Allowed to Vote?</td>\n",
        "      <td> [If Angelina Jolie hasn\u2019t changed her voter re...</td>\n",
        "      <td> [How, Many, Women, Won\u2019t, Be, Allowed, to, Vot...</td>\n",
        "      <td> [how, many, women, won, t, be, allowed, to, vo...</td>\n",
        "      <td> [If Angelina Jolie hasn\u2019t changed her voter re...</td>\n",
        "      <td> [[If, Angelina, Jolie, hasn\u2019t, changed, her, v...</td>\n",
        "      <td> [[(If, IN), (Angelina, NNP), (Jolie, NNP), (ha...</td>\n",
        "      <td> [[(How, WRB), (Many, JJ), (Women, NNS), (Won\u2019t...</td>\n",
        "      <td> [Angelina Jolie hasn\u2019t, driver\u2019s license, Mrs....</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> by Ian Millhiser Posted on November 4, 2014 at...</td>\n",
        "      <td> How Black Students Are Reportedly Being Disenf...</td>\n",
        "      <td> [by Ian Millhiser Posted on November 4, 2014 a...</td>\n",
        "      <td> [How, Black, Students, Are, Reportedly, Being,...</td>\n",
        "      <td> [how, black, students, are, reportedly, being,...</td>\n",
        "      <td> [by Ian Millhiser Posted on November 4, 2014 a...</td>\n",
        "      <td> [[by, Ian, Millhiser, Posted, on, November, 4,...</td>\n",
        "      <td> [[(by, IN), (Ian, NNP), (Millhiser, NNP), (Pos...</td>\n",
        "      <td> [[(How, WRB), (Black, NNP), (Students, NNP), (...</td>\n",
        "      <td> [Ian Millhiser Posted, How Black Students Are ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http:...</td>\n",
        "      <td> James OKeefe Offered a Bus Load of Ballots in ...</td>\n",
        "      <td> [BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http...</td>\n",
        "      <td> [James, OKeefe, Offered, a, Bus, Load, of, Bal...</td>\n",
        "      <td> [james, okeefe, offered, a, bus, load, of, bal...</td>\n",
        "      <td> [BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http...</td>\n",
        "      <td> [[BUY, JAMES, O'KEEFE, 'S, NYT, BESTSELLER, HE...</td>\n",
        "      <td> [[(BUY, NNP), (JAMES, NNP), (O'KEEFE, NNP), ('...</td>\n",
        "      <td> [[(James, NNP), (OKeefe, NNP), (Offered, NNP),...</td>\n",
        "      <td> [BUY JAMES O'KEEFE, NYT BESTSELLER HERE, under...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Insufficient voting machines and poll workers ...</td>\n",
        "      <td> Being white on Election Day means you probably...</td>\n",
        "      <td> [Insufficient voting machines and poll workers...</td>\n",
        "      <td> [Being, white, on, Election, Day, means, you, ...</td>\n",
        "      <td> [being, white, on, election, day, means, you, ...</td>\n",
        "      <td> [Insufficient voting machines and poll workers...</td>\n",
        "      <td> [[Insufficient, voting, machines, and, poll, w...</td>\n",
        "      <td> [[(Insufficient, NNP), (voting, NN), (machines...</td>\n",
        "      <td> [[(Being, VBG), (white, JJ), (on, IN), (Electi...</td>\n",
        "      <td> [Insufficient voting machines, poll workers, E...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jenny Huong Dao, Opinions Contributor\\nNovembe...</td>\n",
        "      <td>     Texas Voter ID law discourages voter security</td>\n",
        "      <td> [Jenny Huong Dao, Opinions Contributor\\nNovemb...</td>\n",
        "      <td> [Texas, Voter, ID, law, discourages, voter, se...</td>\n",
        "      <td> [texas, voter, id, law, discourages, voter, se...</td>\n",
        "      <td> [Jenny Huong Dao, Opinions Contributor\\nNovemb...</td>\n",
        "      <td> [[Jenny, Huong, Dao, ,, Opinions, Contributor,...</td>\n",
        "      <td> [[(Jenny, NNP), (Huong, NNP), (Dao, NNP), (,, ...</td>\n",
        "      <td> [[(Texas, NNP), (Voter, NNP), (ID, NNP), (law,...</td>\n",
        "      <td> [Jenny Huong Dao, Opinions Contributor Novembe...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "                                             article  \\\n",
        "0  If Angelina Jolie hasn\u2019t changed her voter reg...   \n",
        "1  by Ian Millhiser Posted on November 4, 2014 at...   \n",
        "2  BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http:...   \n",
        "3  Insufficient voting machines and poll workers ...   \n",
        "4  Jenny Huong Dao, Opinions Contributor\\nNovembe...   \n",
        "\n",
        "                                               title  \\\n",
        "0           How Many Women Won\u2019t Be Allowed to Vote?   \n",
        "1  How Black Students Are Reportedly Being Disenf...   \n",
        "2  James OKeefe Offered a Bus Load of Ballots in ...   \n",
        "3  Being white on Election Day means you probably...   \n",
        "4      Texas Voter ID law discourages voter security   \n",
        "\n",
        "                                   tokenized_article  \\\n",
        "0  [If Angelina Jolie hasn\u2019t changed her voter re...   \n",
        "1  [by Ian Millhiser Posted on November 4, 2014 a...   \n",
        "2  [BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http...   \n",
        "3  [Insufficient voting machines and poll workers...   \n",
        "4  [Jenny Huong Dao, Opinions Contributor\\nNovemb...   \n",
        "\n",
        "                                     tokenized_title  \\\n",
        "0  [How, Many, Women, Won\u2019t, Be, Allowed, to, Vot...   \n",
        "1  [How, Black, Students, Are, Reportedly, Being,...   \n",
        "2  [James, OKeefe, Offered, a, Bus, Load, of, Bal...   \n",
        "3  [Being, white, on, Election, Day, means, you, ...   \n",
        "4  [Texas, Voter, ID, law, discourages, voter, se...   \n",
        "\n",
        "                                    tokenized_title2  \\\n",
        "0  [how, many, women, won, t, be, allowed, to, vo...   \n",
        "1  [how, black, students, are, reportedly, being,...   \n",
        "2  [james, okeefe, offered, a, bus, load, of, bal...   \n",
        "3  [being, white, on, election, day, means, you, ...   \n",
        "4  [texas, voter, id, law, discourages, voter, se...   \n",
        "\n",
        "                                      sent_tokenized  \\\n",
        "0  [If Angelina Jolie hasn\u2019t changed her voter re...   \n",
        "1  [by Ian Millhiser Posted on November 4, 2014 a...   \n",
        "2  [BUY JAMES O'KEEFE'S NYT BESTSELLER HERE: http...   \n",
        "3  [Insufficient voting machines and poll workers...   \n",
        "4  [Jenny Huong Dao, Opinions Contributor\\nNovemb...   \n",
        "\n",
        "                                      word_tokenized  \\\n",
        "0  [[If, Angelina, Jolie, hasn\u2019t, changed, her, v...   \n",
        "1  [[by, Ian, Millhiser, Posted, on, November, 4,...   \n",
        "2  [[BUY, JAMES, O'KEEFE, 'S, NYT, BESTSELLER, HE...   \n",
        "3  [[Insufficient, voting, machines, and, poll, w...   \n",
        "4  [[Jenny, Huong, Dao, ,, Opinions, Contributor,...   \n",
        "\n",
        "                           pos_tagged_word_tokenized  \\\n",
        "0  [[(If, IN), (Angelina, NNP), (Jolie, NNP), (ha...   \n",
        "1  [[(by, IN), (Ian, NNP), (Millhiser, NNP), (Pos...   \n",
        "2  [[(BUY, NNP), (JAMES, NNP), (O'KEEFE, NNP), ('...   \n",
        "3  [[(Insufficient, NNP), (voting, NN), (machines...   \n",
        "4  [[(Jenny, NNP), (Huong, NNP), (Dao, NNP), (,, ...   \n",
        "\n",
        "                          pos_tagged_tokenized_title  \\\n",
        "0  [[(How, WRB), (Many, JJ), (Women, NNS), (Won\u2019t...   \n",
        "1  [[(How, WRB), (Black, NNP), (Students, NNP), (...   \n",
        "2  [[(James, NNP), (OKeefe, NNP), (Offered, NNP),...   \n",
        "3  [[(Being, VBG), (white, JJ), (on, IN), (Electi...   \n",
        "4  [[(Texas, NNP), (Voter, NNP), (ID, NNP), (law,...   \n",
        "\n",
        "                                      article_chunks  \n",
        "0  [Angelina Jolie hasn\u2019t, driver\u2019s license, Mrs....  \n",
        "1  [Ian Millhiser Posted, How Black Students Are ...  \n",
        "2  [BUY JAMES O'KEEFE, NYT BESTSELLER HERE, under...  \n",
        "3  [Insufficient voting machines, poll workers, E...  \n",
        "4  [Jenny Huong Dao, Opinions Contributor Novembe...  "
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_______"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "5. After POS Tagging, Chunk into NPs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#look for important noun phrase patterns, either nouns preceded by Det+Adj or simply compound nouns\n",
      "def parseImportantNps():\n",
      "    grammar = r\"\"\"\n",
      "    N-N: {<DET|CD.*>?<J*|N.*>+<N.*>} # chunk DET/Cardinal w/optional ADJ or N with proper noun\n",
      "           {<NNP.*>+<NNP.*>}             # chunk solo proper nouns only\n",
      "    \"\"\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    return cp, 'N-N'\n",
      "\n",
      "#function to chunk \n",
      "def chunk(tagged, func=parseImportantNps):\n",
      "    chunks = []\n",
      "    leaves = []\n",
      "    cp, cn = func()\n",
      "    for i in tagged:\n",
      "        tree = cp.parse(i)\n",
      "        for subtree in tree.subtrees():\n",
      "            if subtree.node == cn:\n",
      "                leaflist = [leaf[0] for leaf in subtree.leaves()]\n",
      "                chunks.append(subtree.leaves())\n",
      "                leaves.append(' '.join(leaflist))\n",
      "    return leaves\n",
      "        \n",
      "#show the proper nouns as strings without their tags\n",
      "def getChunksAsStrings(chunk_list):\n",
      "    phrases = []\n",
      "    for i in chunk_list:\n",
      "        phrase = ''\n",
      "        for j in i:\n",
      "            phrase = phrase + j[0] + ' '\n",
      "        phrases.append(phrase)\n",
      "    return phrases    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function to add new column with tagged tokens (whether from article or title) to df\n",
      "def tokensPOStag(columnname, df, option='article'):\n",
      "    if option=='article':\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTokens)\n",
      "        return df\n",
      "    else:\n",
      "        columntitle = 'pos_tagged_%s' %columnname\n",
      "        df[columntitle] = df[columnname].map(tagTitle)\n",
      "        return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#chunking is done here; if blank articles, you'll get message 'parsing empty text' but for the rest of the articles, it works\n",
      "df_vid['article_chunks'] = df_vid.pos_tagged_word_tokenized.apply(chunk)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: parsing empty text\n"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "6. Frequency Distribution of Chunks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get frequency distribution of chunks across corpus\n",
      "corpus_chunks = []\n",
      "for chunk in df_vid['article_chunks']:\n",
      "    corpus_chunks.extend(chunk)\n",
      "     \n",
      "chunk_fd = nltk.FreqDist(corpus_chunks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get a sense of where the frequency drops off; generally we'll use the top 100 chunks\n",
      "chunk_fd.items()[10], chunk_fd.items()[100], chunk_fd.items()[1000], chunk_fd.items()[10000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 169,
       "text": [
        "((u'poll workers', 65),\n",
        " (u'Washington Post', 12),\n",
        " (u'low expectations', 3),\n",
        " (u'full article ACLU', 1))"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freqchunks = chunk_fd.keys()[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_______"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "7. Text Tiling Using Frequency Distribution of Chunks:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "a. Break Chunks into Groups By Length "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#break chunks into groups by length\n",
      "def getPhraseLengths(chunkfd):\n",
      "    lenMore = []\n",
      "    len3 = []\n",
      "    len2 = []\n",
      "    len1 = []\n",
      "    combined = {}\n",
      "    \n",
      "    for c in chunkfd:\n",
      "        if len(c.split()) > 3:\n",
      "            lenMore.append(c)\n",
      "        if len(c.split()) == 3:\n",
      "            len3.append(c)\n",
      "        if len(c.split()) == 2:\n",
      "            len2.append(c)\n",
      "        if len(c.split()) == 1:\n",
      "            len1.append(c)\n",
      "    return len1, len2, len3, lenMore\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "b. Merge Terms within Same-length Groups"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "#merge ngrams into same length other ngrams\n",
      "def mergeTerms(list1):\n",
      "    \n",
      "    results = []\n",
      "    list2 = set([i.lower() for i in list1])\n",
      "    \n",
      "    for i in list2: \n",
      "        flag = True\n",
      "        for j in list2:\n",
      "            if i in j and i != j:\n",
      "                results.append(j)\n",
      "                flag = False\n",
      "                \n",
      "        if flag == True and i not in results: \n",
      "            results.append(i)\n",
      "    \n",
      "    return set(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "c. Merge Shorter Chunks into Larger Ones"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#merge shorter length terms into longer length terms\n",
      "def mergeTerms2Lists(shortlenlist, longerlenlist):\n",
      "    termMapping = {}\n",
      "    \n",
      "    for j in longerlenlist:\n",
      "        termMapping[j] = []\n",
      "    for i in shortlenlist: \n",
      "        flag = True\n",
      "        for j in longerlenlist:\n",
      "            if i.lower() in j.lower():\n",
      "                termMapping[j].append(i)\n",
      "                flag = False\n",
      "        if flag == True:\n",
      "            termMapping[i] = []\n",
      "    \n",
      "    return termMapping"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#produce chunk groups by length\n",
      "len1, len2, len3, lenMore = getPhraseLengths(freqchunks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#condense all terms of same length into new lists\n",
      "new_len2 = mergeTerms(len2)\n",
      "new_len3 = mergeTerms(len3)\n",
      "new_lenMore = mergeTerms(lenMore)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#resulting list \n",
      "merged2_3 = mergeTerms2Lists(new_len2, new_len3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#resulting list if we decide to merge into larger chunks\n",
      "improved_freqchunks = mergeTerms2Lists(merged2_3.keys(), new_lenMore).keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(improved_freqchunks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "81"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#concatenate all rows in two of the columns of a dataframe\n",
      "def createCorpusMultiColumns(df, columnName1, columnname2):\n",
      "    corpus = []\n",
      "    for row in df[columnName1]:\n",
      "        corpus.extend(row)\n",
      "    for row in df[columnname2]:\n",
      "        corpus.extend(row)\n",
      "    return corpus\n",
      "\n",
      "def createCorpusSingleColumn(df, columnName1):\n",
      "    corpus = []\n",
      "    for row in df[columnName1]:\n",
      "        corpus.extend(row)\n",
      "    return corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get all tokenized sentences across corpus\n",
      "all_sents = createCorpusSingleColumn(df_vid, 'sent_tokenized')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "______"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "8. Extract Sentences Containing Chunks (you can ignore this)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get sentences containing words from improved list of freqchunks\n",
      "imp_sents_dict = {} \n",
      "\n",
      "for fc in improved_freqchunks:\n",
      "    imp_sents = []\n",
      "    imp_sents_dict[fc] = imp_sents\n",
      "    for sent in all_sents:\n",
      "        if sent.find(fc) != -1:\n",
      "            imp_sents.append(sent)\n",
      "           "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# aggregate all sentences in corpus\n",
      "total_sents = []\n",
      "\n",
      "for article in df_vid['sent_tokenized']:\n",
      "    for s in article:\n",
      "        total_sents.append(s)\n",
      "    \n",
      "len(total_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "10016"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create set of all sentences containing important words\n",
      "all_sents = []\n",
      "for l in imp_sents_dict.values():\n",
      "    for sent in l:\n",
      "        all_sents.extend(l)\n",
      "\n",
      "sents_of_interest = set(all_sents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "9. Order sentences by length of associated chunk list"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this still doesn't do the trick because it counts chunks multiple times in a single sentences: \n",
      "#[u'photo ID', u'ID law', u'ID laws', u'photo ID law',u'young people']\n",
      "\n",
      "import math\n",
      "\n",
      "sent_dict = {}\n",
      "\n",
      "for sent in sents_of_interest:\n",
      "    chunks_contained = {}\n",
      "    fcs = []\n",
      "    score = 0\n",
      "    \n",
      "    #grab all sentences of interest from corpus\n",
      "    if sent not in sent_dict:\n",
      "        sent_dict[sent] = chunks_contained\n",
      "        chunks_contained['fcs'] = fcs\n",
      "         \n",
      "        #associate score with sentence depending on number of chunks contained\n",
      "        for fc in freqchunks:\n",
      "            if sent.find(fc) != -1:\n",
      "                fcs.append(fc)\n",
      "                score = score + (len(fc.split())**2)\n",
      "        chunks_contained['score'] = int(score)\n",
      "\n",
      "sent_dict.items()[-10:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "[(u'At the same time, North Carolina\\u2019s voters were, for the first time, voting under one of the harshest new election laws in the country \\u2014 a law that Tillis helped to craft.',\n",
        "  {'fcs': [u'North Carolina', u'first time'], 'score': 8}),\n",
        " (u'(Photo by Jay LaPrete/Getty Images)\\nIf you\\u2019re a student, check out this interactive map from Brennan Center for voter requirements and early voting information.',\n",
        "  {'fcs': [u'Brennan Center', u'early voting'], 'score': 8}),\n",
        " (u'Or are photo ID laws just another conservative scheme to oppress young people and minorities and limit Democratic turnout?',\n",
        "  {'fcs': [u'photo ID',\n",
        "    u'ID law',\n",
        "    u'ID laws',\n",
        "    u'photo ID law',\n",
        "    u'young people'],\n",
        "   'score': 25}),\n",
        " (u\"The study cautioned that the results from Kansas and Tennessee don't necessarily apply to other states with stricter ID laws.\",\n",
        "  {'fcs': [u'ID law', u'ID laws', u'other states'], 'score': 12}),\n",
        " (u'So far, the county has received about twenty provisional ballots a day.',\n",
        "  {'fcs': [u'provisional ballot', u'provisional ballots'], 'score': 8}),\n",
        " (u'In Louisville, Ky., a city with a growing Hispanic population, there were reports of poll workers treating Latino voters rudely or failing to help, monitors said.',\n",
        "  {'fcs': [u'poll workers', u'poll worker'], 'score': 8}),\n",
        " (u'To get a Texas ID, Bates needed a birth certificate from her native Mississippi, which cost $42.',\n",
        "  {'fcs': [u'birth certificate'], 'score': 4}),\n",
        " (u'Nov. 2000: A vote was cast in the general election in Miami, FL, in the name of Andre Alism\\xe9, who had died in 1997.',\n",
        "  {'fcs': [u'general election'], 'score': 4}),\n",
        " (u\"After the Supreme Court invalidated Texas' poll tax, the state Legislature enacted a restrictive registration system requiring voters to reregister annually during a four-month time period that ended nearly eight months before the general election.\",\n",
        "  {'fcs': [u'Supreme Court', u'general election', u'poll tax'], 'score': 12}),\n",
        " (u'By contrast, beliefs about the prevalence of fraud by election officials show far less of a partisan skew, with 16 percent of Republicans, 21 percent of independents and 14 percent of Democrats (and 17 percent of Wisconsin voters over all) thinking that this affects a few thousand votes or more each election.',\n",
        "  {'fcs': [u'election officials'], 'score': 4})]"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "summ_sents = list(sent_dict.items())\n",
      "summ_sents.sort(key=lambda x: x[1]['score']) \n",
      "summ_sents[-10:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "[(u'AMY GOODMAN: Last month, Supreme Court Justice Ruth Bader Ginsburg issued a six-page dissent criticizing the court\\u2019s decision to allow Texas to use its new voter ID law in the midterm elections.',\n",
        "  {'fcs': [u'Supreme Court',\n",
        "    u'voter ID law',\n",
        "    u'voter ID',\n",
        "    u'ID law',\n",
        "    u'midterm elections',\n",
        "    u'new voter ID law',\n",
        "    u'AMY GOODMAN'],\n",
        "   'score': 45}),\n",
        " (u'\\u201cAnd that\\u2019s just not right.\\u201d\\nUnder some states\\u2019 new restrictive voter ID laws, individuals must have a state-issued photo ID that matches the name on their voter registration cards.',\n",
        "  {'fcs': [u'photo ID',\n",
        "    u'voter ID laws',\n",
        "    u'voter ID law',\n",
        "    u'voter ID',\n",
        "    u'ID law',\n",
        "    u'ID laws',\n",
        "    u'voter registration card',\n",
        "    u'voter registration'],\n",
        "   'score': 47}),\n",
        " (u\"Republicans in the Texas legislature had first introduced the voter ID law in 2011, but the state wasn't able to enact the measure until 2013, after the Supreme Court had struck down the part of the Voting Rights Act that required certain states, such as Texas, that have a history of discriminating against minority voters to get approval from the federal government before implementing new voting restrictions.\",\n",
        "  {'fcs': [u'Supreme Court',\n",
        "    u'voter ID law',\n",
        "    u'Voting Rights Act',\n",
        "    u'voter ID',\n",
        "    u'minority voters',\n",
        "    u'ID law',\n",
        "    u'federal government',\n",
        "    u'new voting restrictions'],\n",
        "   'score': 47}),\n",
        " (u'The claim made involves a narrow type of election fraud, in-person voter fraud, that voter ID laws are intended to prevent.',\n",
        "  {'fcs': [u'voter fraud',\n",
        "    u'voter ID laws',\n",
        "    u'voter ID law',\n",
        "    u'voter ID',\n",
        "    u'ID law',\n",
        "    u'ID laws',\n",
        "    u'election fraud',\n",
        "    u'in-person voter fraud'],\n",
        "   'score': 47}),\n",
        " (u'Some say photo ID laws are an attempt to suppress black voting\\nOne of the biggest voter frauds may be the idea promoted by Attorney General Eric Holder and others that there is no voter fraud, that laws requiring voters to have a photo identification are just attempts to suppress black voting.',\n",
        "  {'fcs': [u'photo ID',\n",
        "    u'voter fraud',\n",
        "    u'photo identification',\n",
        "    u'ID law',\n",
        "    u'ID laws',\n",
        "    u'Attorney General Eric Holder',\n",
        "    u'photo ID law',\n",
        "    u'Eric Holder'],\n",
        "   'score': 49}),\n",
        " (u'New Voter ID Proposals | Legislation Active in 2014\\nIllinois\\u2014HB 3007, HB 976,SB 1393, SB 1682, SB 1685 (all carried over from 2013); HB 4353, HB 5524\\nIowa\\u2014HB 485, SB 85 (all carried over from 2013; failed)\\nMaryland\\u2014HB 1094 (failed)\\nMassachusetts\\u2014HB 572, HB 580, HB 586, HB 592, HB 626, HB 3308, SB 335 and SB 339 (all carried over from 2013)\\nMinnesota\\u2014HB 1612 (failed)\\nNebraska \\u2014L 381 (carried over from 2013), L 622 (both failed)\\nNew York \\u2014A 3788, A 3789 and S 100\\nWest Virginia\\u2014HB 2215, HB 3107, HB 3117, HB 4479 (failed)\\nStrengthening Existing Voter ID Laws | Legislation Active in 2014\\nAlaska\\u2014HB 3 (failed)\\nColorado\\u2014HB 1128 (failed)\\nKentucky\\u2014SB 10 (failed)\\nMissouri\\u2014SJR 31, HJR 47, SB 511, HB 1073 (passed first chamber)\\nNew Hampshire\\u2014HB 1506 (failed)\\nOklahoma\\u2014HB 2106, HB 2116 (failed); SB 1284 (failed)\\nOther Changes to Voter ID Laws | Legislation Active in 2014\\nAlabama\\u2014SB 166 would require the existing strict photo ID law to be in effect by the 2014 general election (failed)\\nArizona\\u2014SB 1433 would add student ID cards to list; HB 2246 would sets up a task force to study elections, including studying the demand for provisional ballots based on ID requirements (failed)\\nIllinois\\u2014HB 976 (carried over from 2013) would require Voters Identification cards be provided for those who do not have an acceptable photo ID.',\n",
        "  {'fcs': [u'photo ID',\n",
        "    u'provisional ballot',\n",
        "    u'provisional ballots',\n",
        "    u'general election',\n",
        "    u'ID law',\n",
        "    u'New York',\n",
        "    u'photo ID law',\n",
        "    u'ID card',\n",
        "    u'student ID',\n",
        "    u'ID requirement',\n",
        "    u'New Hampshire'],\n",
        "   'score': 49}),\n",
        " (u'\"When you do see election fraud, it invariably involves election officials taking steps to change election results or it involves absentee ballots which voter ID laws can\\'t prevent,\" he said.',\n",
        "  {'fcs': [u'voter ID laws',\n",
        "    u'voter ID law',\n",
        "    u'voter ID',\n",
        "    u'election officials',\n",
        "    u'ID law',\n",
        "    u'ID laws',\n",
        "    u'absentee ballots',\n",
        "    u'election results',\n",
        "    u'absentee ballot',\n",
        "    u'election fraud'],\n",
        "   'score': 50}),\n",
        " (u'On the eve of the midterm elections, we air a report by investigative journalist Greg Palast on how new voter ID laws risk disenfranchising millions, especially black, Hispanic and Asian-American voters.',\n",
        "  {'fcs': [u'voter ID laws',\n",
        "    u'voter ID law',\n",
        "    u'voter ID',\n",
        "    u'ID law',\n",
        "    u'ID laws',\n",
        "    u'midterm elections',\n",
        "    u'new voter ID law'],\n",
        "   'score': 50}),\n",
        " (u\"(National Conference of State Legislatures)\\nIn this StoryStream\\n2014 Midterm Elections: Results and reactions from Election Day\\nNov 17\\nElection results 2014: News and updates on major midterm races\\nNov 4\\n6 questions about voter ID laws you were too embarrassed to ask\\nNov 4\\n2014 midterm elections: 5 reasons we might not know who wins the Senate for weeks\\n97 updates\\nRead This\\nEverything you need to know about the Bill Cosby sexual assault allegations\\nThis brilliant illustration shows how much public space we've surrendered to cars\\nWhy Bill Keller left the New York Times to put a spotlight on criminal justice\\nTrans-Pacific Partnership, the trade deal Obama and the GOP both love, explained\\n23 maps and charts on language\\nWhy do people run the marathon?\",\n",
        "  {'fcs': [u'voter ID laws',\n",
        "    u'Election Day',\n",
        "    u'voter ID law',\n",
        "    u'voter ID',\n",
        "    u'ID law',\n",
        "    u'ID laws',\n",
        "    u'midterm elections',\n",
        "    u'New York',\n",
        "    u'New York Times'],\n",
        "   'score': 51}),\n",
        " (u'This Election Day, a number of states are implementing strict new voter ID laws and registration policies in a high-turnout election for the first time.',\n",
        "  {'fcs': [u'voter ID laws',\n",
        "    u'Election Day',\n",
        "    u'voter ID law',\n",
        "    u'voter ID',\n",
        "    u'first time',\n",
        "    u'ID law',\n",
        "    u'ID laws',\n",
        "    u'new voter ID law'],\n",
        "   'score': 54})]"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}